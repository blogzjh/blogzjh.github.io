<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MySQL事务与锁</title>
      <link href="/zjh/2022/08/23/MySQL%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%94%81/"/>
      <url>/zjh/2022/08/23/MySQL%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%94%81/</url>
      
        <content type="html"><![CDATA[<ul><li>事务的4大特性分别由：事务日志、锁机制实现，0~4标题是事务日志，5之后是锁机制</li><li>每个阶段的小结放在最前面</li></ul><h1 id="0-事务日志：总结"><a href="#0-事务日志：总结" class="headerlink" title="0.事务日志：总结"></a>0.事务日志：总结</h1><ul><li>redo log保证持久性，在<code>innodb_flush_log_at_trx_commit=1</code>（默认）的情况下，保证了事务的安全可靠</li><li>undo log保证原子性、一致性，且undo log自身的持久化也依赖于redo log。undo log通过<strong>回滚指针形成链路</strong>，保证了回滚与MVCC。如果undo log被MVCC占用，则一直不会被删除。</li><li>刷盘持久化对于：页中数据(脏页)持久化、redo log持久化都有着相似的策略：（另外的线程）</li><li>delete和对<strong>主键</strong>update，实际上进行的软删除（修改deletemark隐藏字段），由purge线程来进行真实的删除。<h1 id="1-事务的4种特性"><a href="#1-事务的4种特性" class="headerlink" title="1.事务的4种特性"></a>1.事务的4种特性</h1></li><li>事务有4种特性：原子性、一致性、持久性、隔离性</li><li><code>隔离性</code>：由锁机制 or  MVCC实现</li><li><code>原子性、一致性、持久性</code>：由事务的redo日志和undo日志保证<br><img src="https://img-blog.csdnimg.cn/15768b7c08c14eec9fae8e77459f1d04.png"></li></ul><h1 id="2-事务日志概述"><a href="#2-事务日志概述" class="headerlink" title="2.事务日志概述"></a>2.事务日志概述</h1><ul><li>redo log ：<code>重做日志</code>，记录<strong>物理级别</strong>上的修改(在页上的修改)的日志，提供再写入操作，恢复提交事务修改页的操作，保证事务<code>持久性</code>；主要保证数据可靠性</li><li>undo log：<code>回滚日志</code>，记录<strong>逻辑操作</strong>的日志(每个改动操作的逆过程)，回滚到某一个特定版本，保证事务的<code>原子性、一致性</code>；主要用于回滚和MVCC</li><li><strong>二者都是一种恢复操作</strong>，只是场景不同</li><li>都是存储引擎生成的日志（而bin log则是数据层产生的）</li></ul><h1 id="3-redo-log与持久性-D"><a href="#3-redo-log与持久性-D" class="headerlink" title="3.redo log与持久性(D)"></a>3.redo log与持久性(D)</h1><h2 id="3-1Buffer-Pool"><a href="#3-1Buffer-Pool" class="headerlink" title="3.1Buffer Pool"></a>3.1Buffer Pool</h2><ul><li>在InnoDB中数据是存储在16k的页中的，在访问页中数据之前，会先将数据从磁盘读到内存中的Buffer Pool中</li><li>每次变更都需要先修改Buffer Pool，然后master线程以一定频率刷入磁盘。从而优化整体性能</li></ul><h2 id="3-2刷盘频率"><a href="#3-2刷盘频率" class="headerlink" title="3.2刷盘频率"></a>3.2刷盘频率</h2><ul><li>如果每次事务提交都进行刷盘，那么效率就很低下（因为每次刷盘都是对一整个页进行刷盘，每次IO都是16kb）</li><li> 当一个事务影响了多个页，刷盘时可能进行很多的随机IO（页可能不连续，而随机IO比顺序IO更慢，尤其对于传统机械硬盘）</li></ul><h2 id="3-3redo日志解决刷盘频率问题"><a href="#3-3redo日志解决刷盘频率问题" class="headerlink" title="3.3redo日志解决刷盘频率问题"></a>3.3redo日志解决刷盘频率问题</h2><ul><li>redo log也是写在磁盘中的，但占用的空间很小，也减少了刷盘的频率（<strong>16kb带来的性能开销远高于写一条日志</strong>）</li><li>redo log是<strong>顺序写入磁盘</strong>的，比随机IO速度更快</li><li><strong>此刷盘（redo log）非彼刷盘（页中数据）</strong></li></ul><h2 id="3-4redo-log-buffer和redo-log-file"><a href="#3-4redo-log-buffer和redo-log-file" class="headerlink" title="3.4redo log buffer和redo log file"></a>3.4redo log buffer和redo log file</h2><p>buffer：在内存中，默认16M，内部的block块是512kb<br>file：在磁盘中</p><p><strong>只要保证redo log从buffer持久化到file不出错，那么MySQL宕机也能恢复数据</strong><br><img src="https://img-blog.csdnimg.cn/63a03ebe859341208c8d8c6ed631c457.png"></p><h3 id="3-4-1刷盘策略innodb-flush-log-at-trx-commit"><a href="#3-4-1刷盘策略innodb-flush-log-at-trx-commit" class="headerlink" title="3.4.1刷盘策略innodb_flush_log_at_trx_commit="></a>3.4.1刷盘策略innodb_flush_log_at_trx_commit=</h3><ul><li>innodb_flush_log_at_trx_commit=1：每次commit就刷盘，redo log 一定在磁盘中，安全，不存在数据丢失问题，效率最差</li><li>innodb_flush_log_at_trx_commit=2：每次commit只写入文件系统缓存(page cache)，由后台线程进行刷盘，效率高，但不安全</li><li>innodb_flush_log_at_trx_commit=0：1、2的折中做法，后台线程刷盘频率为1s</li></ul><h3 id="3-4-2建议使用默认"><a href="#3-4-2建议使用默认" class="headerlink" title="3.4.2建议使用默认"></a>3.4.2建议使用默认</h3><p>默认值为1，虽然效率差，但安全。使用事务本来考虑的就是安全性优先</p><h1 id="4-undo-log与原子性-A"><a href="#4-undo-log与原子性-A" class="headerlink" title="4.undo log与原子性(A)"></a>4.undo log与原子性(A)</h1><ul><li>第3点的redo log保证的是持久性，事务过程中每次操作<code>之后</code>都会产生一条redo log</li><li>而undo log保证的是原子性，要保留之前的数据则需要在每次操作<code>之前</code></li></ul><h2 id="4-1undo-log应用场景"><a href="#4-1undo-log应用场景" class="headerlink" title="4.1undo log应用场景"></a>4.1undo log应用场景</h2><ul><li>服务器出错、断电需要回滚</li><li>事务手动roll back回滚</li><li>MVCC</li><li>注：<strong>SELECT不产生undo log，但在MVCC机制中会用到undo log</strong></li><li><strong>undo log产生的同时也会产生保护自身的redo log</strong>，而redo log默认刷盘策略innodb_flush_log_at_trx_commit=1又能保证回滚日志的安全(持久化)</li></ul><h2 id="4-2undo-log回滚的理解"><a href="#4-2undo-log回滚的理解" class="headerlink" title="4.2undo log回滚的理解"></a>4.2undo log回滚的理解</h2><ul><li>undo log是逻辑日志，回滚只是表面上恢复之前的物理状态，但实际上是反向操作</li><li>InnoDB支持的<strong>并发事务数量</strong>是由<code>回滚段roll back segment</code>决定的，默认是128*1024</li></ul><h2 id="4-3每一行数据的结构"><a href="#4-3每一行数据的结构" class="headerlink" title="4.3每一行数据的结构"></a>4.3每一行数据的结构</h2><p>对于InnoDB来说，每一行都有3个隐藏列</p><ul><li>DB_ROW_ID: 没有指定主键时的隐藏主键</li><li>DB_TRX_ID：事务ID</li><li>DB_ROLL_PTR：回滚指针，指向undo log，<strong>相当于记录了修改该行之前的值</strong>，而undo log本身的数据结构也有一个undo log指针，指向上一个undo log（通过序号链式指向，在回滚和MVCC中用处很大）<img src="https://img-blog.csdnimg.cn/632b7b30e4fc498392ec41e1db4c2c4a.png"><h3 id="4-3-1undo-log序号"><a href="#4-3-1undo-log序号" class="headerlink" title="4.3.1undo log序号"></a>4.3.1undo log序号</h3>这个序号是按顺序写入日志的，因此在回滚的时候直接倒叙回滚就好</li></ul><h2 id="4-4更新主键：deletemark"><a href="#4-4更新主键：deletemark" class="headerlink" title="4.4更新主键：deletemark"></a>4.4更新主键：deletemark</h2><p>4.3这种更新非主键是通过直接修改undo log指针指向来实现的。而如果修改主键id则需要利用<code>deletemark</code>（一个软删除标志，=1则软删，真实的删除由<code>purge线程</code>删除线程实现）<br><img src="https://img-blog.csdnimg.cn/ecfaae3fedf94c03a401683f5ba73d38.png"></p><h2 id="4-5undo-log何时删除"><a href="#4-5undo-log何时删除" class="headerlink" title="4.5undo log何时删除"></a>4.5undo log何时删除</h2><h3 id="4-5-1对于insert操作"><a href="#4-5-1对于insert操作" class="headerlink" title="4.5.1对于insert操作"></a>4.5.1对于insert操作</h3><p>在RR(可重复读)的隔离级别下，insert操作只对本事务可见（RR级别的MVCC解决了幻读），因此insert操作的 undo log可以在commit之后直接删除</p><h3 id="4-5-2对于update操作"><a href="#4-5-2对于update操作" class="headerlink" title="4.5.2对于update操作"></a>4.5.2对于update操作</h3><p>由于MVCC机制中的日志数组可能仍持有这条undo log记录，因此update操作commit后不能直接删除，而是存入undo log的一个链表中</p><h1 id="5-事务的隔离级别与解决的问题"><a href="#5-事务的隔离级别与解决的问题" class="headerlink" title="5.事务的隔离级别与解决的问题"></a>5.事务的隔离级别与解决的问题</h1><p>问题一般是：脏读、不可重复读、幻读</p><ul><li>脏读：B读取了A<strong>回滚前</strong>的数据</li><li>不可重复读：<strong>B两次读取</strong>，分别读了A修改前和修改后的数据</li><li>幻读：一般是B事务<strong>SELECT一个WHERE范围</strong>，在这个范围中读到了<strong>A没提交的insert数据</strong></li><li><code> SELECT @@transaction_isolation;</code>查看隔离级别<h2 id="5-1RU级别"><a href="#5-1RU级别" class="headerlink" title="5.1RU级别"></a>5.1RU级别</h2>RU：Read Uncommitted <strong>读未提交</strong>，最低的隔离级别，<strong>任何情况都不加锁</strong>，在这个隔离级别下可能出现所有的问题</li></ul><h2 id="5-2RC级别"><a href="#5-2RC级别" class="headerlink" title="5.2RC级别"></a>5.2RC级别</h2><p>RC：Read Committed <strong>读已提交</strong>，MVCC支持的最低隔离级别</p><ul><li>如果有InnoDB的MVCC机制，则解决了：脏读、不可重复读</li><li>如果没有MVCC机制，则只解决了：脏读</li></ul><h2 id="5-3RR级别"><a href="#5-3RR级别" class="headerlink" title="5.3RR级别"></a>5.3RR级别</h2><p>RR：Read Repeatable <strong>可重复读</strong>，<strong>在MVCC机制下可避免幻读</strong></p><h2 id="5-4Serializable"><a href="#5-4Serializable" class="headerlink" title="5.4Serializable"></a>5.4Serializable</h2><p>Serializable：<strong>串行化</strong>，最高的隔离级别，由加锁实现，最安全，性能最差<br>如果每条crud都加x锁，那么即便是不设置隔离级别为串行化，也是串行的</p><h1 id="6-锁：总结"><a href="#6-锁：总结" class="headerlink" title="6.锁：总结"></a>6.锁：总结</h1><ul><li>事务的<code>隔离性</code>是由锁实现的 （也可由MVCC）</li><li><strong>锁的互斥性需要相同类型的锁</strong>，比如间隙锁与插入意向锁同为gap锁，同类型的冲突保证了间隙不出现幻读；而真正表级的意向锁互相都是兼容的，不会相互阻塞，他仅作为一个提示</li><li></li></ul><h1 id="7-锁的概述"><a href="#7-锁的概述" class="headerlink" title="7.锁的概述"></a>7.锁的概述</h1><p>锁机制用于多个线程or进程并发访问某一个资源，保证数据的一致性和完整性。<br>锁机制保证了各个事务的隔离级别<br>锁机制一般不针对读-读，只针对读-写 、写-读 、写-写</p><h1 id="8-补：InnoDB的内存结构"><a href="#8-补：InnoDB的内存结构" class="headerlink" title="8.补：InnoDB的内存结构"></a>8.补：InnoDB的内存结构</h1><p><img src="https://img-blog.csdnimg.cn/a3142b47e0964d91b5c8c3e008e17589.png"></p><p><img src="https://img-blog.csdnimg.cn/5db385f9d8d645d68273214e751b6ffa.png"><img src="https://img-blog.csdnimg.cn/77bb4e2b7ea34215943f2f71e1535af6.png"></p><p><img src="https://img-blog.csdnimg.cn/377617355b2c4c268ad3faa83b5edbad.png"><img src="https://img-blog.csdnimg.cn/399dbcd17e0a4a5a971abc9d497c21b2.png"></p><h1 id="9-按操作类型-兼容性-划分"><a href="#9-按操作类型-兼容性-划分" class="headerlink" title="9.按操作类型(兼容性)划分"></a>9.按操作类型(兼容性)划分</h1><p>共享锁（读锁）（S锁）：<code>SELECT ... LOCK IN SHARE MODE</code>或<code>SELECT .. FOR SHARE</code><br>排他锁（写锁）（X锁）：<code>SELECT .. FOR UPDATE</code></p><ul><li>锁可以手动加，也可以自动加</li><li>这两种锁主要体现在兼容性（是否会相互阻塞）上，无论是行锁表锁、意向锁等等都存在兼容性问题<br><img src="https://img-blog.csdnimg.cn/fb551713969e4aeca3fa14b689e04ecd.png"></li><li>兼容性不是一成不变的，<strong>表锁的兼容性与行锁的就不同</strong>。</li><li><em>同一个事务中</em>*<br>行锁：不会互相影响，即同一事务可以同时SELECT 又 UPDATE<br>表锁：独占的，本事务加S表锁，则不能在本事务中UPDATE</li></ul><h2 id="9-1读"><a href="#9-1读" class="headerlink" title="9.1读"></a>9.1读</h2><p>读没什么好说的</p><h2 id="9-2写"><a href="#9-2写" class="headerlink" title="9.2写"></a>9.2写</h2><h3 id="9-2-1-insert"><a href="#9-2-1-insert" class="headerlink" title="9.2.1 insert"></a>9.2.1 insert</h3><p>由<code>隐式锁</code>保护，<strong>保证新数据在commit之前不会被其他事务访问</strong></p><h3 id="9-2-2-delete"><a href="#9-2-2-delete" class="headerlink" title="9.2.2 delete"></a>9.2.2 delete</h3><p>从B+树找到该条记录的位置，获取这条记录的X锁，执行delete mark软删。真正的删除是purge线程删除</p><h3 id="9-2-3-update"><a href="#9-2-3-update" class="headerlink" title="9.2.3 update"></a>9.2.3 update</h3><p>分为3种情况</p><ul><li>情况1：未修改主键，且更新后存储空间<strong>不变</strong>：定位——获取X锁——在原记录的位置上修改</li><li>情况2：未修改主键，但更新后存储空间<strong>改变</strong>：定位——获取X锁——删除原数据，<strong>再insert（隐式锁）</strong></li><li>情况3：修改了主键：类似情况2，先delete再insert</li></ul><h1 id="10-按粒度划分"><a href="#10-按粒度划分" class="headerlink" title="10.按粒度划分"></a>10.按粒度划分</h1><ul><li>锁粒度越小（锁定的少），并发性越好，但资源消耗更大</li></ul><h2 id="10-1表锁"><a href="#10-1表锁" class="headerlink" title="10.1表锁"></a>10.1表锁</h2><h3 id="10-1-1表级S锁与X锁"><a href="#10-1-1表级S锁与X锁" class="headerlink" title="10.1.1表级S锁与X锁"></a>10.1.1表级S锁与X锁</h3><ul><li><p>没有死锁问题</p></li><li><p>表锁也有S锁和X锁，但是兼容性与行锁不同：具体体现在如下两点<br><img src="https://img-blog.csdnimg.cn/94af8e0a0407413db3ce008bfe79b54f.png"></p></li><li><p>语法演示：</p><pre><code>  begin;  lock tables xxx read; #也可以加write锁  show open tables where in_use &gt; 0; #查看加锁的表  SELECT * FROM xxx ; # 正常可以查  UPDATE xxx SET s1 = 111  WHERE ... ;#阻塞，因为加了S表锁，所以同一事务也不能写当前表  unlock tables;#也可以直接commit; 都是释放表锁</code></pre></li></ul><h3 id="10-1-2意向锁intention-lock-多粒度锁支持-加行锁时自动添加表级意向锁"><a href="#10-1-2意向锁intention-lock-多粒度锁支持-加行锁时自动添加表级意向锁" class="headerlink" title="10.1.2意向锁intention lock(多粒度锁支持)(加行锁时自动添加表级意向锁)"></a>10.1.2意向锁intention lock(多粒度锁支持)(加行锁时自动添加表级意向锁)</h3><ul><li>InnoDB支持多粒度锁（允许行锁表锁共存）。而<strong>意向锁就是一种表锁</strong></li><li>意向锁由存储引擎自己维护，用户无法操作。当添加<strong>行锁</strong>的时候，自动生成这个<strong>表级别的意向锁</strong></li><li><strong>意向锁不会锁住这个表</strong>，他只是告诉其他表“<strong>有其他事务锁住了表中的某些记录</strong>”</li></ul><p>如果事务想要获得数据表中<strong>某些记录</strong>的<strong>共享S锁</strong>，就需要在数据<strong>表</strong>上添加<strong>意向共享S锁</strong>。<br>如果事务想要获得数据表中<strong>某些记录</strong>的<strong>排他X锁</strong>，就需要在数据<strong>表</strong>上添加<strong>意向排他X锁</strong>。</p><ul><li>意向锁互相兼容（也可以看作意向锁与行锁相互兼容）<br><img src="https://img-blog.csdnimg.cn/37629e64af5d4b0a85047941f4737e3e.png"></li><li>意向锁与<strong>表锁</strong>存在不兼容情况<br><img src="https://img-blog.csdnimg.cn/f38c426a765e45818115c2040e01e1f9.png"><img src="https://img-blog.csdnimg.cn/61d05a11722a4cd39639cbcd9d275798.png"></li></ul><h3 id="10-1-3自增锁AUTO-INC"><a href="#10-1-3自增锁AUTO-INC" class="headerlink" title="10.1.3自增锁AUTO-INC"></a>10.1.3自增锁AUTO-INC</h3><p>如果主键设置的是auto_increment，那么就有这个自增锁，<strong>当一个事务持有自增锁的时候，其他事务的insert语句都会被阻塞。</strong>如果innoDB知道要插入多少条数据则不会上自增锁</p><ul><li>能明确知道插入的行数：例如insert into xx ..value(),(),()</li><li>不能明确知道插入的行数：例如从其他表查<code>insert...select</code> 或 <code>replace...select</code>  或<code>load data</code>或混合模式</li></ul><h3 id="10-1-4元数据锁meta-data-lock"><a href="#10-1-4元数据锁meta-data-lock" class="headerlink" title="10.1.4元数据锁meta data lock"></a>10.1.4元数据锁meta data lock</h3><ul><li>这个锁是表级别的，是为了防止crud DML的途中<strong>其他事务修改表结构</strong></li><li> crud DML的时候加MDL读锁，修改表结构DDL的时候加MDL写锁。读-读不互斥</li><li>对用户透明，自动添加</li></ul><h2 id="10-2行锁"><a href="#10-2行锁" class="headerlink" title="10.2行锁"></a>10.2行锁</h2><p>行锁在存储引擎层实现，粒度小，开销大，更容易出现死锁，并发度高<br>对于行锁的监控方法如下</p><p><img src="https://img-blog.csdnimg.cn/8fd568b351e3472f8ade4bf64fc9c8b5.png"><br><img src="https://img-blog.csdnimg.cn/19b3af1633fc4eb8b06fa5e9ca660a05.png"><img src="https://img-blog.csdnimg.cn/910c2321bfbc4c3eae19989bd882f3d1.png"></p><h3 id="10-2-1记录锁record-locks"><a href="#10-2-1记录锁record-locks" class="headerlink" title="10.2.1记录锁record locks"></a>10.2.1记录锁record locks</h3><p>这个就是可以自行添加，或在非RU级别下自动添加的锁，是狭义上的行锁</p><h3 id="10-2-2间隙锁gap-lock"><a href="#10-2-2间隙锁gap-lock" class="headerlink" title="10.2.2间隙锁gap lock"></a>10.2.2间隙锁gap lock</h3><ul><li>gap lock的提出仅仅是为了防止<strong>幻读</strong>，防止在间隙写入数据</li><li>gap lock可能是由next_key locks退化而来</li><li>我个人更倾向于：间隙锁是临键锁的组成成分，而保证间隙锁的必要条件是<code>索引</code>，因为只有索引才能保证确定这个间隙锁的范围</li><li>如何触发间隙锁？：<strong>有索引</strong>，<code>范围查询or查不存在的值</code></li></ul><h3 id="10-2-3临键锁next-key-locks"><a href="#10-2-3临键锁next-key-locks" class="headerlink" title="10.2.3临键锁next_key locks"></a>10.2.3临键锁next_key locks</h3><ul><li>默认情况下，InnoDB在REPEATABLE READ事务隔离级别运行，InnoDB使用next-key锁进行<strong>搜索和索引扫描，以防止幻读。</strong></li><li><code>临键锁 =  gap锁 + 记录锁  </code></li><li>例如 SELCT * FROM xxx WHERE age &lt;= 10 and age &gt; 5 （for update）这样加S锁（或X锁），因为有索引存在，（5,10]上的数据是不允许被其他事务插入的，从而防止了幻读</li></ul><h3 id="10-2-4插入意向锁insert-intention-locks"><a href="#10-2-4插入意向锁insert-intention-locks" class="headerlink" title="10.2.4插入意向锁insert intention locks"></a>10.2.4插入意向锁insert intention locks</h3><ul><li>这个锁是一个gap锁，而不是意向锁。</li><li>因为其他事务需要保证间隙锁生效，<strong>因此需要一个同类型的锁来进行判断，所以引出了插入意向锁用于判断是否冲突</strong></li></ul><h2 id="10-3页锁"><a href="#10-3页锁" class="headerlink" title="10.3页锁"></a>10.3页锁</h2><ul><li>行锁与表锁的折中粒度锁，并发度一般，也会出现死锁</li><li>InnoDB一般用不到页锁</li><li><strong>锁空间占满了，自动进行了锁升级</strong>，比如delete太多数据会导致锁表</li></ul><h1 id="11-按态度划分"><a href="#11-按态度划分" class="headerlink" title="11.按态度划分"></a>11.按态度划分</h1><h2 id="11-1乐观锁"><a href="#11-1乐观锁" class="headerlink" title="11.1乐观锁"></a>11.1乐观锁</h2><ul><li>通过程序代码实现，而不采用数据库的锁机制</li><li>例如CAS机制、版本号机制（如where xxx = #{xxx}比如对update_time的时间戳进行校验）</li></ul><h2 id="11-2悲观锁"><a href="#11-2悲观锁" class="headerlink" title="11.2悲观锁"></a>11.2悲观锁</h2><ul><li>像Java中的<code>synchronized和ReentantLock</code>等等<code>独占锁</code>都是悲观锁实现</li><li>在MySQL中使用悲观锁<strong>一定需要索引</strong>，否则会导致锁表（全表扫描）</li><li>如果事务太长（锁开销过高），推荐使用乐观锁</li></ul><h1 id="12-加锁方式"><a href="#12-加锁方式" class="headerlink" title="12.加锁方式"></a>12.加锁方式</h1><h2 id="12-1隐式锁"><a href="#12-1隐式锁" class="headerlink" title="12.1隐式锁"></a>12.1隐式锁</h2><p>隐式锁是没有指令可以查看的，当且仅当产生锁等待的时候转为显示锁</p><p><img src="https://img-blog.csdnimg.cn/81d18400a69c40c2b8c231afab322b9c.png"></p><h2 id="12-2显示锁"><a href="#12-2显示锁" class="headerlink" title="12.2显示锁"></a>12.2显示锁</h2><p>上面能查看的锁都是显示锁</p><h1 id="13-其他"><a href="#13-其他" class="headerlink" title="13.其他"></a>13.其他</h1><h2 id="13-1全局锁"><a href="#13-1全局锁" class="headerlink" title="13.1全局锁"></a>13.1全局锁</h2><ul><li>对整个数据加锁：例如在全库逻辑备份的时候，整个数据库都是只读状态</li><li>粒度最大的锁</li></ul><h2 id="13-2死锁"><a href="#13-2死锁" class="headerlink" title="13.2死锁"></a>13.2死锁</h2><h3 id="13-2-1产生条件"><a href="#13-2-1产生条件" class="headerlink" title="13.2.1产生条件"></a>13.2.1产生条件</h3><ul><li>两个or以上的事务</li><li>每个事务都已经持有锁，并且正在申请新的锁</li><li>锁在不同的事务间不兼容</li><li>关键在于：<strong>加锁的顺序不一致</strong></li></ul><h3 id="13-2-2如何处理死锁"><a href="#13-2-2如何处理死锁" class="headerlink" title="13.2.2如何处理死锁"></a>13.2.2如何处理死锁</h3><p>存储引擎层面：</p><ul><li>等待，直到超时：默认的innodb_lock_wait_timeout=50s，这个时间可以自己设置，如果太短也会误伤正常锁等待</li><li>死锁检测：存储引擎自动检查事务是否产生回路（死锁），回滚undo量最小的事务。<strong>但是这个方法每次遇到阻塞都去检测，并发量高的情况下检测回路的开销特别大</strong>，也可以自行关闭</li></ul><p>业务设计层面：</p><ul><li>控制并发量：例如使用MQ</li><li>调整SQL业务顺序，避免update和delete在事务的开头占据太长时间</li><li>将大事务拆分为小事务</li></ul><p>数据库设计层面：</p><ul><li>合理设计索引，减少锁竞争</li><li>降低隔离级别，且尽量不要显示加锁。（例如有MVCC的存在，可以将RR调整为RC，避免gap lock造成的死锁）</li></ul><h1 id="14-MVCC"><a href="#14-MVCC" class="headerlink" title="14.MVCC"></a>14.MVCC</h1><ul><li>MVCC:多版本并发控制，与锁机制共同保证了事务的隔离性</li><li>依赖于数据库每行记录中的<code>三个隐藏字段</code>、<code>undo log</code>、<code>readView</code></li><li>在MySQL的InnoDB中，依赖于MVCC，<code>RR(REPEATABLE READ)</code>隔离级别下解决了幻读问题（如果没有MVCC机制则需要串行化or全加X锁才能解决幻读）</li><li>MVCC在RR级别和RC级别都是有效的，区别在于<code>ReadView</code>对于undo log的判断规则。只是后者不能解决幻读问题。<strong>MVCC保证的是读，锁保证的是写，因为写永远是针对最新的版本。</strong></li></ul><p><img src="https://img-blog.csdnimg.cn/848e9bb938f74a488cd5e76484c4a6fd.png"></p><h2 id="14-1当前读、快照读"><a href="#14-1当前读、快照读" class="headerlink" title="14.1当前读、快照读"></a>14.1当前读、快照读</h2><p>快照读的前提是<strong>不能是串行化</strong>，串行化下快照读退化为当前读<br><img src="https://img-blog.csdnimg.cn/aba4d84e165a4c17b741561cb154a39c.png"></p><h2 id="14-2MVCC实现原理"><a href="#14-2MVCC实现原理" class="headerlink" title="14.2MVCC实现原理"></a>14.2MVCC实现原理</h2><h3 id="14-2-1undo-log版本链"><a href="#14-2-1undo-log版本链" class="headerlink" title="14.2.1undo log版本链"></a>14.2.1undo log版本链</h3><p>每次事务修改这条记录，都会产生一个版本，版本中的隐藏列DB_ROLL_PTR指针又形成了undo log版本链<br><img src="https://img-blog.csdnimg.cn/c90f31a47bda43408606a4be6c4ca21d.png"></p><h3 id="14-2-2readView"><a href="#14-2-2readView" class="headerlink" title="14.2.2readView"></a>14.2.2readView</h3><p>这里面包含的四个字段，都是事务id相关的，他们共同决定了在读取undo log版本链的时候究竟是读哪个版本的数据。并且跟隔离级别也有关系</p><p><img src="https://img-blog.csdnimg.cn/ebf094ebf632406892dbbc4a085e3b39.png"><br><img src="https://img-blog.csdnimg.cn/5804adb358f34b83bf6f767daeb3b479.png"><br><img src="https://img-blog.csdnimg.cn/c62ecd17a1f5460aa0e115c238963a31.png"></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>AOP实现分布式锁</title>
      <link href="/zjh/2022/08/23/AOP%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>/zjh/2022/08/23/AOP%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h1 id="1-使用示例"><a href="#1-使用示例" class="headerlink" title="1.使用示例"></a>1.使用示例</h1><ul><li>可以对整个接口加锁，也可以对某一个业务方法加锁</li><li>必须指定锁的key值，为避免冲突最好使用枚举</li><li>可选锁等待时间waitTime、超时时间leaseTime、单位timeUnit</li><li>关于AOP代码中“获取注解信息”也可以再封装为一个方法，这里就不写了</li></ul><pre><code>  @GetMapping(&quot;lock&quot;)  @RedissonLock(lockKey = &quot;lock1&quot;)  public Integer getAop(String s1 , String s2)&#123;    System.out.println(&quot;阻塞？&quot;+s1+s2);    if(&quot;ex&quot;.equals(s1))&#123;//模拟异常            throw new RuntimeException();    &#125;    return 1;  &#125;</code></pre><h1 id="2-AOP实现"><a href="#2-AOP实现" class="headerlink" title="2.AOP实现"></a>2.AOP实现</h1><h2 id="2-1注解"><a href="#2-1注解" class="headerlink" title="2.1注解"></a>2.1注解</h2><pre><code>@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)public @interface RedissonLock &#123;  /**   * 锁标识   */  String lockKey();  /**   * 时间单位，默认秒   */  TimeUnit timeUnit() default TimeUnit.SECONDS;  /**   * 锁等待时间   */  int waitTime() default 10;  /**   * 锁超时时间   */  int leaseTime() default 60;&#125;</code></pre><h2 id="2-2AOP"><a href="#2-2AOP" class="headerlink" title="2.2AOP"></a>2.2AOP</h2><pre><code>@Aspect@Componentpublic class RedissonLockAspect &#123;  @Autowired  private RedissonClient redissonClient;  @Before(value = &quot;@annotation(RedissonLock)&quot;)  public void beforeAspect(JoinPoint jp) throws RuntimeException, NoSuchMethodException &#123;    MethodSignature signature = (MethodSignature) jp.getSignature();    Class[]         parameterTypes = signature.getParameterTypes();    String          name = signature.getName();    Object target = jp.getTarget();    //用target.getClass()获得的是一个类对象的实例，不同于Class.forName();因此可以获取指定的注解信息    Method   method = target.getClass().getMethod(name, parameterTypes);    RedissonLock annotation = method.getAnnotation(RedissonLock.class);    boolean flag = tryLock(annotation.lockKey(), annotation.timeUnit(), annotation.waitTime(), annotation.leaseTime());    if(!flag)&#123;      //可添加日志记录      throw new RuntimeException(&quot;业务繁忙，分布式锁获取失败&quot;);    &#125;  &#125;  @AfterReturning(value = &quot;@annotation(RedissonLock)&quot;)  public void afterAspect(JoinPoint jp) throws NoSuchMethodException &#123;    MethodSignature signature = (MethodSignature) jp.getSignature();    Class[]         parameterTypes = signature.getParameterTypes();    String          name = signature.getName();    Object target = jp.getTarget();    //用target.getClass()获得的是一个类对象的实例，不同于Class.forName();因此可以获取指定的注解信息    Method   method = target.getClass().getMethod(name, parameterTypes);    RedissonLock annotation = method.getAnnotation(RedissonLock.class);    unLock(annotation.lockKey());  &#125;  @AfterThrowing(value = &quot;@annotation(RedissonLock)&quot;, throwing = &quot;ex&quot;)  public void afterThrowing(JoinPoint jp, Throwable ex) throws NoSuchMethodException &#123;    //先释放锁    MethodSignature signature = (MethodSignature) jp.getSignature();    Class[]         parameterTypes = signature.getParameterTypes();    String          name = signature.getName();    Object target = jp.getTarget();    Method   method = target.getClass().getMethod(name, parameterTypes);    RedissonLock annotation = method.getAnnotation(RedissonLock.class);    unLock(annotation.lockKey());    //然后追加一些日志记录    System.out.println(&quot;日志记录&quot;);  &#125;  public boolean tryLock(String lockKey, TimeUnit unit, int waitTime, int leaseTime) &#123;    try &#123;      RLock lock = redissonClient.getLock(lockKey);      if (Objects.nonNull(lock)) &#123;        return lock.tryLock(waitTime, leaseTime, unit);      &#125; else &#123;        return false;      &#125;    &#125; catch (InterruptedException e) &#123;     //可添加日志记录      return false;    &#125;  &#125;  public void unLock(String lockKey)&#123;    try &#123;      RLock lock = redissonClient.getLock(lockKey);      //可能存在锁过期等问题      if (Objects.nonNull(lock) &amp;&amp; lock.isLocked() &amp;&amp; lock.isHeldByCurrentThread()) &#123;        lock.unlock();      &#125;    &#125; catch (Exception e) &#123;      //解锁出错一般不会导致严重业务问题，例如阻塞，这里可以添加日志记录    &#125;  &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>ReentrantLock源码剖析</title>
      <link href="/zjh/2022/08/23/ReentrantLock%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
      <url>/zjh/2022/08/23/ReentrantLock%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="1-源码分析总结"><a href="#1-源码分析总结" class="headerlink" title="1.源码分析总结"></a>1.源码分析总结</h1><p>这里把结论提前放这里：</p><ul><li>AQS是一个抽象类，包含了Node（用于维护<strong>同步队列</strong>）、ConditionObject（也用Node维护了<strong>等待队列</strong>，给ReentrantLock提供更高的自由度，可由<code>reentrantLock.newCondition()</code>创建）</li><li>CAS（乐观锁的一种实现，本身与自旋锁无关）是通过比较属性的<code>offset</code>偏移量来实现原子性操作，一般<strong>配合while()或者for(;;)实现自旋锁</strong>，如果只是想尝试一次获取锁，那么就不需要循环，只需要保证原子性即可</li><li>自旋锁只是不停尝试，真正执行语句的原子性需要CAS保证，<strong>自旋锁也一般配合阻塞实现</strong></li><li>公平锁和非公平锁<strong>都用Node维护了2个双端队列</strong>，不过只有公平锁在争锁的时候会先<strong>判断是不是队列的头节点</strong>，一旦进入队列仍然是有序的</li><li><code> reentrantLock.lock()</code>和<code>condition.await()</code>底层都同时做了两件事：将节点放入队列、在<code>for(;;)</code>自旋锁中调用<code>LockSupport.park()</code>来阻塞线程，<strong>暂停自旋,防止消耗cpu资源</strong>，有且仅有同步队列的第二个节点在自旋</li><li> <code> reentrantLock.unlock()</code>和<code>condition.signal()</code>底层都同时做了两件事：从自己维护的队列中取出头节点（即便是非公平锁也是取头节点）、底层调用<code>LockSupport.park()</code>来唤醒对应的线程</li><li>由此可见，<strong>ReentrantLock的非公平锁并不是真正意义上的非公平，他只是在第一次获取锁的时候非公平，一旦进入同步队列，还是得乖乖排队</strong></li><li>源码中大量使用了if( &amp;&amp; ) 的短路功能，来简化代码</li><li>关于<code>LockSupport.park()</code>，底层就是阻塞线程，lock失败、awiat都用到了他。同理unpark在unlock和signal中被使用，用于唤醒指定线程（唤醒等待队列的头节点）</li><li>关于<strong>同步队列与等待队列</strong>，其实<code>lock和unlock操作的是同步队列</code>（即使源码注释只提到了等待队列），而awati和signal分别是“<code>将同步队列节点移到等待队列</code>”，“<code>将等待列队节点移到同步队列</code>”————在第6点中细讲</li></ul><h1 id="2-ReentrantLock大体思路"><a href="#2-ReentrantLock大体思路" class="headerlink" title="2.ReentrantLock大体思路"></a>2.ReentrantLock大体思路</h1><ul><li>已知 lock()在没有抢到锁的时候会导致线程阻塞，那么可以猜测相关的线程挂起逻辑是<code>while(true) for(;;) </code>自旋 +<code> park()</code>阻塞，等待别人<code>unpark()</code>唤醒后继续自旋</li><li>Java中调用CAS(<strong>乐观锁，底层是原子操作</strong>)是在Usafe类下的native方法，而这个<code>state</code>的值在CAS锁机制下使用的参数是<code>stateOffset</code>偏移量，效果相同，例如<code>unsafe.objectFieldOffset</code>获取偏移量，然后<code>usafe.compareAndSwapInt</code>执行原子指令</li><li>利用形如<code>while( !unsafe.compareAndSwapInt(this, stateOffset, 0 ,1 ))</code>来实现自旋锁，直到加到锁，其中原子性是由CAS（一种乐观锁实现）来保证的</li></ul><h2 id="2-1CAS实现一个简单的自旋锁"><a href="#2-1CAS实现一个简单的自旋锁" class="headerlink" title="2.1CAS实现一个简单的自旋锁"></a>2.1CAS实现一个简单的自旋锁</h2><ul><li>用while + cas 可以实现一个<strong>自旋锁</strong>（自旋的思想就是不停重试）</li><li>但是一直while很消耗cpu资源</li><li>因此，<strong>我们不能让所有等待线程都while，在源码中使用park进行阻塞自旋</strong><h3 id="2-1-1-Unsafe类的使用demo"><a href="#2-1-1-Unsafe类的使用demo" class="headerlink" title="2.1.1 Unsafe类的使用demo"></a>2.1.1 Unsafe类的使用demo</h3></li></ul><pre><code>public class AQSTest &#123;  public static void main(String[] args) &#123;    AQSTest aqsTest = new AQSTest();    aqsTest.test();  &#125;  public void test()&#123;    System.out.println(state);//0    Unsafe unsafe = getUnsafe();    boolean b     = unsafe.compareAndSwapInt(this, stateOffset, 0, 1);    System.out.println(state);//1  &#125;    private volatile int state = 0;//状态0则没加锁，volatile防止指令重排  private static final Unsafe unsafe = getUnsafe();//import sun.misc.Unsafe;  //偏移量，即在计算机中定位到state的位置，以便于原子操作  private static Long stateOffset;  //用静态代码块捕获异常，如果直接定义private static Long stateOffset =  // unsafe.objectFieldOffset(AQSTest.class.getDeclaredField(&quot;state&quot;));  //那么则会在空参构造上抛出异常  static &#123;    try &#123;      stateOffset = unsafe.objectFieldOffset(AQSTest.class.getDeclaredField(&quot;state&quot;));    &#125; catch (NoSuchFieldException e) &#123;      e.printStackTrace();    &#125;  &#125;  //获取unsafe对象  private static Unsafe getUnsafe()&#123;    try &#123;      Field field = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);      field.setAccessible(true);      return (Unsafe) field.get(null);    &#125; catch (NoSuchFieldException e) &#123;      e.printStackTrace();    &#125; catch (IllegalAccessException e) &#123;      e.printStackTrace();    &#125;    return null;  &#125;&#125;</code></pre><h3 id="2-1-2lock和unlock"><a href="#2-1-2lock和unlock" class="headerlink" title="2.1.2lock和unlock"></a>2.1.2lock和unlock</h3><p>加锁解锁方法:</p><pre><code>  public void lock()&#123;    Unsafe unsafe = getUnsafe();    while ( !unsafe.compareAndSwapInt(this,stateOffset,0,1) )&#123;      System.out.println(Thread.currentThread().getName() + &quot;尝试获取锁&quot;);      try &#123;        TimeUnit.SECONDS.sleep(1);      &#125; catch (InterruptedException e) &#123;        e.printStackTrace();      &#125;    &#125;    System.out.println(Thread.currentThread().getName() + &quot;获取锁成功&quot;);  &#125;  public void unlock()&#123;    Unsafe unsafe = getUnsafe();    boolean flag     = unsafe.compareAndSwapInt(this, stateOffset, 1, 0);    if(flag)&#123;      System.out.println(&quot;解锁成功&quot;);    &#125;  &#125;</code></pre><h3 id="2-1-3两个线程测试"><a href="#2-1-3两个线程测试" class="headerlink" title="2.1.3两个线程测试"></a>2.1.3两个线程测试</h3><p>main中开启两个线程：</p><pre><code>AQSTest t = new AQSTest();new Thread(()-&gt;&#123;  System.out.println(&quot;线程1开始,上锁&quot;);  t.lock();  try &#123;    TimeUnit.SECONDS.sleep(3);  &#125; catch (InterruptedException e) &#123;    e.printStackTrace();  &#125;  //3秒后释放锁  t.unlock();&#125;,&quot;线程1&quot;).start();new Thread(()-&gt;&#123;  System.out.println(&quot;线程2开始&quot;);  t.lock();  t.unlock();&#125;,&quot;线程2&quot;).start();</code></pre><p>输出：</p><p><img src="https://img-blog.csdnimg.cn/0cd0d31e4b724f7e904b697d3b60b078.png"></p><h1 id="3-AQS下的两个类"><a href="#3-AQS下的两个类" class="headerlink" title="3.AQS下的两个类"></a>3.AQS下的两个类</h1><p><img src="https://img-blog.csdnimg.cn/e9763c7896d04f1ea70a3942dd8fd362.png"></p><h2 id="3-1Node节点（双端队列）"><a href="#3-1Node节点（双端队列）" class="headerlink" title="3.1Node节点（双端队列）"></a>3.1Node节点（双端队列）</h2><ul><li>这几个状态值在lock、await  unlock、signal中都是不同的，起到一个状态对应的作用，也用于判断是否可以唤醒线程</li><li>每个ReentrantLock中维护着一个Node对象（相应的维护了一个双端队列）</li><li>每个Condition中也维护着一个Node对象（同上，一个condition可以对应await在很多地方），因此可以实现指定唤醒</li><li>Node中的属性Thread非常重要，由于底层的unpark方法唤醒的是指定线程，<strong>在源码中的逻辑是：unpark()唤醒同步队列中的头节点head.thread线程</strong><br><img src="https://img-blog.csdnimg.cn/ea516a10a19841f38dfbb596b016b811.png"></li></ul><h2 id="3-2ConditionObject"><a href="#3-2ConditionObject" class="headerlink" title="3.2ConditionObject"></a>3.2ConditionObject</h2><p>主要是使用这两个方法，其内部也用到了上述双端队列，并且在大题执行逻辑上</p><ul><li>signal()与lock()相似，底层都是调用<code> LockSupport.unpark(node.thread);</code></li><li>await()与unlock()<strong>被阻塞</strong>相似，底层都是<code>LockSupport.park(this);</code></li><li>正是由于使用<code>Condition</code>类，在阻塞、唤醒的操作上比传统多线程提高了很多灵活性</li><li>在传统的多线程中，使用<code>notify()</code>、<code>notifyAll()</code>、<code>wait()</code>来<strong>唤醒其他线程</strong> 和 <strong>阻塞自己并进入等待队列，等待唤醒后进入同步队列</strong>，在JUC编程中使用<code>await()</code>替换了Object类中的wait,<code>signal()</code>替换Object中的notify</li></ul><p><img src="https://img-blog.csdnimg.cn/3fe9366cb11b4edd9cf9959f9b920b76.png"></p><h2 id="3-2-1signal-指定唤醒等待队列头节点"><a href="#3-2-1signal-指定唤醒等待队列头节点" class="headerlink" title="3.2.1signal()指定唤醒等待队列头节点"></a>3.2.1signal()指定唤醒等待队列头节点</h2><p><img src="https://img-blog.csdnimg.cn/c2e3dcc3d8e54a3cbae3b4a095bf2ef2.png">其中doSIgnal()底层调用的就是<code>LockSupport.unpark(node.thread);</code></p><h2 id="3-2-2await-阻塞进入等待队列"><a href="#3-2-2await-阻塞进入等待队列" class="headerlink" title="3.2.2await()阻塞进入等待队列"></a>3.2.2await()阻塞进入等待队列</h2><p><strong>着重需要注意的是：调用condition.await()很容易写成condition.wait()从而报错</strong><br>这个方法与unlock调用的都是<code>tryRelease()</code>，底层也都是unpark()<br>因为Condition类的存在，await()变得异常灵活，我们可以在不同的线程用同一个condition调用await()，其等待队列维护在这个condition对象中，可以被signal()给唤醒</p><p><img src="https://img-blog.csdnimg.cn/3c939cf2b4f64e17acefbd3e32265ada.png"></p><p>关于同步队列、等待队列的内容在第6号标题</p><p><img src="https://img-blog.csdnimg.cn/14818daac6ab453db15015500855457e.png"><br><img src="https://img-blog.csdnimg.cn/bb371c8836d3439ca8a50ef0a8cb49d1.png"></p><h1 id="4-lock源码分析"><a href="#4-lock源码分析" class="headerlink" title="4.lock源码分析"></a>4.lock源码分析</h1><ul><li>lock有两个实现  公平和非公平</li><li>两者的区别在于第一步tryAcquire，而第二步acquireQueued二者都是相同的（<strong>这也同时证明了非公平锁并不是真正意义上的公平</strong>）</li><li><em>二者都维护了等待队列，但在获取锁时只有公平锁使用的队列顺序</em>*</li><li>非公平锁<strong>第一次加锁不考虑队列</strong>，会尝试两次锁（失败后进入等待队列）</li></ul><p><img src="https://img-blog.csdnimg.cn/e689244922b74bc78c1ea1f3b7078c86.png" alt="加锁失败后会打断自己"></p><h2 id="4-1-amp-amp-的左边条件tryAcquire"><a href="#4-1-amp-amp-的左边条件tryAcquire" class="headerlink" title="4.1&amp;&amp;的左边条件tryAcquire"></a>4.1&amp;&amp;的左边条件tryAcquire</h2><ul><li><p>在这个&amp;&amp;的前半块，在<code>tryAcquire </code>中，<strong>公平锁要先判断是不是队列队头，而非公平锁是直接cas抢锁</strong>（当然因为没有循环，只会获取一次，如果没抢到就算了）<br><img src="https://img-blog.csdnimg.cn/ec889af94870461fa875bdf58e623e68.png"></p></li><li><p>关于排队<code>hasQueuedPredecessors</code>，详细内容如下（考虑了并发问题）<img src="https://img-blog.csdnimg.cn/d69c0f216eec422dbd082c8e1129e98f.png"></p><h2 id="4-2-amp-amp-的右边条件acquireQueued"><a href="#4-2-amp-amp-的右边条件acquireQueued" class="headerlink" title="4.2&amp;&amp;的右边条件acquireQueued"></a>4.2&amp;&amp;的右边条件acquireQueued</h2></li></ul><p>在这里面公平锁与非公平锁都一样，都是使用了：<br><strong>自旋锁 + park阻塞 + unpark唤醒 + 同步队列FIFO</strong> 的策略</p><h3 id="4-2-1-addWaiter维护同步队列"><a href="#4-2-1-addWaiter维护同步队列" class="headerlink" title="4.2.1 addWaiter维护同步队列"></a>4.2.1 addWaiter维护同步队列</h3><p>（这里源码中的等待队列其实<strong>本质是同步队列</strong>，相关内容在第6号标题中）</p><p>那么非公平锁是否有维护这个队列呢？在&amp;&amp;的后半块：我们在<code>addWaiter()</code>的方法打个断点，分别测试公平锁和非公平锁，发现都会进来，就证明<strong>其实二者都维护了同步队列</strong>（只有公平锁加锁时用<code>hasQueuedPredecessors</code>判断是否是队列头）<br><img src="https://img-blog.csdnimg.cn/d51949a4212f41cd849f9167892a7cb7.png">debug后发现，对于<code>addWaiter同步队列</code>，二者的流程一致。不得不说这个addWaiter设计十分精妙，<strong>enq(Node node)方法的自旋锁完全考虑了队列为空、创建队列时被插入、新增节点时可能遇到的所有并发问题</strong><br><img src="https://img-blog.csdnimg.cn/c60fee28abec4502a7bc429f25714225.png"><img src="https://img-blog.csdnimg.cn/f5180873882741ad807cebbd357dfc9e.png" alt="自旋保证节点成功添加到队列中"></p><h3 id="4-2-2acquireQueued获取同步队列"><a href="#4-2-2acquireQueued获取同步队列" class="headerlink" title="4.2.2acquireQueued获取同步队列"></a>4.2.2acquireQueued获取同步队列</h3><p>刚刚分析到了加锁失败后，这里形参是刚刚生成的节点，这里最重要的是这个打框的地方，<code>shouldParkAfterFailedAcquire(pre,node)</code>是一个should开头的疑问句，作用是<strong>判断当前节点是不是下一个执行节点</strong>，如果是的话则执行<code>parkAndCheckInterrupt()</code>阻塞<br><strong>而在for(;;)中是自旋的，这里阻塞了可以减少循环消耗cpu资源，也能被上一个节点成功唤醒</strong><br><img src="https://img-blog.csdnimg.cn/0825b54af554421fa85c78d915261cdc.png">因为被<code>parkAndCheckInterrupt()</code>阻塞了，停止了循环，当上一个节点唤醒当前节点后解除阻塞，继续循环，尝试加锁（非公平锁仍有可能抢不过————<strong>存在虽然被唤醒但竞争失败的情况</strong>）</p><h3 id="4-2-3-parkAndCheckInterrupt方法"><a href="#4-2-3-parkAndCheckInterrupt方法" class="headerlink" title="4.2.3 parkAndCheckInterrupt方法"></a>4.2.3 parkAndCheckInterrupt方法</h3><p>关于LockSupport.park方法，这里参考<a href="https://blog.csdn.net/a7980718/article/details/83661613">参考链接</a>，park是一个native方法，<strong>可以实现精准唤醒（配合队列可以指定唤醒某一个节点）</strong>，其中公平锁非公平锁都用了相同逻辑的同步队列</p><p><img src="https://img-blog.csdnimg.cn/4fdc7bd52bdd41299be58193331ad315.png"></p><h1 id="5-unlock源码分析"><a href="#5-unlock源码分析" class="headerlink" title="5.unlock源码分析"></a>5.unlock源码分析</h1><h2 id="5-1源码浅析"><a href="#5-1源码浅析" class="headerlink" title="5.1源码浅析"></a>5.1源码浅析</h2><p>unlock调的都是同一个<code>release()</code>方法<br><img src="https://img-blog.csdnimg.cn/769e9e42e82c4304b436c8b67f04c3a5.png">这里调用unpark去唤醒下一个节点，下一个节点那边接触阻塞</p><p><img src="https://img-blog.csdnimg.cn/324ebc43c92341f6a847b93fac89c18e.png"></p><h2 id="5-2使用示例"><a href="#5-2使用示例" class="headerlink" title="5.2使用示例"></a>5.2使用示例</h2><p>这个案例主要是探究await()阻塞、</p><p><img src="https://img-blog.csdnimg.cn/38aab27ea2c04426a9a069387f177f80.png"></p><h1 id="6-同步队列、等待队列"><a href="#6-同步队列、等待队列" class="headerlink" title="6.同步队列、等待队列"></a>6.同步队列、等待队列</h1><ul><li>首先：同步队列的优先级高于等待队列，<strong>同步队列决定接下来执行哪个线程</strong>。</li><li>例如：<strong>有多个condition等待队列存在的情况下</strong>，需要先通过signal扔进同步队列才能确定线程的最终执行顺序</li></ul><h2 id="6-1同步队列"><a href="#6-1同步队列" class="headerlink" title="6.1同步队列"></a>6.1同步队列</h2><ul><li>使用reentrantLock.lock()时，当前线程进入的是<code>同步队列</code>，如果阻塞也是阻塞在同步队列</li><li>使用reentrantLock.unlock()会将当前节点（线程）从<code>同步队列</code>剔除，释放锁，并通知下一个节点（<code>LockSupport.unpark()</code>）</li></ul><p><img src="https://img-blog.csdnimg.cn/f79e1caf91134c56b13c2ec01bcc3a7d.png"></p><h2 id="6-2等待队列"><a href="#6-2等待队列" class="headerlink" title="6.2等待队列"></a>6.2等待队列</h2><ul><li>使用condtion.await()时，将当前<strong>同步队列的头节点</strong>（当前获取锁的线程）扔到对应的<strong>condition中的队列尾</strong>，同时释放锁（与unlock逻辑相同）</li><li>使用condition.signal()时，将<strong>condition等待队列的头节点</strong>扔到<strong>同步队列的队尾</strong></li></ul><p><img src="https://img-blog.csdnimg.cn/35af5a50c9ab4980b9488627d109a45e.png"></p><h2 id="6-3执行流程"><a href="#6-3执行流程" class="headerlink" title="6.3执行流程"></a>6.3执行流程</h2><p>线程的执行顺序由同步队列决定，等待队列仅仅起到一个保存节点的作用</p><p><img src="https://img-blog.csdnimg.cn/14818daac6ab453db15015500855457e.png" alt="案例"></p><h2 id="6-4demo"><a href="#6-4demo" class="headerlink" title="6.4demo"></a>6.4demo</h2><pre><code>public class AwaitTest &#123;  public static void main(String[] args) &#123;    final ReentrantLock lock = new ReentrantLock();    final  Condition     condition = lock.newCondition();    new Thread(()-&gt;&#123;      lock.lock();      System.out.println(&quot;线程000000开始&quot;);      System.out.println(&quot;线程000000await()阻塞，进入等待队列&quot;);      try &#123;       condition.await();//线程0进入等待队列      &#125; catch (InterruptedException e) &#123;      &#125;      System.out.println(&quot;线程0被唤醒&quot;);      lock.unlock();//线程0释放锁，锁交给同步队列的下一个节点    &#125;).start();    new Thread(()-&gt;&#123;      lock.lock();      System.out.println(&quot;线程111111开始&quot;);      System.out.println(&quot;线程111111await()阻塞，进入等待队列，此时等待队列有线程0和1&quot;);      try &#123;        //线程1从同步队列移除，进入condition等待队列，此时的condition等待队列有两个元素        condition.await();      &#125; catch (InterruptedException e) &#123;      &#125;      System.out.println(&quot;线程1被唤醒&quot;);      lock.unlock();//线程1释放锁，锁交给同步队列的下一个节点    &#125;).start();    new Thread(()-&gt;&#123;      try &#123;      lock.lock();      System.out.println(&quot;此时同步队列队首为线程2（线程2获取锁），线程222222开始&quot;);        System.out.println(&quot;唤醒0线程————线程0从等待队列进入同步队列，当线程2 unlock后执行&quot;);        condition.signal();//唤醒0线程        System.out.println(&quot;唤醒1线程————线程1从等待队列进入同步队列，当线程0 unlock后执行&quot;);        condition.signal();//唤醒1线程        System.out.println(&quot;此时同步队列队首的线程2调用unlock释放锁，执行其他同步队列节点&quot;);        lock.unlock();      &#125; catch (Exception e) &#123;        e.printStackTrace();      &#125;    &#125;).start();      &#125;&#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/8336b084e785433daaa749fcffa107b1.png"></p><h2 id="6-4两个队列的本质"><a href="#6-4两个队列的本质" class="headerlink" title="6.4两个队列的本质"></a>6.4两个队列的本质</h2><ul><li><p>本质其实就是这个Node节点的结构问题。Node节点是在AQS抽象类中的，且被AQS内部类创建，<strong>因此一个ReentrantLock可以有多个Node节点（1个同步队列，多个newCondition创建的等待队列）</strong></p></li><li><p>除此之外，我们用lock  unlock操作的节点隶属于最外层AQS<img src="https://img-blog.csdnimg.cn/d131da198363458e9d4513e4344cd522.png"></p></li><li><p>而await  signal操作的节点是AQS的内部类ConditionObject中的<img src="https://img-blog.csdnimg.cn/087978696280470f977253c723f770a7.png"></p></li><li><p>因此形成了这种情况：</p></li><li><p><em>lock  unlock操作的是同步队列<br>await  signal操作的是等待队列</em>*</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 源码 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>反射获取AQS中同步队列与等待队列的长度</title>
      <link href="/zjh/2022/08/23/%E5%8F%8D%E5%B0%84%E8%8E%B7%E5%8F%96AQS%E4%B8%AD%E5%90%8C%E6%AD%A5%E9%98%9F%E5%88%97%E4%B8%8E%E7%AD%89%E5%BE%85%E9%98%9F%E5%88%97%E7%9A%84%E9%95%BF%E5%BA%A6/"/>
      <url>/zjh/2022/08/23/%E5%8F%8D%E5%B0%84%E8%8E%B7%E5%8F%96AQS%E4%B8%AD%E5%90%8C%E6%AD%A5%E9%98%9F%E5%88%97%E4%B8%8E%E7%AD%89%E5%BE%85%E9%98%9F%E5%88%97%E7%9A%84%E9%95%BF%E5%BA%A6/</url>
      
        <content type="html"><![CDATA[<ul><li><p>在使用JUC中的锁时（如<code>ReentrantLock</code>、<code>ReentrantReadWriteLock</code>），底层维护了两个队列（<strong>同步队列和等待队列</strong>），但是并没有提供相关的API来获取其队列的长度。我这里通过反射写了一个工具类，可以传入一个Lock实例获取两个队列的长度</p></li><li><p>在写这个工具类前，需要先完全弄清楚AQS与Lock的结构（<strong>包括其中的内部类、内部类子类</strong>）。尤其是不能忽略实际上<code>Lock</code>在运行中中创建的<code>Sync</code>对象是其子类<code>NonfairSync</code>和<code>fairSync</code>。如果需要反射获取到AQS中的Node节点，就需要<strong>连续两次</strong><code>syncClazz.getSuperclass().getSuperclass()</code>获取父类</p></li><li><p>下面标题1给出最终工具类，标题2开始分析源码和改造思路，按照这个思路还可以自由地更改AQS锁队列的顺序，指定线程强制提前，指定剔除等</p></li></ul><h1 id="1-工具类"><a href="#1-工具类" class="headerlink" title="1.工具类"></a>1.工具类</h1><h2 id="1-1代码"><a href="#1-1代码" class="headerlink" title="1.1代码"></a>1.1代码</h2><p><strong>获取同步队列长度：传入Lock实例<br>获取等待队列长度：传入Condition实例</strong></p><pre><code>public class AQSUtils &#123;  /**   * 获取同步队列长度（线程lock被阻塞 + 正持有锁的 节同步队列点总数） 支持JUC下locks包中所有锁   *   * @Author: zjh   * @Date: 2022/8/23 10:14   */  public static int getSyncQueueLength(Lock lock) throws NoSuchFieldException, IllegalAccessException &#123;    Class&lt;? extends Lock&gt; lockClazz = lock.getClass();    //先获取内部类Sync实例，因为Sync继承于AbstractQueuedSynchronizer，从而可以获得Node head节点    //这里Lock接口下的几个实现类（如ReentrantLock、ReentantReadWriteLock）中Sync都是内部类    Field syncField = lockClazz.getDeclaredField(&quot;sync&quot;);    syncField.setAccessible(true);    AbstractQueuedSynchronizer                  sync      = (AbstractQueuedSynchronizer) syncField.get(lock);    Class&lt;? extends AbstractQueuedSynchronizer&gt; syncClazz = sync.getClass();    //***十分需要注意，这里用了两次getSuperclass()    Class&lt;AbstractQueuedSynchronizer&gt; AQSClazz = (Class&lt;AbstractQueuedSynchronizer&gt;) syncClazz.getSuperclass().getSuperclass();    //获取同步队列的头节点  末尾节点    Field headNode = AQSClazz.getDeclaredField(&quot;head&quot;);    headNode.setAccessible(true);    //这里实际上是同步队列的Node节点，碍于访问修饰符问题，只能通过反射获取next节点的值    Object head = headNode.get(sync);    //计算长度    int    length = 0;    Object temp   = head;    while (temp != null) &#123;      length++;      Class&lt;?&gt; nodecLazz = temp.getClass();      Field    nextNode      = nodecLazz.getDeclaredField(&quot;next&quot;);      nextNode.setAccessible(true);      temp = nextNode.get(temp);    &#125;    return length;  &#125;  /**   * 每个Condition对象中都持有一个等待队列，获取其等待队列长度   *   * @Author: zjh   * @Date: 2022/8/23 10:18   */  public static int getWaiteQueueLengthInCondition(Condition condition)      throws NoSuchFieldException, IllegalAccessException, NoSuchMethodException, InvocationTargetException, InstantiationException &#123;    Class&lt;? extends Condition&gt; conClazz = condition.getClass();    Field                      firstWaiterNode = conClazz.getDeclaredField(&quot;firstWaiter&quot;);    firstWaiterNode.setAccessible(true);    Object firstWaiter = firstWaiterNode.get(condition);    int length = 0;    Object temp = firstWaiter;    while(temp!=null)&#123;      length++;      Class&lt;?&gt; nodeClazz = temp.getClass();      Field    next      = nodeClazz.getDeclaredField(&quot;nextWaiter&quot;);      next.setAccessible(true);      temp = next.get(temp);    &#125;    return length;  &#125;&#125;</code></pre><h2 id="1-2演示案例"><a href="#1-2演示案例" class="headerlink" title="1.2演示案例"></a>1.2演示案例</h2><ol><li><p>在main中创建Lock和Condition实例:</p><pre><code> ReentrantLock lock = new ReentrantLock(); Condition     condition = lock.newCondition();</code></pre></li></ol><ol start="2"><li><p>创建3个这样的线程：</p><pre><code>   //lock加锁后await阻塞————》同步队列不变   等待队列+1     new Thread(()-&gt;&#123;       lock.lock();       try &#123;         condition.await();       &#125; catch (InterruptedException e) &#123;         e.printStackTrace();       &#125;       lock.unlock();     &#125;).start();</code></pre></li><li><p>创建5个这样的线程：</p><pre><code> //lock加锁 同步队列+1  等待队列不变 new Thread(()-&gt;&#123;   lock.lock(); &#125;).start();</code></pre></li><li><p>调用AQSUtils</p></li></ol><pre><code>    TimeUnit.SECONDS.sleep(1);//保证线程全部开启    int syncQueueLength = AQSUtils.getSyncQueueLength(lock);    System.out.println(syncQueueLength);    int waiteQueueLengthInCondition = AQSUtils.getWaiteQueueLengthInCondition(condition);    System.out.println(waiteQueueLengthInCondition);</code></pre><ol start="5"><li>结果：同步队列5个  等待队列3个<br><img src="https://img-blog.csdnimg.cn/08a3ffaeec91417f8fa219abfcbc6de3.png"></li><li>同理，调用<code>signal()</code>也会让等待队列-1  同步队列+1，<code>signalAll()</code>会将对应condition中所有等待队列节点全部移入同步队列</li></ol><h1 id="2-源码解析"><a href="#2-源码解析" class="headerlink" title="2.源码解析"></a>2.源码解析</h1><p>这个其实主要是看AQS源码的结构，已知：</p><ul><li>Lock下的实例的锁相关操作都是调的AQS类中的方法，</li><li>AQS中有一个内部类Node用于维护队列，AQS另一个内部类ConditionObject也调用了Node，</li><li>因此有两个不同维度的Node，一个是同步队列，一个是等待队列</li></ul><h2 id="2-1生成同步队列-用于debug"><a href="#2-1生成同步队列-用于debug" class="headerlink" title="2.1生成同步队列(用于debug)"></a>2.1生成同步队列(用于debug)</h2><p>在main线程中运行如下代码，debug可知产生了同步队列的节点</p><pre><code>ReentrantLock lock   = new ReentrantLock(false);//用于通知生产者进行生产Condition pro = lock.newCondition();new Thread(()-&gt;&#123;  //产生同步队列  lock.lock();&#125;).start();new Thread(()-&gt;&#123;  //产生同步队列  lock.lock();&#125;).start();new Thread(()-&gt;&#123;  //产生同步队列  lock.lock();&#125;).start();</code></pre><p>Sync实例的直接Node属性是同步队列，Sync.<br><img src="https://img-blog.csdnimg.cn/7e80845395d9401e93accd5c12b8d728.png"></p><h2 id="2-2AQS结构"><a href="#2-2AQS结构" class="headerlink" title="2.2AQS结构"></a>2.2AQS结构</h2><p><img src="https://img-blog.csdnimg.cn/8cce10ff5e2546029e5cfa563a15940e.png"></p><p><img src="https://img-blog.csdnimg.cn/d693bd89dce94727a294c1ce1f8adaad.png"></p><h2 id="2-3改造思路"><a href="#2-3改造思路" class="headerlink" title="2.3改造思路"></a>2.3改造思路</h2><h3 id="2-3-1同步队列"><a href="#2-3-1同步队列" class="headerlink" title="2.3.1同步队列"></a>2.3.1同步队列</h3><p>Lock——》Sync——》获取父类的父类AQS——》获取head节点——》循环遍历next节点</p><h3 id="2-3-2等待队列"><a href="#2-3-2等待队列" class="headerlink" title="2.3.2等待队列"></a>2.3.2等待队列</h3><p>Lock——》生成的Condition——》获取firstWaiter节点——》循环遍历nextWaiter节点</p>]]></content>
      
      
      <categories>
          
          <category> 源码 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spring、Servlet监听器</title>
      <link href="/zjh/2022/08/14/Spring%E3%80%81Servlet%E7%9B%91%E5%90%AC%E5%99%A8/"/>
      <url>/zjh/2022/08/14/Spring%E3%80%81Servlet%E7%9B%91%E5%90%AC%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="1-Servlet监听器"><a href="#1-Servlet监听器" class="headerlink" title="1.Servlet监听器"></a>1.Servlet监听器</h1><ul><li><code>ServletContext、HttpSession、ServletRequest</code>的监听都是通过<code>javax.servlet </code>包下定义的，他们都是servlet的特性，换句话说，他们不依赖于Spring，而依赖于web容器（tomcat容器），他们的加载优先于Spring容器</li><li>Servlet监听器有用处，但是没有Spring监听器用的多，用的方便；并且通常可以用<code>HttpServletRequest和HttpServletResponse实现相同的需求</code></li><li>Servlet监听器提供了很多接口，在这些接口的实现类中<strong>需要重写接口方法</strong>，<strong>并且要制定对应的监听事件，监听事件也会直接影响监听目标</strong><br><a href="https://cloud.tencent.com/developer/article/1018726">参考链接1</a><br><a href="https://cloud.tencent.com/developer/article/1551830">参考链接2</a><br><a href="https://blog.csdn.net/dirft_din/article/details/107041979">参考链接3统计在线人数</a></li><li><em>其实统计人数用<code>httpServletRequest().getServletContext().setAttribute();</code>来直接获取Servlet上下文实现</em>*</li></ul><h2 id="1-1Servlet上下文监听"><a href="#1-1Servlet上下文监听" class="headerlink" title="1.1Servlet上下文监听"></a>1.1Servlet上下文监听</h2><ul><li>补充：<strong>在Spring项目中，启动Spring会先启动Servlet(tomcat）</strong>，Spring的init()紧跟其后<br>而关闭Spring项目会之后会立马destroyed()Servlet容器，因此这个<code>ServletContext监听器可以完全被ApplicationListener监听器代替</code>,<code>ApplicationListener是Spring3.0沿用至今最流行的全局监听器</code></li></ul><p>可以监听ServletContext对象的创建和删除以及属性的添加、删除和修改等操作。该监听器需要使用到如下两个接口类：</p><p>● <code>ServletContextAttributeListener</code>：监听对ServletContext属性的操作，如增加、删除、修改操作。</p><p>● <code>ServletContextListener</code>：监听ServletContext。</p><p>当创建ServletContext时，激发<code>contextInitialized(ServletContextEvent sce)</code>方法；</p><p>当销毁ServletContext时，激发<code>contextDestroyed(ServletContext- Event sce)</code>方法。</p><h2 id="1-2Http会话监听"><a href="#1-2Http会话监听" class="headerlink" title="1.2Http会话监听"></a>1.2Http会话监听</h2><ul><li>在Spring项目中对Session域进行监控仍然用的是<code>HttpSessionListener</code>，其来自于Servlet2.3</li><li>用来监听 Web 应用种的 Session 对象，通常用于统计在线情况。</li></ul><p>可以监听Http会话活动情况、Http会话中属性设置情况，也可以监听Http会话的active、pasivate情况等。</p><p>该监听器需要使用到如下多个接口类：</p><p>● <code>HttpSessionListener</code>：监听HttpSession的操作。</p><p>当创建一个Session时，激发<code>sessionCreated (SessionEvent se)</code>方法；</p><p>当销毁一个Session时，激发<code>sessionDestroyed (HttpSessionEvent se)</code>    方法。</p><p>● <code>HttpSessionActivationListener</code>：用于监听Http会话active、passivate情况。</p><p>● <code>HttpSessionAttributeListener</code>：监听HttpSession中属性的操作。</p><p>当在Session<strong>增加</strong>一个属性时，激发attributeAdded(HttpSessionBindingEvent se) 方法；</p><p>当在Session<strong>删除</strong>一个属性时，激发attributeRemoved(HttpSessionBindingEvent se)方法；</p><p>在Session属性被<strong>修改</strong>时，激发attributeReplaced(HttpSessionBindingEvent se) 方法。</p><h2 id="1-3客户端Request请求监听"><a href="#1-3客户端Request请求监听" class="headerlink" title="1.3客户端Request请求监听"></a>1.3客户端Request请求监听</h2><ul><li>用来监听 Request 对象的属性操作。</li><li>ServletRequestListener监听器来自于Servlet2.4</li></ul><p>● <code>ServletRequestListener</code>接口类。</p><p>● <code>ServletRequestAttrubuteListener</code>接口类。</p><p>其实现类实现了ServletContextAttributeListener和ServletContextListener两个接口类中的<strong>5个方法</strong>：</p><p>● contextInitialized(ServletContextEvent s)方法用来<strong>初始化</strong>ServletContext对象。</p><p>● contextDestroyed(ServletContextEvent s)方法在上下文中<strong>删除</strong>某个属性时调用。</p><p>● attributeAdded(ServletContextAttributeEvent sa)方法在上下文中<strong>添加</strong>一个新的属性时调用。</p><p>● attributeReplaced(ServletContextAttributeEvent sa)方法在<strong>更新</strong>属性时调用。</p><p>● attributeRemoved(ServletContextAttributeEvent sa)方法在上下文中<strong>删除</strong>某个属性时会被调用。</p><h1 id="2-Servlet监听事件"><a href="#2-Servlet监听事件" class="headerlink" title="2.Servlet监听事件"></a>2.Servlet监听事件</h1><p>在实现了Servlet监听器接口的方法中，需要重写其接口抽象方法，而其抽象方法的形参，<strong>则对应了一个监听器对象</strong></p><h2 id="2-1不带Attribute监听事件的创建和销毁"><a href="#2-1不带Attribute监听事件的创建和销毁" class="headerlink" title="2.1不带Attribute监听事件的创建和销毁"></a>2.1不带Attribute监听事件的创建和销毁</h2><pre><code>@WebListenerpublic class MyServletListener implements ServletContextListener &#123;  @Override  public void contextInitialized(ServletContextEvent sce) &#123;    ServletContextListener.super.contextInitialized(sce);  &#125;  @Override  public void contextDestroyed(ServletContextEvent sce) &#123;    ServletContextListener.super.contextDestroyed(sce);  &#125;&#125;————————————————————————————————————————————————————————————————————————@WebListenerpublic class MyServletListener implements HttpSessionListener &#123;  @Override  public void sessionCreated(HttpSessionEvent se) &#123;    HttpSessionListener.super.sessionCreated(se);  &#125;  @Override  public void sessionDestroyed(HttpSessionEvent se) &#123;    HttpSessionListener.super.sessionDestroyed(se);  &#125;&#125;—————————————————————————————————————————————————————————————————————————    @WebListenerpublic class MyServletListener implements ServletRequestListener &#123;  @Override  public void requestDestroyed(ServletRequestEvent sre) &#123;    ServletRequestListener.super.requestDestroyed(sre);  &#125;  @Override  public void requestInitialized(ServletRequestEvent sre) &#123;    ServletRequestListener.super.requestInitialized(sre);  &#125;&#125;</code></pre><h2 id="2-2带Attribute监听事件的增、删、改"><a href="#2-2带Attribute监听事件的增、删、改" class="headerlink" title="2.2带Attribute监听事件的增、删、改"></a>2.2带Attribute监听事件的增、删、改</h2><pre><code>@WebListenerpublic class MyServletListener implements ServletContextAttributeListener &#123;  @Override  public void attributeAdded(ServletContextAttributeEvent scae) &#123;    ServletContextAttributeListener.super.attributeAdded(scae);  &#125;  @Override  public void attributeRemoved(ServletContextAttributeEvent scae) &#123;    ServletContextAttributeListener.super.attributeRemoved(scae);  &#125;  @Override  public void attributeReplaced(ServletContextAttributeEvent scae) &#123;    ServletContextAttributeListener.super.attributeReplaced(scae);  &#125;&#125;</code></pre><p>其他两个关于Attribute监听的都是有三个抽象方法：added  removed repalced</p><h1 id="3-为什么大量出现ed过去式？"><a href="#3-为什么大量出现ed过去式？" class="headerlink" title="3.为什么大量出现ed过去式？"></a>3.为什么大量出现ed过去式？</h1><p>众所周知英语中ed结尾的动词都是<code>过去完成式</code><br>我们发现 <code>sessionCreated  contextDestroyed Replaced等等</code>这些抽象方法都是ed结尾的过去式，那么可以 从中推断出：监听中的方法是在事件发生之后进行的。<br>因此我们可以解决一个疑惑：“我想在监听器方法中使用容器中的其他对象方法，会不会报错？”<br>答案是不会：“因为对context监听的ed方法一定触发在整个容器加载结束之后”</p><h1 id="4-Spring监听器"><a href="#4-Spring监听器" class="headerlink" title="4. Spring监听器"></a>4. Spring监听器</h1><p><a href="https://segmentfault.com/a/1190000039097608">两种方式：参考资料</a></p><h2 id="4-1ApplicationListener接口实现监听"><a href="#4-1ApplicationListener接口实现监听" class="headerlink" title="4.1ApplicationListener接口实现监听"></a>4.1ApplicationListener接口实现监听</h2><p>一般来说，在Spring项目中监听器只选择ApplicationListener，而对于监听事件spring提供了多种选择</p><pre><code>ApplicationStartedEvent：spring boot启动监听类ApplicationEnvironmentPreparedEvent：环境事先准备ApplicationPreparedEvent：上下文context准备时触发ApplicationReadyEvent：上下文已经准备完毕的时候触发ApplicationFailedEvent：该事件为spring boot启动失败时的操作</code></pre><ul><li>他们<code>都是ApplicationEvent的抽象子类</code>，触发的时机不同</li><li>例如用<code>ApplicationListener监听</code>，那么<code>以上5种子类事件都可以被监听到</code></li><li>你可以<code>自定义一个事件</code>，继承于上面的<code>子事件</code>，来实现一些<code>数据的绑定</code>，不过一般不会用到</li></ul><h2 id="4-2-EventListener注解实现监听"><a href="#4-2-EventListener注解实现监听" class="headerlink" title="4.2@EventListener注解实现监听"></a>4.2@EventListener注解实现监听</h2><pre><code>@Component//需要注入IOC，无需实现任何接口public class MySprigListenerAnno &#123;@EventListener//配置一个监听器，省去了写ApplicationListener，但必须明确指出形参中的监听事件  public void myEvent(ApplicationEvent event)&#123;  System.out.println(&quot;用注解的方式实现Spring监听器，当前：&quot;+event.getClass().getName());&#125;&#125;</code></pre><h2 id="4-3重要的泛型"><a href="#4-3重要的泛型" class="headerlink" title="4.3重要的泛型"></a>4.3重要的泛型</h2><p>查看源码可知<code>泛型决定了监听事件是谁</code>，如果不指定，那么就是<code>默认监听根父类ApplicationEvent</code></p><p><img src="https://img-blog.csdnimg.cn/12e25b4e04b048b8be588db230769b26.png" alt="源码"></p><h1 id="5-Servlet和Spring的初始化顺序"><a href="#5-Servlet和Spring的初始化顺序" class="headerlink" title="5.Servlet和Spring的初始化顺序"></a>5.Servlet和Spring的初始化顺序</h1><p>我们用一个案例直接看</p><h2 id="5-1Serlvet：监听context"><a href="#5-1Serlvet：监听context" class="headerlink" title="5.1Serlvet：监听context"></a>5.1Serlvet：监听context</h2><pre><code>@WebListenerpublic class MyServletListener implements ServletContextListener &#123;  @Override  public void contextInitialized(ServletContextEvent sce) &#123;    /**     * ServletContextEvent的父类EventListener是没有contextInitialized(sce)方法的。     * 所以对于此处来说，调不调super.contextInitialized都无所谓     */    ServletContextListener.super.contextInitialized(sce);    System.out.println(&quot;当前是Servlet初始化&quot;);  &#125;  @Override  public void contextDestroyed(ServletContextEvent sce) &#123;    ServletContextListener.super.contextDestroyed(sce);    System.out.println(&quot;当前是Servlet销毁&quot;);  &#125;&#125;</code></pre><h2 id="5-2Spring：监听context"><a href="#5-2Spring：监听context" class="headerlink" title="5.2Spring：监听context"></a>5.2Spring：监听context</h2><p>这里监听ApplicationEvent，相当于监听其所有子类事件的，他的子类很多，但是Spring启动的时候只有几个事件会被监听<br><img src="https://img-blog.csdnimg.cn/b1c3fa9dfe8f42e1b7ea48967e353f25.png"></p><pre><code>@Component@Order(1)public class MySpringListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123;  @Override  public void onApplicationEvent(ApplicationEvent event) &#123;    System.out.println(&quot;当前是Spring的:&quot;+event.getClass().getName()+&quot;监听事件&quot;);  &#125;&#125;</code></pre><h2 id="5-3启动Spring"><a href="#5-3启动Spring" class="headerlink" title="5.3启动Spring"></a>5.3启动Spring</h2><p>执行顺序大概是:  tomcat初始化——Servlet启动——Servlet引擎——Servlet初始化完成——tomcat启动完成——Spring初始化</p><p><img src="https://img-blog.csdnimg.cn/1ba92b971a804d79823eeef5f62e9733.png"></p><h1 id="6-监听器的应用：Spring启动时就调用业务方法"><a href="#6-监听器的应用：Spring启动时就调用业务方法" class="headerlink" title="6.监听器的应用：Spring启动时就调用业务方法"></a>6.监听器的应用：Spring启动时就调用业务方法</h1><ul><li>通过监听<code>ApplicationReadyEvent</code>或<code>ApplicationStartedEvent</code>事件，就可以调用；</li><li><strong>注意started是过去式，即此时Spring的IOC容器已经启动完成，可以在此时调用IOC容器中的bean</strong></li><li>而Ready更是在Started之后，更可以直接@Autowired使用IOC容器中的bean</li></ul><pre><code>    @Service    public class TheFuckList &#123;          @Autowired      RedisTemplate redisTemplate;          public List&lt;String&gt; getFuckList()&#123;    //    List fuckList = redisTemplate.boundListOps(&quot;list1&quot;).range(0, 10);        List fuckList = redisTemplate.opsForList().range(&quot;list1&quot;,0,10);        Iterator iterator = fuckList.iterator();        while(iterator.hasNext())&#123;          System.out.println(iterator.next());        &#125;        return fuckList;      &#125;    &#125;</code></pre><hr><pre><code>@Component@Order(0)public class MySpringListener2 implements ApplicationListener&lt;ApplicationStartedEvent&gt; &#123;  @Autowired  TheFuckList theFuckList;  @Autowired  FuckListBean fuckListBean;  @Override  public void onApplicationEvent(ApplicationStartedEvent event) &#123;    fuckListBean.fuckList = theFuckList.getFuckList();    System.out.println(fuckListBean.fuckList.size());  &#125;&#125;</code></pre><h1 id="7-多个Spring监听器执行顺序"><a href="#7-多个Spring监听器执行顺序" class="headerlink" title="7.多个Spring监听器执行顺序"></a>7.多个Spring监听器执行顺序</h1><p>以<code>监听事件</code>为基准，监听器之间的顺序以@Order决定</p><pre><code>@Component@Order(-1)public class MySpringListener implements ApplicationListener&lt;ApplicationEvent&gt; &#123;//ApplicationStartedEvent    @Override  public void onApplicationEvent(ApplicationEvent event) &#123;    System.out.println(&quot;当前是Srp:&quot;+event.getClass().getName()+&quot;监听事件&quot;);  &#125;@Component@Order(0)public class MySpringListener2 implements ApplicationListener&lt;ApplicationEvent&gt; &#123;  @Override  public void onApplicationEvent(ApplicationEvent event) &#123;    System.out.println(&quot;第二个监听器&quot;);  &#125;&#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/19d04361b5834e95bbe60f7f96c00c4d.png"></p><h1 id="8-过滤器、拦截器、监听器执行顺序"><a href="#8-过滤器、拦截器、监听器执行顺序" class="headerlink" title="8.过滤器、拦截器、监听器执行顺序"></a>8.过滤器、拦截器、监听器执行顺序</h1><ul><li>注意，<strong>过滤器、拦截器</strong>是针对某个包下的<strong>controller接口被调用时而进行处理的</strong>；</li><li><strong>监听器</strong>则可以深入到Servlet、Spring容器的创建之时执行。</li><li>Filter过滤器的本质是：<code>回调</code></li><li>Interceptor拦截器的本质是：<code>反射</code></li></ul><p><a href="https://cloud.tencent.com/developer/article/1981326">参考资料</a></p><p>那么如果是过滤器，拦截器，监听器同时生效呢？</p><p><img src="https://img-blog.csdnimg.cn/97a00ec1378f4e7f835f8d0448de819d.png"><br><img src="https://img-blog.csdnimg.cn/b7c8f3983c3d4b4789c11a10eca876cc.png"></p><h2 id="8-1Filter的过滤流程"><a href="#8-1Filter的过滤流程" class="headerlink" title="8.1Filter的过滤流程"></a>8.1Filter的过滤流程</h2><ul><li>在我们自定义的过滤器中都会实现一个 doFilter()方法，这个方法有一个FilterChain 参数，而实际上它是一个回调接口。ApplicationFilterChain是它的实现类， 这个实现类内部也有一个 doFilter() 方法就是回调方法。</li><li>回调的顺序由@Order来进行配置</li><li>过滤器Filter是在<strong>请求进入web容器后，但在进入servlet之前进行预处理</strong>，请求结束是在servlet处理完以后。</li></ul><h2 id="8-2Interceptor拦截器流程"><a href="#8-2Interceptor拦截器流程" class="headerlink" title="8.2Interceptor拦截器流程"></a>8.2Interceptor拦截器流程</h2><ul><li>对于Spring拦截器，一般直接实现<code>HandlerInterceptor接口</code>，并重写三个抽象方法。</li><li>拦截器 Interceptor 是在请求进入servlet后，在进入Controller之前进行预处理的，Controller 中渲染了对应的视图之后请求结束。</li></ul><p><a href="https://cloud.tencent.com/developer/article/1413447">参考资料1</a></p><p><img src="https://img-blog.csdnimg.cn/077b51c0573f4111a6102f7a618838b0.png"></p><h2 id="8-3Controller请求调用顺序"><a href="#8-3Controller请求调用顺序" class="headerlink" title="8.3Controller请求调用顺序"></a>8.3Controller请求调用顺序</h2><p>controller 中所有的请求都要经过<strong>核心组件<code>DispatcherServlet</code>路由</strong>，都会执行它的 <code>doDispatch() </code>方法，<strong>而拦截器postHandle()、preHandle()方法便是在其中调用的。</strong></p><h1 id="9-DispatcherServlet类：路由，中央调度器"><a href="#9-DispatcherServlet类：路由，中央调度器" class="headerlink" title="9.DispatcherServlet类：路由，中央调度器"></a>9.DispatcherServlet类：路由，中央调度器</h1><p><img src="https://img-blog.csdnimg.cn/e1e200007df2422d9279852fde1274ac.png" alt="源码"></p><ul><li><strong><code>HTTP请求处理程序/控制器的中央调度器</code></strong></li></ul><pre><code>![源码](https://img-blog.csdnimg.cn/e7bb33374b2444b09cef9327d79c312b.png)</code></pre><h2 id="9-1doDispatch中央调度方法"><a href="#9-1doDispatch中央调度方法" class="headerlink" title="9.1doDispatch中央调度方法"></a>9.1doDispatch中央调度方法</h2><pre><code>    protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;            try &#123;     ...........        try &#123;                   // 获取可以执行当前Handler的适配器            HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler());            // Process last-modified header, if supported by the handler.            String method = request.getMethod();            boolean isGet = &quot;GET&quot;.equals(method);            if (isGet || &quot;HEAD&quot;.equals(method)) &#123;                long lastModified = ha.getLastModified(request, mappedHandler.getHandler());                if (logger.isDebugEnabled()) &#123;                    logger.debug(&quot;Last-Modified value for [&quot; + getRequestUri(request) + &quot;] is: &quot; + lastModified);                &#125;                if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123;                    return;                &#125;            &#125;            // 注意： 执行Interceptor中PreHandle()方法            if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123;                return;            &#125;            // 注意：执行Handle【包括我们的业务逻辑，当抛出异常时会被Try、catch到】            mv = ha.handle(processedRequest, response, mappedHandler.getHandler());            if (asyncManager.isConcurrentHandlingStarted()) &#123;                return;            &#125;            applyDefaultViewName(processedRequest, mv);            // 注意：执行Interceptor中PostHandle 方法【抛出异常时无法执行】            mappedHandler.applyPostHandle(processedRequest, response, mv);        &#125;    &#125;    ...........&#125;</code></pre><h2 id="9-2为何拦截器的pre和post执行顺序是栈顺序"><a href="#9-2为何拦截器的pre和post执行顺序是栈顺序" class="headerlink" title="9.2为何拦截器的pre和post执行顺序是栈顺序"></a>9.2为何拦截器的pre和post执行顺序是栈顺序</h2><p>看看两个方法<code>applyPreHandle(）</code>、<code>applyPostHandle(）</code>具体是如何被调用的，就明白为什么postHandle()、preHandle() 执行顺序是相反的了。</p><p><img src="https://img-blog.csdnimg.cn/15a94ae683a14c4b83a6104f1fba77a6.png"></p><p>正是因为<code>DispathcherServlet类中的doDispach()方法</code>进行调度的时候，<strong>实际上</strong>是调用了<code>applyPreHandler()和applyPostHandler()</code>，而这两个方法中的for循环遍历<code>interceptorList</code>数组时一个是<code>i++</code>一个是<code>i--</code>，所以表面上就成了入栈出栈的执行顺序</p><h1 id="10-过滤器监听器几个注解及配置"><a href="#10-过滤器监听器几个注解及配置" class="headerlink" title="10.过滤器监听器几个注解及配置"></a>10.过滤器监听器几个注解及配置</h1><h2 id="WebFilter"><a href="#WebFilter" class="headerlink" title="@WebFilter"></a>@WebFilter</h2><p>标注在 xxxxx<code>implements Filter</code>的类上，即把<code>Servlet过滤器</code>注入Servlet容器中，这是Servlet3.0的注解规范，被Spring5.0引入</p><h2 id="WebListener"><a href="#WebListener" class="headerlink" title="@WebListener"></a>@WebListener</h2><p>标注在 xxxxx<code> implements ServletContextListener</code>的类上，即把<code>Servlet监听器</code>注入Servlet容器中，这是Servlet3.0的注解规范，被Spring5.0引入</p><h2 id="EventListener"><a href="#EventListener" class="headerlink" title="@EventListener"></a>@EventListener</h2><pre><code>@Component//需要注入IOC，无需实现任何接口public class MySprigListenerAnno &#123;@EventListener//配置一个监听器，省去了写ApplicationListener，但必须明确指出形参中的监听事件  public void myEvent(ApplicationEvent event)&#123;  System.out.println(&quot;用注解的方式实现Spring监听器，当前：&quot;+event.getClass().getName());&#125;</code></pre><p>————————————如果不用注解就需要实现接口</p><pre><code>@Component@Order(0)public class MySpringListener2 implements ApplicationListener&lt;ApplicationEvent&gt; &#123;  @Override  public void onApplicationEvent(ApplicationEvent event) &#123;    System.out.println(&quot;第二个监听器&quot;);  &#125;&#125;</code></pre><h2 id="WebMvcConfigurer配置"><a href="#WebMvcConfigurer配置" class="headerlink" title="WebMvcConfigurer配置"></a>WebMvcConfigurer配置</h2><p>为Spring容器注册HandlerInterceptor的实现类</p><pre><code>@Configurationpublic class MyWebMvcConfigurer implements WebMvcConfigurer &#123;  @Override  public void addInterceptors(InterceptorRegistry registry) &#123;    registry.addInterceptor(new MyHandlerInterceptor()).addPathPatterns(&quot;/login/web&quot;)        .excludePathPatterns(&quot;/login/no&quot;);  &#125;&#125;</code></pre><p>————————<strong>拦截器本身内容跟注册配置缺一不可</strong></p><pre><code>public class MyHandlerInterceptor  implements HandlerInterceptor &#123;  @Override  public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123;    long start = System.currentTimeMillis();    request.setAttribute(&quot;startTime&quot;, start);    return true;//直接放行//    return HandlerInterceptor.super.preHandle(request, response, handler);  &#125;  @Override  public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123;    long start = (long) request.getAttribute(&quot;startTime&quot;);    long end     = System.currentTimeMillis();    request.setAttribute(&quot;handleTime&quot;,end-start);//    HandlerInterceptor.super.postHandle(request, response, handler, modelAndView);  &#125;  @Override  public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123;  log.info(      String.format(&quot;本次请求%s的%s接口耗时%s毫秒&quot;,          request.getRequestURL(),          request.getMethod(),          (long)request.getAttribute(&quot;handleTime&quot;)));//    HandlerInterceptor.super.afterCompletion(request, response, handler, ex);  &#125;&#125;</code></pre><h2 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h2><p>除了@EventListener可以不写实现类，其他都必须写</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>AOP+反射：接口参数校验</title>
      <link href="/zjh/2022/08/13/AOP-%E5%8F%8D%E5%B0%84%EF%BC%9A%E6%8E%A5%E5%8F%A3%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C/"/>
      <url>/zjh/2022/08/13/AOP-%E5%8F%8D%E5%B0%84%EF%BC%9A%E6%8E%A5%E5%8F%A3%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<ul><li>本案例包括4个核心类：<br>AopUtils：抽取出来的公共方法<br>@ValidateGroup<br>@ValidateField<br>ValidateAspectJHandler</li><li>功能包括：长度、值范围、正则匹配、非空校验</li><li>以下是设计思路、最终代码、测试结果</li><li>后续扩展只需要修改@ValidateField 和 ValidateAspectJHandler；例如如果是按照我第一份实习时候的代码架构，可以在AspectJ中添加<a href="https://zjhblog.gitee.io/zjh/2022/08/12/%E5%AF%B9dto%E6%8C%87%E5%AE%9A%E5%B1%9E%E6%80%A7%E4%B8%80%E9%94%AE%E5%8A%A0%E8%A7%A3%E5%AF%86/">对dto指定属性一键加解密</a>的逻辑。</li></ul><h1 id="1-演示-最终使用方法"><a href="#1-演示-最终使用方法" class="headerlink" title="1.演示: 最终使用方法"></a>1.演示: 最终使用方法</h1><p>以注册功能为例</p><pre><code>@RestController@RequestMapping(&quot;validater&quot;)public class ValidateController &#123;  @ValidateGroup(fields = &#123;    //index默认=0，即对第一个参数param1校验，其他参数是校验规则、报错日志记录的内容      @ValidateField(index = 0,notNull = true,maxLen = 10,code = &quot;param1-error&quot;,message = &quot;param1校验错误&quot;),      @ValidateField(index = 1,notNull = true,fieldName = &quot;passWord&quot;,minLen = 6,code = &quot;passWord-erro&quot;,message = &quot;密码校验错误&quot;),      @ValidateField(index = 1,notNull = true,fieldName = &quot;age&quot;,minVal = 0,code = &quot;age-error&quot;,message = &quot;年龄不能小于0&quot;),      @ValidateField(index = 1,notNull = true,fieldName = &quot;tall&quot;,minVal = 0,maxVal = 250.9,code =&quot;tall-error&quot;,message = &quot;身高范围出错&quot;),      @ValidateField(index = 1,notNull = true,fieldName = &quot;phone&quot;,regStr = &quot;^(13[0-9]|14[01456879]|15[0-35-9]|16[2567]|17[0-8]|18[0-9]|19[0-35-9])\\d&#123;8&#125;$&quot;,code = &quot;phone-error&quot;,message = &quot;手机号错误&quot;)  &#125;)  @PostMapping(&quot;post&quot;)  public String postValidater(@RequestParam String param1,  RegisterDto dto)&#123;    System.out.println(&quot;成功通过校验&quot;);    System.out.println(&quot;第一个参数是：&quot; + param1);    System.out.println(&quot;第二个参数是&quot;+dto.toString());    return &quot;succeed&quot;;  &#125;    &#125;</code></pre><p>其中：请求Dto包含name、passWord、phone等字段；<br>利用AspectJ对接口方法直接进行代理校验</p><h1 id="2-流程分析"><a href="#2-流程分析" class="headerlink" title="2.流程分析"></a>2.流程分析</h1><ul><li>AspectJ代理注解<code>@ValidateGroup</code>标注的方法，而这个Group注解中的属性就是<code>@ValidateField []</code></li><li>获取到<code>@ValidateField</code>数组后，遍历。通过比对注解的参数 与 dto或者param中对应名字的参数来进行校验</li><li>如果校验成功就放行，校验失败就抛异常终止</li></ul><h1 id="3-公共方法抽取AopUtils"><a href="#3-公共方法抽取AopUtils" class="headerlink" title="3.公共方法抽取AopUtils"></a>3.公共方法抽取AopUtils</h1><p>经过流程分析可知：至少需要以下几个方法（并可以抽取为公共组件）</p><ul><li> <code>public Method getMethod(ProceedingJoinPoint pjp)</code>：获取被AOP拦截的方法Method对象</li><li> <code> public Annotation getAnnotationByMethod(Method method, Class annoClass)</code>：获取目标方法对象的指定注解对象</li><li><code>public Object getFieldFromDtoByFieldName(Object dto , String fieldName) </code>从dto中，获取指定属性名的属性值</li></ul><p>如下工具类也可以做成全静态方法</p><pre><code>public class AopUtils &#123;private volatile static AopUtils aopUtils;private AopUtils() &#123;&#125;public static AopUtils getInstance() &#123;    if (aopUtils == null) &#123;        synchronized (AopUtils.class) &#123;            if (aopUtils == null) &#123;                aopUtils = new AopUtils();            &#125;        &#125;    &#125;    return aopUtils;&#125;/** * 获取目标类的指定方法 */public Method getMethodByClassAndName(Class c, String methodName) &#123;    Method[] methods = c.getDeclaredMethods();    for (Method method : methods) &#123;        if (method.getName().equals(methodName)) &#123;            return method;        &#125;    &#125;    return null;&#125;/** * 获取目标方法的指定注解 * 相当于 method.getAnnotation(xxxx.class); */public Annotation getAnnotationByMethod(Method method, Class annoClass) &#123;    Annotation all[] = method.getAnnotations();    for (Annotation annotation : all) &#123;        if (annotation.annotationType() == annoClass) &#123;            return annotation;        &#125;    &#125;    return null;&#125;/** * 获取被拦截方法的对象 * 配合使用，最终用于在Aspectj中获取被拦截方法上的注解 * 例如：AopUtils.getMethod(pjp).getDeclaredAnnotation(被aop拦截的注解.class) */public Method getMethod(ProceedingJoinPoint pjp) &#123;    //获取参数的签名    MethodSignature msig = (MethodSignature) pjp.getSignature();    // MethodSignature.getMethod() 获取的是顶层接口或者父类的方法对象 如果在实现类的方法上，应该使用反射获取当前对象的方法对象    Object target = pjp.getTarget();//获取连接点所在的目标对象（被代理的对象）而不是父类or接口    //方法名 + 方法形参 ————》获取指定的方法对象(重载)    String methodName = msig.getName();    Class[] parameterTypes = msig.getParameterTypes();    Method method = null;    try &#123;        method = target.getClass().getMethod(methodName, parameterTypes);    &#125; catch (NoSuchMethodException e) &#123;        //log.error(...);    &#125;    return method;&#125;/** * 从dto中，获取指定属性名的属性值； */public Object getFieldFromDtoByFieldName(Object dto , String fieldName) throws NoSuchFieldException, IllegalAccessException &#123;    Class&lt;?&gt; dtoClazz = dto.getClass();    Field field = dtoClazz.getDeclaredField(fieldName);    field.setAccessible(true);    return field.get(dto);&#125;//  这个其实还有另一种写法//  private Method getMethod(ProceedingJoinPoint joinPoint) &#123;//    try &#123;//      Class[] parameterTypes = ((MethodSignature) joinPoint.getSignature()).getMethod().getParameterTypes();//      return joinPoint.getTarget().getClass().getMethod(joinPoint.getSignature().getName(), parameterTypes);//    &#125; catch (NoSuchMethodException e) &#123;//      e.printStackTrace();//    &#125;//    return null;//  &#125;&#125;</code></pre><h1 id="4-注解及设计原理"><a href="#4-注解及设计原理" class="headerlink" title="4.注解及设计原理"></a>4.注解及设计原理</h1><h2 id="4-1ValidateGroup"><a href="#4-1ValidateGroup" class="headerlink" title="4.1ValidateGroup"></a>4.1ValidateGroup</h2><p>这个注解用于被AspectJ拦截，其属性是一个数组，用于参数校验</p><pre><code>@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD, ElementType.FIELD&#125;)public @interface ValidateGroup &#123;  ValidateFiled[] fields();&#125;</code></pre><h2 id="4-2ValidateField"><a href="#4-2ValidateField" class="headerlink" title="4.2ValidateField"></a>4.2ValidateField</h2><ul><li>当且仅当只有一个参数的时候可以不用指定index</li><li>index默认为0，例如<code>public void register(@RequestParam String param1 , @RequestBody Dto dto)&#123;&#125;</code>中应该设置index = 1 ，这是由于<code>joinPoint.getArgs()</code>获取的形参是一个数组，需要用index指定位置</li><li>所有参数都有默认值（不进行校验）</li></ul><p>如下：</p><pre><code>@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD, ElementType.FIELD&#125;)public @interface ValidateField &#123;  /**   * 参数索引位置：接口中有多个参数时用index指定需要校验的参数   * 默认：0号索引，当且仅当接口方法只有一个参数   */  int index() default 0;  /**   * 默认：如果参数是基本数据类型或String，就不用指定该参数   * 如果参数是对象，要验证对象里面某个属性，就用该参数指定属性名   */  String fieldName() default &quot;&quot;;  /**   * 错误码，用于日志记录   */  String code() default &quot;&quot;;  /**   * 错误提示语，用于日志记录   */  String message() default &quot;&quot;;  /**   * 正则验证   */  String regStr() default &quot;&quot;;  /**   * 非空校验，为true表示不能为空，false表示能够为空   */  boolean notNull() default false;  /**   * 字符串最大长度   */  int maxLen() default 0x7fffffff;  /**   * 字符串最小长度   */  int minLen() default 0;  /**   * 最大值，用于验证数值类型数据   */  double maxVal() default 0x1.fffffffffffffP+1023;  /**   * 最小值，用于验证数值类型数据   */  double minVal() default 0x0.0000000000001P-1022;&#125;</code></pre><h1 id="5-ValidateAspectJHandler"><a href="#5-ValidateAspectJHandler" class="headerlink" title="5.ValidateAspectJHandler"></a>5.ValidateAspectJHandler</h1><h2 id="5-1大体结构"><a href="#5-1大体结构" class="headerlink" title="5.1大体结构"></a>5.1大体结构</h2><pre><code>@Component@Aspectpublic class ValidateAspectHandler &#123;  private AopUtils aopUtils = AopUtils.getInstance();  /**   * 使用AOP对使用了ValidateGroup的方法进行代理校验   */  @Around(&quot;@annotation(ValidateGroup)&quot;)  public Object validateAround(ProceedingJoinPoint joinPoint) throws Throwable &#123;//1.获取当前方法对象method//2.根据method对象获取对应的ValidateGroup对象//3.调用封装方法，将validateGroup.fields() 与 joinPoint.getArgs()形参数组传入，进行校验//4.如果为true，则执行下一步    return joinPoint.proceed();  &#125;  /**   * 封装方法：验证参数是否合法   */  private boolean validateField(ValidateFiled[] validateFields, Object[] args) &#123;    for (ValidateFiled validateFiled : validateFields) &#123;        //1.每次循环都是一个校验逻辑        //2.index仍然是指定对第几号元素进行校验        //3.fieldName如果不指定，那就是对基本数据类型即@RequestParam进行校验；如果指定，则对Dto即@RequestBody进行校验&#125;</code></pre><h2 id="5-2具体实现"><a href="#5-2具体实现" class="headerlink" title="5.2具体实现"></a>5.2具体实现</h2><pre><code>@Component@Aspectpublic class ValidateAspctJHandler &#123;//    private static org.slf4j.Logger logger = LoggerFactory.getLogger(&quot;ValidateAspctJHandler&quot;);    private AopUtils aopUtils = AopUtils.getInstance();  /**   * 使用AOP对使用了ValidateGroup的方法进行代理校验   */  //相当于用@Around + return joinPoint.proceed();   //使用@Before的时候不能用ProceedingJoinPoint 只能用JoinPoint    @Before(&quot;@annotation(ValidateGroup)&quot;)    public void validateAround(JoinPoint joinPoint) throws Throwable &#123;        //获取被代理的方法对象        Method method = aopUtils.getMethod(joinPoint);        //获取被代理的方法对象对应的@ValidateGroup对象        ValidateGroup validateGroup = (ValidateGroup)aopUtils.getAnnotationByMethod(method, ValidateGroup.class);        //获取被代理方法的参数数组(这是参数值，而不是 method.getParameterTypes()返回的是Class[]  )        Object[] args = joinPoint.getArgs();        /*         * args和validateGroup中包含了全部需要校验的信息，因此可以封装为一个方法         * 在这个方法中，如果校验失败则用throws抛异常的方式终止         */        validateAllFields(validateGroup.fields(), args);    &#125;    /**     * 验证参数是否合法     * ValidateField[]中每一条都是一个校验规则，每一条都对应一个属性     * Object[] args中是所有的请求参数值，需要从args[validateFiled.index()中确定是对谁进行校验     */  private void validateAllFields(ValidateField[] validateFields, Object[] args) throws NoSuchFieldException, IllegalAccessException &#123;      //遍历：对每个@ValidateField进行校验    for (ValidateField validateFiled : validateFields) &#123;      Object arg;      //1.当fieldName为默认值&quot;&quot;的时候，此时是对@RequestParam即基本数据类型orString进行校验      if (&quot;&quot;.equals(validateFiled.fieldName())) &#123;          //arg是基本数据类型orString        arg = args[validateFiled.index()];        //2.如果fieldName设置了，那就是对dto中的某个属性进行校验      &#125; else &#123;          //获取第index号参数dto指定的属性值        arg = aopUtils.getFieldFromDtoByFieldName(args[validateFiled.index()], validateFiled.fieldName());      &#125;      //3.以下是校验流程，需要同时考虑是对dto属性or基本数据类型orString      //3.1判断参数是否为空      if (validateFiled.notNull()) &#123;        if (arg == null || arg.equals(&quot;&quot;)) &#123;//            logger.error(validateFiled.code() + &quot;:&quot; + validateFiled.message());          throw new RuntimeException(validateFiled.code()  + &quot;:&quot; + validateFiled.message());        //如果该参数能够为空，并且当参数为空时，就不用判断后面的了 ，直接返回        &#125; &#125;else &#123;        if (arg == null || arg.equals(&quot;&quot;)) &#123;          return;        &#125;      &#125;      //3.2判断字符串最大长度  如果设置为一个负数则不校验  默认为最大int值      if (validateFiled.maxLen() &gt;= 0) &#123;        if (arg.toString().length() &gt; validateFiled.maxLen()) &#123;//          logger.error(validateFiled.code() + &quot;:&quot; + validateFiled.message());          throw new RuntimeException(validateFiled.code()  + &quot;:&quot; + validateFiled.message());        &#125;      &#125;      //3.3判断字符串最小长度  如果设置为一个负数则不校验  默认为0      if (validateFiled.minLen() &gt;= 0) &#123;        if (arg.toString().length() &lt; validateFiled.minLen()) &#123;//          logger.error(validateFiled.code() + &quot;:&quot; + validateFiled.message());          throw new RuntimeException(validateFiled.code()  + &quot;:&quot; + validateFiled.message());        &#125;      &#125;      //3.4判断数值最大值  当不是默认值0x1.fffffffffffffP+1023的时候进行判断      if (validateFiled.maxVal() != 0x1.fffffffffffffP+1023) &#123;        if (Double.parseDouble(arg.toString()) &gt; validateFiled.maxVal()) &#123;//          logger.error(validateFiled.code() + &quot;:&quot; + validateFiled.message());          throw new RuntimeException(validateFiled.code()  + &quot;:&quot; + validateFiled.message());        &#125;      &#125;      //3.5判断数值最小值   当不是默认值0x0.0000000000001P-1022的时候进行判断      if (validateFiled.minVal() != 0x0.0000000000001P-1022) &#123;        if (Double.parseDouble(arg.toString()) &lt; validateFiled.minVal()) &#123;//          logger.error(validateFiled.code() + &quot;:&quot; + validateFiled.message());          throw new RuntimeException(validateFiled.code()  + &quot;:&quot; + validateFiled.message());        &#125;      &#125;      //3.6判断正则 若未设置正则校验则跳过      if (!&quot;&quot;.equals(validateFiled.regStr())) &#123;        if (arg instanceof String || arg instanceof Integer || arg instanceof BigDecimal || arg instanceof Double) &#123;          if (!(arg.toString()).matches(validateFiled.regStr())) &#123;//            logger.error(validateFiled.code() + &quot;:&quot; + validateFiled.message());            throw new RuntimeException(validateFiled.code()  + &quot;:&quot; + validateFiled.message());          &#125;        &#125;      &#125;    &#125;    return;  &#125;&#125;</code></pre><h2 id="5-3接口测试"><a href="#5-3接口测试" class="headerlink" title="5.3接口测试"></a>5.3接口测试</h2><pre><code>@RestController@RequestMapping(&quot;validater&quot;)public class ValidateController &#123;  @ValidateGroup(fields = &#123;      //如果是index=0也可以省略不写      @ValidateField(index = 0,notNull = true,maxLen = 10,code = &quot;param1-error&quot;,message = &quot;param1校验错误&quot;),      @ValidateField(index = 1,notNull = true,fieldName = &quot;passWord&quot;,minLen = 6,code = &quot;passWord-erro&quot;,message = &quot;密码校验错误&quot;),      @ValidateField(index = 1,notNull = true,fieldName = &quot;age&quot;,minVal = 0,code = &quot;age-error&quot;,message = &quot;年龄不能小于0&quot;),      @ValidateField(index = 1,notNull = true,fieldName = &quot;tall&quot;,minVal = 0,maxVal = 250.9,code =&quot;tall-error&quot;,message = &quot;身高范围出错&quot;),      @ValidateField(index = 1,notNull = true,fieldName = &quot;phone&quot;,regStr = &quot;^(13[0-9]|14[01456879]|15[0-35-9]|16[2567]|17[0-8]|18[0-9]|19[0-35-9])\\d&#123;8&#125;$&quot;,code = &quot;phone-error&quot;,message = &quot;手机号错误&quot;)  &#125;)  @PostMapping(&quot;post&quot;)  public String postValidater(@RequestParam String param1,  RegisterDto dto)&#123;    System.out.println(&quot;成功通过校验&quot;);    System.out.println(&quot;第一个参数是：&quot; + param1);    System.out.println(&quot;第二个参数是&quot;+dto.toString());    return &quot;succeed&quot;;  &#125;&#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/e5f4ac9d44474348ba35f74fc9263209.png"><br>如果参数错误，则会直接抛异常终止请求<br><img src="https://img-blog.csdnimg.cn/09ae76ac260b4970a236069c7e020fa6.png"></p><p>如果参数都正确就可以通过校验，如下：<br><img src="https://img-blog.csdnimg.cn/1f5e188fef6142eca85c1074208832ee.png"></p><h1 id="6-可扩展的点"><a href="#6-可扩展的点" class="headerlink" title="6.可扩展的点"></a>6.可扩展的点</h1><p>传入的参数是加密后的，那么可以再写一个拦截器对入参dto中的属性进行解密，这里可以参考<br><a href="https://zjhblog.gitee.io/zjh/2022/08/12/%E5%AF%B9dto%E6%8C%87%E5%AE%9A%E5%B1%9E%E6%80%A7%E4%B8%80%E9%94%AE%E5%8A%A0%E8%A7%A3%E5%AF%86/">对dto指定属性一键加解密</a></p><p>也可以调用这个工具类直接写在这个AspectJ里面</p>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>对dto指定属性一键加解密</title>
      <link href="/zjh/2022/08/12/%E5%AF%B9dto%E6%8C%87%E5%AE%9A%E5%B1%9E%E6%80%A7%E4%B8%80%E9%94%AE%E5%8A%A0%E8%A7%A3%E5%AF%86/"/>
      <url>/zjh/2022/08/12/%E5%AF%B9dto%E6%8C%87%E5%AE%9A%E5%B1%9E%E6%80%A7%E4%B8%80%E9%94%AE%E5%8A%A0%E8%A7%A3%E5%AF%86/</url>
      
        <content type="html"><![CDATA[<p>在第一份电商实习的时候，公司对于接口的规范是：</p><ul><li>入参必须封装为一个dto用@RequestBody接收；</li><li>出参也必须封装为一个Dto然后转JSON</li></ul><p>但对于某些属性的加密解密，只是机械的直接对某个属性进行set。这个方法可以一键对dto指定属性加密解密<br>虽然已经过了几个月了，但是还是来复盘一下吧</p><h1 id="1-实现思路"><a href="#1-实现思路" class="headerlink" title="1.实现思路"></a>1.实现思路</h1><ul><li>用<code>CodecUtils.encodeDtoField(xxxDto)</code>对dto里面的指定属性进行加密</li><li>用<code>@DtoEncoder</code>标注在属性上，决定是否被加密  </li><li>用<code>@DtoEncoder(Boolean force)</code>注解的参数来决定是否强制加密  </li></ul><p>以上decoder和encoder同理（解密）</p><h1 id="2-使用实例"><a href="#2-使用实例" class="headerlink" title="2.使用实例"></a>2.使用实例</h1><h2 id="2-1入参实体类Dto"><a href="#2-1入参实体类Dto" class="headerlink" title="2.1入参实体类Dto"></a>2.1入参实体类Dto</h2><p>这里只展示入参，需要加密的属性，如果是出参可以使用@DtoEncoder</p><pre><code>public class LoginDto &#123;String name;//passWord将会被解密(因为传参过来的时候是加密的，所以需要先解密)@DtoDecoderString passWord;//这个test属性不会被解密@DtoDecoder(force = false)String test;&#125;</code></pre><h2 id="2-2调用解密方法"><a href="#2-2调用解密方法" class="headerlink" title="2.2调用解密方法"></a>2.2调用解密方法</h2><pre><code>//这将会对passWord进行解密LoginDto destLoginDto = CodecUtils.decodeDtoField(loginDto);</code></pre><h1 id="3-具体实现"><a href="#3-具体实现" class="headerlink" title="3.具体实现"></a>3.具体实现</h1><h2 id="3-1加密解密注解"><a href="#3-1加密解密注解" class="headerlink" title="3.1加密解密注解"></a>3.1加密解密注解</h2><h3 id="3-1-1加密注解"><a href="#3-1-1加密注解" class="headerlink" title="3.1.1加密注解"></a>3.1.1加密注解</h3><pre><code>@Documented@Target(&#123;ElementType.FIELD&#125;)@Retention(RUNTIME)public @interface DtoEncoder &#123;/*** true：必须转（无论是否已转码，都需要进行转换），false：非必须转（如果已转码，则不会再次进行转换）*/boolean force() default true;&#125;</code></pre><h3 id="3-1-2解密注解"><a href="#3-1-2解密注解" class="headerlink" title="3.1.2解密注解"></a>3.1.2解密注解</h3><pre><code>@Documented@Target(&#123;ElementType.FIELD&#125;)@Retention(RUNTIME)public @interface DtoDecoder &#123;/*** true：必须转（无论是否已转码，都需要进行转换），false：非必须转（如果已转码，则不会再次进行转换）*/boolean force() default true;&#125;</code></pre><h2 id="3-2加密解密工具类"><a href="#3-2加密解密工具类" class="headerlink" title="3.2加密解密工具类"></a>3.2加密解密工具类</h2><pre><code>public class CodecUtils &#123;public static String encode(String src)&#123;    return &quot;加密过程省略&quot;;&#125;public static String decode(String src)&#123;    return &quot;解密过程省略&quot;;&#125;/*** 对dto进行加密，需要判断force属性* @Author: zjh* @Date: 2022/8/12 22:22*/public static &lt;T&gt; T encodeDtoField(T dto) &#123;    if (dto != null) &#123;    try &#123;        Class&lt;?&gt; dtoClass = dto.getClass();        Field[]  fields   = dtoClass.getDeclaredFields();        for (Field field : fields) &#123;        //对使用@DtoEncoder注解的属性进行加密        if (field.isAnnotationPresent(DtoEncoder.class)) &#123;            field.setAccessible(true);            Object obj = field.get(dto);            String value = obj == null ? &quot;&quot; : String.valueOf(obj);            DtoEncoder dtoEncoder = field.getAnnotation(DtoEncoder.class);            //如果force设置为false，则不加密，@DtoEncoder(true)相当于没有写这个注解            if (dtoEncoder.force()) &#123;            field.set(dto, encode(value));            &#125;        &#125;        &#125;        return dto;    &#125;    catch (Exception e) &#123;        throw new RuntimeException(&quot;dto encode error&quot;, e);    &#125;    &#125;    return null;&#125;/*** 对dto进行解密，需要判断force属性* @Author: zjh* @Date: 2022/8/12 22:22*/public static &lt;T&gt; T decodeDtoField(T dto) &#123;    if (dto != null) &#123;    try &#123;        Class&lt;?&gt; dtoClass = dto.getClass();        Field[]  fields   = dtoClass.getDeclaredFields();        for (Field field : fields) &#123;        //对使用@DtoEncoder注解的属性进行加密        if (field.isAnnotationPresent(DtoDecoder.class)) &#123;            field.setAccessible(true);            Object obj = field.get(dto);            String value = obj == null ? &quot;&quot; : String.valueOf(obj);            DtoDecoder dtoDecoder = field.getAnnotation(DtoDecoder.class);            //如果force设置为false，则不加密，@DtoEncoder(true)相当于没有写这个注解            if (dtoDecoder.force()) &#123;            field.set(dto, decode(value));            &#125;        &#125;        &#125;        return dto;    &#125;    catch (Exception e) &#123;        throw new RuntimeException(&quot;dto encode error&quot;, e);    &#125;    &#125;    return null;&#125;&#125;</code></pre><h1 id="4-小结"><a href="#4-小结" class="headerlink" title="4.小结"></a>4.小结</h1><ul><li>因为有的数据很敏感，出参入参都需要解密加密，如果一个dto有多个需要解密加密的属性，那用这个方法再合适不过了</li><li>至于为何不用拦截器+反射处理：如果用拦截器直接对入参dto进行解密，虽然可以减少一些代码量，但同时也更加笨重</li></ul>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>反射修改jsessionid实现session共享</title>
      <link href="/zjh/2022/08/03/%E5%8F%8D%E5%B0%84%E4%BF%AE%E6%94%B9jsessionid%E5%AE%9E%E7%8E%B0session%E5%85%B1%E4%BA%AB/"/>
      <url>/zjh/2022/08/03/%E5%8F%8D%E5%B0%84%E4%BF%AE%E6%94%B9jsessionid%E5%AE%9E%E7%8E%B0session%E5%85%B1%E4%BA%AB/</url>
      
        <content type="html"><![CDATA[<p>1~7为源码分析，8为最终改造代码（工具类）</p><ul><li>虽然说前端可以通过伪造Cookie中的JESESSIONID来模拟劫持</li><li>而后端<strong>并不能直接通过原生API</strong>成功修改JESSIONID获取指定session。我在阅读源码后推测很多年前支持直接指定jsessionid，但现在只能通过反射修改session获取逻辑</li><li> 本案例一共12000字，源码分析部分10000字左右</li></ul><h1 id="0-Session域的大体流程"><a href="#0-Session域的大体流程" class="headerlink" title="0.Session域的大体流程"></a>0.Session域的大体流程</h1><p>先大概了解一下为了创建Session会话域，原生API做了什么</p><ul><li>存在一个接口：HttpServletRequest，有实现类Request、RequestFacade（外观模式，也是实际请求对象）</li><li>Session对象维护在Request中</li><li>Request对象维护在RequestFacade中<img src="https://img-blog.csdnimg.cn/86b981f85bbc4d16928a4e3024abe45a.png"></li></ul><h2 id="0-1第一次：创建Session"><a href="#0-1第一次：创建Session" class="headerlink" title="0.1第一次：创建Session"></a>0.1第一次：创建Session</h2><ul><li>JSESSIONID是在请求打过来的时候初始化的时候，用<code>ServerCookie</code>对Request进行了赋值（Request类是HttpServletRequest的实现类）</li><li>然后创建一个供用户使用的Cookie（实际上是ServerCookie的拷贝值、<strong>ServerCookie不允许用户使用</strong>） </li><li>请求打过来的初始化过程就对Request对象的<code>Session和jsessionid</code>属性进行了绑定</li><li>Request对象的<code>Session和jsessionid</code>属性（主要是这两个）在很多地方都起着互相校验的功能（<strong>修改时需要两个一起修改，否则会导致request.getSession()时重新生成Session</strong>）</li></ul><h2 id="0-2第二次：获取Session"><a href="#0-2第二次：获取Session" class="headerlink" title="0.2第二次：获取Session"></a>0.2第二次：获取Session</h2><ul><li>ServerCookie中携带的jseesionid赋值给Request对象</li><li>请求打过来时<strong>被预先处理</strong>，调用<code>request -》context -》manager</code>的<code>findSession</code>方法直接获取Session后<strong>传给Request对象当形参</strong></li><li>之后使用request.getSession()调用则<strong>直接调用</strong>Request的属性地址</li></ul><p>下面进行论述</p><h1 id="1-前端设置Cookie再发送"><a href="#1-前端设置Cookie再发送" class="headerlink" title="1.前端设置Cookie再发送"></a>1.前端设置Cookie再发送</h1><p>那么正常情况下我们切换浏览器（切换Session）是不能够获取这个k-v对的，但是我们可以通过在<code>浏览器、PostMan、js代码</code>将JSESSIONID设置为刚才的<br>这样就能在服务器中劫持Session了<img src="https://img-blog.csdnimg.cn/8f1447491cd441078be3d676f634f0ce.png">但是实际开发环境中，这种方案可行度接近于0，<strong>那么尝试下后端原生API修改Cookie的值？？</strong></p><h1 id="2-后端设置Cookie值"><a href="#2-后端设置Cookie值" class="headerlink" title="2.后端设置Cookie值"></a>2.后端设置Cookie值</h1><h2 id="2-1输出JSESSIONID"><a href="#2-1输出JSESSIONID" class="headerlink" title="2.1输出JSESSIONID"></a>2.1输出JSESSIONID</h2><pre><code>Cookie[] cookies = request.getCookies();    if(cookies!=null)for(Cookie c: cookies)&#123;  //此案例中Cookie仅包含JSESIONID，等价于(request.getSession().getId())  System.out.println(c.getName()+&quot;:&quot;+c.getValue());&#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/be0458c3d1734ee299440cb92417d948.png"></p><h2 id="2-2修改JSESSIONID"><a href="#2-2修改JSESSIONID" class="headerlink" title="2.2修改JSESSIONID"></a>2.2修改JSESSIONID</h2><pre><code>request.getCookies()[0].setValue(&quot;newJSessionId&quot;);</code></pre><p><img src="https://img-blog.csdnimg.cn/bdec123319b34d33981f784b870d853c.png"></p><h2 id="2-3getSession-不变"><a href="#2-3getSession-不变" class="headerlink" title="2.3getSession()不变"></a>2.3getSession()不变</h2><pre><code>//还是之前的JSESSIONIDSystem.out.println(request.getSession().getId());</code></pre><h1 id="3-后端为什么不能修改Session"><a href="#3-后端为什么不能修改Session" class="headerlink" title="3.后端为什么不能修改Session"></a>3.后端为什么不能修改Session</h1><h2 id="3-1虽然后端是可以修改Cookie的"><a href="#3-1虽然后端是可以修改Cookie的" class="headerlink" title="3.1虽然后端是可以修改Cookie的"></a>3.1虽然后端是可以修改Cookie的</h2><p>比如在使用<br> <code> request.getCookies()[0].setValue(&quot;newJSessionId&quot;);</code><br> 修改了Cookie之后，重新获取的Cookie确实是最新修改后的</p><pre><code>    Cookie[] cookies2 = request.getCookies();    if(cookies!=null)      for(Cookie c: cookies2)&#123;        System.out.println(c.getName()+&quot;:&quot;+c.getValue());      &#125;</code></pre><p>但是出了另外一个问题，<strong>Cookie能修改，Cookie中的JESSIONID修改后却没有用？</strong></p><h2 id="3-2修改JSESSIONID但无效"><a href="#3-2修改JSESSIONID但无效" class="headerlink" title="3.2修改JSESSIONID但无效"></a>3.2修改JSESSIONID但无效</h2><h3 id="3-2-1debug：getSession"><a href="#3-2-1debug：getSession" class="headerlink" title="3.2.1debug：getSession()"></a>3.2.1debug：getSession()</h3><p>一直跟进<code>request.getSession()</code>方法，发现修改Cookie中JSESSIONID之前和之后都是在这个地方返回的session对象，<strong>证明在getSession()之前，session一定被初始化了，修改Cookie不影响直接获取session</strong><br><img src="https://img-blog.csdnimg.cn/01c148e0a43c489a9d8bf98b3a1ee927.png"></p><ul><li>整个过程没有看到任何跟Cookie中JSESSIONID有关的代码</li></ul><ul><li>因此可以大胆推测：<strong>session对象早在请求打过来的时候就获取了其对应的地址值，后期修改Cookie不会导致session对象指向的地址改变</strong></li></ul><h1 id="4-session初始化过程-多次请求的角度"><a href="#4-session初始化过程-多次请求的角度" class="headerlink" title="4.session初始化过程(多次请求的角度)"></a>4.session初始化过程(多次请求的角度)</h1><p>既然session不能被中途修改，那么一定是在初始化的时候，从Cookie中取出JSESSIONID，然后赋值给的session</p><h2 id="4-1利用debug技巧定位"><a href="#4-1利用debug技巧定位" class="headerlink" title="4.1利用debug技巧定位"></a>4.1利用debug技巧定位</h2><p><strong>一个小技巧</strong>，可以在session对象上面打一个断点，每次（按F9）执行到修改session值的时候都会进入<img src="https://img-blog.csdnimg.cn/69bf55cd80154168915c009b5a073f31.png"></p><h2 id="4-2模拟创建Session"><a href="#4-2模拟创建Session" class="headerlink" title="4.2模拟创建Session"></a>4.2模拟创建Session</h2><ul><li>现在代码里写一个<code>request.getSession()</code>;然后新开一个浏览器请求两次，<strong>模拟创建Session和寻找Session的过程</strong></li><li>Session的使用是<code>懒汉式</code>的，<strong>如果你不调getSession方法，他就不会去创建，更不会在响应Cookie里面携带JSESSIONID</strong>。</li><li><strong>Session的创建是懒汉，但并不意味着有关Session的配置信息的初始化是懒汉的</strong><h3 id="4-2-1创建Session"><a href="#4-2-1创建Session" class="headerlink" title="4.2.1创建Session"></a>4.2.1创建Session</h3></li></ul><p><img src="https://img-blog.csdnimg.cn/1d7b6a71d3354fedbba9620e2b6b1902.png"></p><h3 id="4-2-2寻找Session"><a href="#4-2-2寻找Session" class="headerlink" title="4.2.2寻找Session"></a>4.2.2寻找Session</h3><p><img src="https://img-blog.csdnimg.cn/c8aaf611bb7a430f94a93b6679d2a4f1.png"></p><h3 id="4-2-3释放"><a href="#4-2-3释放" class="headerlink" title="4.2.3释放"></a>4.2.3释放</h3><p>释放环节，为下一次请求做准备<br><img src="https://img-blog.csdnimg.cn/fc468410164b41f4a1210402ecaee7fb.png"></p><p><img src="https://img-blog.csdnimg.cn/4eb868bee6044898a091b6c8e735733a.png"></p><h2 id="4-3模拟第二次请求Session"><a href="#4-3模拟第二次请求Session" class="headerlink" title="4.3模拟第二次请求Session"></a>4.3模拟第二次请求Session</h2><p>浏览器刷新一下请求</p><h3 id="4-3-1直接寻找Session"><a href="#4-3-1直接寻找Session" class="headerlink" title="4.3.1直接寻找Session"></a>4.3.1直接寻找Session</h3><p>这次不需要创建，而是直接根据requestedSesionId来寻找，然后将其维护在request的session属性中<br><img src="https://img-blog.csdnimg.cn/c8aaf611bb7a430f94a93b6679d2a4f1.png"></p><h3 id="4-3-2释放"><a href="#4-3-2释放" class="headerlink" title="4.3.2释放"></a>4.3.2释放</h3><p>再次释放资源<br><img src="https://img-blog.csdnimg.cn/4eb868bee6044898a091b6c8e735733a.png"></p><h2 id="4-4小结"><a href="#4-4小结" class="headerlink" title="4.4小结"></a>4.4小结</h2><p>Session的<strong>创建，寻找</strong>都是在<code>doGetSession(boolean create)</code>方法中完成的。</p><h1 id="5-getSession的实现-多次调用的角度"><a href="#5-getSession的实现-多次调用的角度" class="headerlink" title="5.getSession的实现(多次调用的角度)"></a>5.getSession的实现(多次调用的角度)</h1><p>由上述可知，getSession()最终调用的逻辑一定是doGetSession()，验证一下</p><p><img src="https://img-blog.csdnimg.cn/2746e2619eb44a768dcdacfbcb7d80dc.png"></p><ul><li><strong>应该找与Request同包的，里面只有两个</strong></li></ul><h2 id="5-1基本结构"><a href="#5-1基本结构" class="headerlink" title="5.1基本结构"></a>5.1基本结构</h2><h3 id="5-1-1外观模式Facade"><a href="#5-1-1外观模式Facade" class="headerlink" title="5.1.1外观模式Facade"></a>5.1.1外观模式Facade</h3><ul><li>Facade是外观模式，最终的调用者肯定都是<code>request</code></li></ul><p><img src="https://img-blog.csdnimg.cn/6da00f7266564ef7bf140eb410ad467a.png"></p><h3 id="5-1-2Request中的getSession-create"><a href="#5-1-2Request中的getSession-create" class="headerlink" title="5.1.2Request中的getSession(create)"></a>5.1.2Request中的getSession(create)</h3><p>这里明显有个create，<strong>决定这个方法是获取还是创建</strong></p><ul><li>明显空参的是使用的时候调</li><li>带参的一定带false参数，在初始化的时候调<br><img src="https://img-blog.csdnimg.cn/c179c9130bad4363bd620dc2b7b1a5e9.png"><h2 id="5-2一次请求，多次getSession"><a href="#5-2一次请求，多次getSession" class="headerlink" title="5.2一次请求，多次getSession()"></a>5.2一次请求，多次getSession()</h2>在接口中写下代码模拟调用两次getSession()。现在仅模拟第二次请求（不需要再去创建Session，只需要去寻找Session）</li></ul><pre><code>HttpSession session1 = request.getSession();HttpSession sessio2n = request.getSession();</code></pre><p>通过debug可以知道</p><ul><li>session1 需要先findSession把session交给request去维护，然后从request中取session对象</li><li>而sessio2n 只需要直接从request中取session对象</li></ul><h2 id="5-3小结"><a href="#5-3小结" class="headerlink" title="5.3小结"></a>5.3小结</h2><p>通过上面的案例可以侧面反映出大标题4中为什么最后需要进行<code>资源释放</code></p><h1 id="6-Session流程总结"><a href="#6-Session流程总结" class="headerlink" title="6.Session流程总结"></a>6.Session流程总结</h1><h2 id="6-1创建和获取都是懒汉式的"><a href="#6-1创建和获取都是懒汉式的" class="headerlink" title="6.1创建和获取都是懒汉式的"></a>6.1创建和获取都是懒汉式的</h2><h3 id="6-1-1创建懒汉式"><a href="#6-1-1创建懒汉式" class="headerlink" title="6.1.1创建懒汉式"></a>6.1.1创建懒汉式</h3><ul><li>如果<code>每次请求</code>都不需要getSession()，那么<strong>Session永不创建</strong>，<strong>Cookie中的JSESSIONID永不创建</strong></li></ul><h3 id="6-1-2获取懒汉式"><a href="#6-1-2获取懒汉式" class="headerlink" title="6.1.2获取懒汉式"></a>6.1.2获取懒汉式</h3><ul><li>如果<code>一次请求</code>中多次使用getSession()，那么只有第一次会涉及createSession、findSession、request.session获取</li><li>而<code>接下来</code>每一次都只直接request.session获取</li></ul><h2 id="6-2路径变量历史遗留问题"><a href="#6-2路径变量历史遗留问题" class="headerlink" title="6.2路径变量历史遗留问题"></a>6.2路径变量历史遗留问题</h2><p>早期应该是可以通过url上指定jsessionid来设置的，现在会覆盖掉导致设置失效</p><h2 id="6-3创建、数据预置的关系"><a href="#6-3创建、数据预置的关系" class="headerlink" title="6.3创建、数据预置的关系"></a>6.3创建、数据预置的关系</h2><ul><li>其实在<code>CoyoteAdapter</code>类的后置初始化过程中，会将jsessionid写入request，至于你用不用session完全取决于自己。</li><li>这个过程是数据预置，预置了也不一定会创建or获取</li></ul><p><strong>那么问题现在转成了这个requestSessionId是如何被初始化的</strong></p><h1 id="7-CoyoteAdapter-初始化过程"><a href="#7-CoyoteAdapter-初始化过程" class="headerlink" title="7.CoyoteAdapter(初始化过程)"></a>7.CoyoteAdapter(初始化过程)</h1><p>适配器模式的 Adapter接口的一个实现类<br>观察里面的方法，并在<code>service</code> <code>postParseRequest</code>的开头分别打上断点<br>其中<code>service(核心业务)</code>先将Requset对象进行创建，<br>然后<code>postParseRequest(后置处理)</code>将req写入request</p><pre><code>一个题外话，关于url上面可能字符被编码成了%xxx%yyy也是在这里面进行解码的</code></pre><h2 id="7-1postParseRequest"><a href="#7-1postParseRequest" class="headerlink" title="7.1postParseRequest()"></a>7.1postParseRequest()</h2><p>这个方法名结合注释可知：解析完request之后必须要做的一些事。在开头打个断点然后发请求<br><img src="https://img-blog.csdnimg.cn/b983e5fc6e604f77ac91f7fd9912d635.png"></p><h3 id="7-1-1request对象赋值"><a href="#7-1-1request对象赋值" class="headerlink" title="7.1.1request对象赋值"></a>7.1.1request对象赋值</h3><p>在执行postParseRequest()之前，request对象中还没有值，所有的请求的值都存在于<code>org.apache.coyote.Request req</code>中 执行完成之后就将请求参数赋值给了request</p><p><img src="https://img-blog.csdnimg.cn/1f290a3fa994429e84ddcf929a9a6664.png"></p><ul><li><strong>注意这三个的顺序！</strong></li><li>后面经分析我认为这个parsePathParameters解析路径变量是一个<strong>历史遗留问题</strong>，以前应该是支持的，现在无论如何都会被下面的逻辑覆盖<br><img src="https://img-blog.csdnimg.cn/8702cbfecc3e41aeba2cecf49bf00b18.png"></li></ul><h3 id="7-1-2先parsePathParameters解析路径变量"><a href="#7-1-2先parsePathParameters解析路径变量" class="headerlink" title="7.1.2先parsePathParameters解析路径变量"></a>7.1.2先parsePathParameters解析路径变量</h3><p>按这种url格式发送<a href="http://localhost:8088/pic/people/pic1;jsessionid=F0D3200C7D61C8D41E129924585B6234">http://localhost:8088/pic/people/pic1;jsessionid=F0D3200C7D61C8D41E129924585B6234</a></p><p><img src="https://img-blog.csdnimg.cn/f364b20a9b954a528804993d35ae5d89.png"></p><p>这里通过解析request.getParam   用这个枚举类，即<strong>解析路径变量中的jessesionid</strong> 然后赋值给request<img src="https://img-blog.csdnimg.cn/f480e850673347b1baf6cbbdd0358b4e.png"></p><p><img src="https://img-blog.csdnimg.cn/d04db5de9fd442ddb3d27fd66fa4c311.png"></p><h3 id="7-1-3然后parseSessionCookiesId"><a href="#7-1-3然后parseSessionCookiesId" class="headerlink" title="7.1.3然后parseSessionCookiesId"></a>7.1.3然后parseSessionCookiesId</h3><ul><li>这里并没有将<code>Cookie</code>赋值给request，而是直接从<code>ServerCookie</code>中取值JSESSIONID塞给<code>request</code></li><li>并且这个方法是在7.1.1之后执行的，也就是即便是路径变量中写了这个参数也会被覆盖<br><img src="https://img-blog.csdnimg.cn/9928f158ef324b9480bcdaeb859e2e3a.png"><br><img src="https://img-blog.csdnimg.cn/6caefbb14071416ead6e94a34b481e55.png"></li></ul><h3 id="7-1-3被覆盖的路径变量jsessionid-历史遗留问题"><a href="#7-1-3被覆盖的路径变量jsessionid-历史遗留问题" class="headerlink" title="7.1.3被覆盖的路径变量jsessionid(历史遗留问题)"></a>7.1.3被覆盖的路径变量jsessionid(历史遗留问题)</h3><p><a href="http://localhost:8088/pic/people/pic1;jsessionid=F0D3200C7D61C8D41E129924585B623%E8%BF%99%E6%A0%B7%E7%9A%84%E5%86%99%E6%B3%95%EF%BC%8C%E4%BC%9A%E5%AF%BC%E8%87%B4%EF%BC%9A">http://localhost:8088/pic/people/pic1;jsessionid=F0D3200C7D61C8D41E129924585B623这样的写法，会导致：</a></p><ul><li>先修改成功request中的sessionid</li><li>然后<strong>再次被ServerCookie中的sessionid所覆盖</strong></li><li>然后再用这个sessionid去获取Session对象<h2 id="7-2小结"><a href="#7-2小结" class="headerlink" title="7.2小结"></a>7.2小结</h2></li></ul><h3 id="7-2-1后端修改为何没用"><a href="#7-2-1后端修改为何没用" class="headerlink" title="7.2.1后端修改为何没用"></a>7.2.1后端修改为何没用</h3><p>正是因为JSESSIONID是在这个<code>CoyoteAdapter</code>类中的<code>postParseRequest()</code>方法中的<code>parseSessionCookiesId()</code>方法中就对JSESSIONID进行了赋值，导致如下情况：</p><ul><li>前端请求可以通过修改Cookie中的JSESSIONID来实现获取指定session</li><li>但后端<strong>不能</strong>通过request在代码中修改Cookie中的JSESSIONID来实现获取指定session，也不能指定路径变量jsessionid（可能是历史遗留问题，会被覆盖）</li></ul><h3 id="7-2-2Cookie和ServerCookie"><a href="#7-2-2Cookie和ServerCookie" class="headerlink" title="7.2.2Cookie和ServerCookie"></a>7.2.2Cookie和ServerCookie</h3><p>很明显这个JSESSIONID是从ServerCookie中获取的，那二者有什么区别呢？</p><p><img src="https://img-blog.csdnimg.cn/e5e8d921dca746e69eee08b1646f01a0.png"></p><p>ServerCookie来自于coyoteRequest，即tomcat的底层实现，因此不能针对其Cookie进行修改从而达到模拟session的效果<br><img src="https://img-blog.csdnimg.cn/c23451ee616b4bdaba411117939b2c77.png"><br><img src="https://img-blog.csdnimg.cn/251b2b5c84b8424583c463d2f36aad76.png"></p><h1 id="8-反射"><a href="#8-反射" class="headerlink" title="8.反射"></a>8.反射</h1><p>因为<code>request.getSession()</code>调用的是Reuqest类下的<code>doGetSession()</code>，<code>requestedSessionId</code>又是Request下的属性，那么能不能通过反射修改requestedSessionId的值来修改<code>findSession()</code>的结果呢？答案是可以</p><p><img src="https://img-blog.csdnimg.cn/acdd4d91d81f4aa9ad6f7232257df7fa.png"></p><h2 id="8-0撸工具类的前提知识"><a href="#8-0撸工具类的前提知识" class="headerlink" title="8.0撸工具类的前提知识"></a>8.0撸工具类的前提知识</h2><ul><li>通常作为形参进行传递的<code>HttpServletRequest</code>是一个接口，实际上传递是是其实现类<code>RequestFacade</code>，在涉及到反射操作的时候需要再开辟一个<code>RequestFacade</code>的栈空间指向<code>HttpServletRequest</code>堆空间</li><li>外观模式：<code>RequestFacade</code>实际上大部分调用的是<code>Request</code></li><li>Request下的<code>doGetSession(Boolean craete)</code>是最终获取Session对象的方法，包括初始化时session的生成、httpServletRequest.getSeesion()获取。区别是<strong>前者形参create=true、后者形参create=false</strong></li><li>在Request类下的doGetSession()方法中，当<strong>存在session时</strong>直接走<code>manager.findSession(sessionId)</code>；<strong>当初始化时</strong>，先<code>getRequestedSessionId()</code>根据JVM随机数获取sessionid，然后作为形参调用<code>session = manager.createSession(sessionId);</code></li></ul><p>因此可以有如下两条思路： </p><ol><li>通过findSession()直接从ConcurrentHashMap中获取Session对象</li><li>通过对doGetSession()的所需的参数进行一个覆盖操作</li></ol><h2 id="8-1根据JSESSIONID直接返回Session对象"><a href="#8-1根据JSESSIONID直接返回Session对象" class="headerlink" title="8.1根据JSESSIONID直接返回Session对象"></a>8.1根据JSESSIONID直接返回Session对象</h2><pre><code>   /**     * @param httpServletRequest 多态性，本质是requestFacade     * @param jsessionid 指定的jsessionid     * @return javax.servlet.http.HttpSession 指定的Session对象     **/    public static HttpSession getSession(HttpServletRequest httpServletRequest,String jsessionid) throws  Exception&#123;        RequestFacade requestFacade = (RequestFacade)httpServletRequest;        Class&lt;? extends RequestFacade&gt; facadeClazz = requestFacade.getClass();        Field requestField = facadeClazz.getDeclaredField(&quot;request&quot;);        requestField.setAccessible(true);        Request request = (Request)requestField.get(requestFacade);        Context context = request.getContext();        Manager manager = context.getManager();        Session session = manager.findSession(jsessionid);        return session.getSession();    &#125;</code></pre><h2 id="8-2将指定的Session和JSESSIONID赋值给request"><a href="#8-2将指定的Session和JSESSIONID赋值给request" class="headerlink" title="8.2将指定的Session和JSESSIONID赋值给request"></a>8.2将指定的Session和JSESSIONID赋值给request</h2><pre><code>/** * @Description 调用此方法后，httpServletRequest.getSession()获取的是jsessionid对应的Session * @Author zjh * @Date 17:59 2022/8/3 * @param httpServletRequest 请求头，用于获取session * @param jsessionid 指定的sessionid * @return void **/public static void setSession2Request(HttpServletRequest httpServletRequest,String jsessionid) throws Exception&#123;    //RequestFacade    RequestFacade requestFacade = (RequestFacade) httpServletRequest;    Class&lt;? extends RequestFacade&gt; facadeClazz = requestFacade.getClass();    //RequestFacade获取Request    Field requestField = facadeClazz.getDeclaredField(&quot;request&quot;);    requestField.setAccessible(true);    //Request    Request request = (Request)requestField.get(requestFacade);    Class&lt;? extends Request&gt; requestClazz = request.getClass();    //Request设置Session=null    Field sessionField = requestClazz.getDeclaredField(&quot;session&quot;);    sessionField.setAccessible(true);    sessionField.set(request,null);    //Request设置requestedSessionId = 指定值    Field requestedSessionIdField = requestClazz.getDeclaredField(&quot;requestedSessionId&quot;);    requestedSessionIdField.setAccessible(true);    requestedSessionIdField.set(request,jsessionid);&#125;</code></pre><h2 id="8-3最终工具类"><a href="#8-3最终工具类" class="headerlink" title="8.3最终工具类"></a>8.3最终工具类</h2><p>经过异常处理之后的呈现结果</p><pre><code>import java.io.IOException;import java.lang.reflect.Field;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpSession;import org.apache.catalina.Context;import org.apache.catalina.Manager;import org.apache.catalina.Session;import org.apache.catalina.connector.Request;import org.apache.catalina.connector.RequestFacade;import org.slf4j.Logger;import org.slf4j.LoggerFactory;/** * @Description Session共享的工具类，用于Session共享，可实现传入JSESSIONID返回对应Session对象，也可实现传入JSESSIONID永久修改request * @Author zjh * @Date 16:10 2022/8/3 **/public class SessionShareUtils &#123;    private static Logger logger = LoggerFactory.getLogger(&quot;SessionShareUtils&quot;);    /**     * @param httpServletRequest 多态性，本质是requestFacade     * @param jsessionid 指定的jsessionid     * @return org.apache.catalina.Session 指定的Session对象     **/    public static HttpSession getSession(HttpServletRequest httpServletRequest,String jsessionid) &#123;        Session session = null;        try &#123;            RequestFacade requestFacade = (RequestFacade)httpServletRequest;            Class&lt;? extends RequestFacade&gt; facadeClazz = requestFacade.getClass();            //获取Request 最后findSession            Field requestField = facadeClazz.getDeclaredField(&quot;request&quot;);            requestField.setAccessible(true);            Request request = (Request)requestField.get(requestFacade);            Context context = request.getContext();            Manager manager = context.getManager();            session = manager.findSession(jsessionid);        &#125;        catch (NoSuchFieldException e) &#123;            logger.error(&quot;反射找不到属性&#123;&#125;&quot;,e);        &#125;        catch (IllegalAccessException e) &#123;            logger.error(&quot;反射未设置允许访问&#123;&#125;&quot;,e);        &#125;        catch (IOException e) &#123;            logger.error(&quot;HttpServletRequest的IO异常&#123;&#125;&quot;,e);        &#125;        return session.getSession();    &#125;    /**     * @Description 调用此方法后，httpServletRequest.getSession()获取的是jsessionid对应的Session     * @Author zjh     * @Date 17:59 2022/8/3     * @param httpServletRequest 请求头，用于获取session     * @param jsessionid 指定的sessionid     * @return void     **/    public static void setSession2Request(HttpServletRequest httpServletRequest,String jsessionid) &#123;        try &#123;            //RequestFacade            RequestFacade requestFacade = (RequestFacade) httpServletRequest;            Class&lt;? extends RequestFacade&gt; facadeClazz = requestFacade.getClass();            //RequestFacade获取Request            Field requestField = facadeClazz.getDeclaredField(&quot;request&quot;);            requestField.setAccessible(true);            //Request            Request request = (Request)requestField.get(requestFacade);            Class&lt;? extends Request&gt; requestClazz = request.getClass();            //Request设置Session=null            Field sessionField = requestClazz.getDeclaredField(&quot;session&quot;);            sessionField.setAccessible(true);            sessionField.set(request,null);            //Request设置requestedSessionId = 指定值            Field requestedSessionIdField = requestClazz.getDeclaredField(&quot;requestedSessionId&quot;);            requestedSessionIdField.setAccessible(true);            requestedSessionIdField.set(request,jsessionid);        &#125;        catch (NoSuchFieldException e) &#123;            logger.error(&quot;反射找不到属性&#123;&#125;&quot;,e);        &#125;        catch (IllegalAccessException e) &#123;            logger.error(&quot;反射未设置允许访问&#123;&#125;&quot;,e);        &#125;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 源码 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>RestTemlate源码分析及工具类设计</title>
      <link href="/zjh/2022/08/03/RestTemlate%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E5%B7%A5%E5%85%B7%E7%B1%BB%E8%AE%BE%E8%AE%A1/"/>
      <url>/zjh/2022/08/03/RestTemlate%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E5%B7%A5%E5%85%B7%E7%B1%BB%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<p>先说个大概的结构：</p><ul><li>RestTemlate的所有方法最终调用的是<code>doExecute()</code>，层层向外封装</li><li>其中<code>exchange()</code>适合用来封装成工具类，他的返回值是ResponseEntity</li><li><code>postForObject()</code>  和 <code> postForEntity</code>本质上一样，只是<code>后者</code>对运行结果进行了封装，返回的也是ResponseEntity，类似于lambda表达式中的Option类</li></ul><p>1.本文的源码分析部分采用“从外到内”的顺序进行分析<br>2.类似postForObject和getForObject这种的区别仅仅是GET请求和POST请求的区别，本文仅分析POST请求的<br>3.postFroLocation()方法是返回一个URI，不是本文的重点</p><h1 id="1-返回值ResponseEntity有什么用？"><a href="#1-返回值ResponseEntity有什么用？" class="headerlink" title="1.返回值ResponseEntity有什么用？"></a>1.返回值ResponseEntity有什么用？</h1><h2 id="1-1-postForObject-和postForEntity"><a href="#1-1-postForObject-和postForEntity" class="headerlink" title="1.1 postForObject()和postForEntity()"></a>1.1 postForObject()和postForEntity()</h2><p><strong>看源码的注释部分，几乎一致，也就是两个方法基本没有什么区别</strong></p><p>其中一个返回值是封装类ResponseEntity</p><p><img src="https://img-blog.csdnimg.cn/ff77b26b03a846c0a63c5ab067ca1c2a.png"><br><strong>重要！！：关于提取响应的方式</strong></p><p>postForObject：<code>HttpMessageConvertExtractor</code><br>postforEntity：<code>ResponseExtractor</code><br>这两个Extractor类都有一个公共接口<code>extractData</code>，他在execute方法执行的时候被调用，用于获取HTTP响应的数据，只是在实现上，一个只获取响应体，另一个还要额外获取headers和status<br><img src="https://img-blog.csdnimg.cn/1134d9e8c5ba48ca8c789762e64b3932.png" alt="公共接口"></p><p><img src="https://img-blog.csdnimg.cn/cbb84d0aeee54c4a8d206a7ca16c84d2.png"></p><h2 id="1-2ResponseEntity的重要参数"><a href="#1-2ResponseEntity的重要参数" class="headerlink" title="1.2ResponseEntity的重要参数"></a>1.2ResponseEntity的重要参数</h2><p><strong>既然这个封装类有状态码status，响应头headers，那么一定在某个地方，getForObject没有去指定而getForEntity指定了</strong>（这时候应该猜到是extractData()方法，将在后面讨论）</p><p><img src="https://img-blog.csdnimg.cn/d5474ff09bc943b5afb10948902e1965.png" alt="形参"></p><p><img src="https://img-blog.csdnimg.cn/f65367f397be4f47aa015251311c2ac0.png" alt="父类"></p><h3 id="1-2-1状态码"><a href="#1-2-1状态码" class="headerlink" title="1.2.1状态码"></a>1.2.1状态码</h3><p><img src="https://img-blog.csdnimg.cn/cd139059659d4120a31725ab5fd0f4af.png"></p><h3 id="1-2-2-getBody-getHeaders"><a href="#1-2-2-getBody-getHeaders" class="headerlink" title="1.2.2 getBody() getHeaders()"></a>1.2.2 getBody() getHeaders()</h3><p>直接获取上面两个参数，不再赘述</p><h2 id="1-3ResponseEntity是如何封装返回值的？"><a href="#1-3ResponseEntity是如何封装返回值的？" class="headerlink" title="1.3ResponseEntity是如何封装返回值的？"></a>1.3ResponseEntity是如何封装返回值的？</h2><h3 id="1-3-1-responseExtrator-extractData-response-提取数据"><a href="#1-3-1-responseExtrator-extractData-response-提取数据" class="headerlink" title="1.3.1 responseExtrator.extractData(response)提取数据"></a>1.3.1 responseExtrator.extractData(response)提取数据</h3><ul><li>已知，最终都是调用doExecute()</li><li>两个方法到这里的Extractor都是非空的，都是一定要执行，两个执行逻辑不同</li></ul><p><img src="https://img-blog.csdnimg.cn/4617c2b5c4f342e8b090be01ea87b37e.png"></p><h3 id="1-3-2extractDatad抽象方法"><a href="#1-3-2extractDatad抽象方法" class="headerlink" title="1.3.2extractDatad抽象方法"></a>1.3.2extractDatad抽象方法</h3><p>这里直接看getForEntity对应的<code>ResponseEntityResponseExtractor</code>，<strong>即封装了status和headers的执行过程</strong></p><p><img src="https://img-blog.csdnimg.cn/8b3bff8efafa410ca33c7e9971af2d95.png"><br><strong>因此，只有返回值是Entity的才有headers和status，否则像getForObject这种方法返回的只是一个响应体</strong></p><p><img src="https://img-blog.csdnimg.cn/e3d76f4b94734da3919f2f0ba4cceef4.png"></p><h3 id="1-3-3公共的extractData-逻辑"><a href="#1-3-3公共的extractData-逻辑" class="headerlink" title="1.3.3公共的extractData()逻辑"></a>1.3.3公共的extractData()逻辑</h3><p>即两个都会调用的，上面那么打红框的，通篇都是只针对了响应体进行操作，没有涉及任何的headers和status</p><p><img src="https://img-blog.csdnimg.cn/0bb36eb745b948838436c3474fe09222.png"></p><h3 id="1-3-4nonNull检验是否为空"><a href="#1-3-4nonNull检验是否为空" class="headerlink" title="1.3.4nonNull检验是否为空"></a>1.3.4nonNull检验是否为空</h3><p>如果是封装为Entity，那么还要再加一层判断方法<img src="https://img-blog.csdnimg.cn/365add9267e14f11bcf45c145c8f4c1f.png"></p><h2 id="1-4小结"><a href="#1-4小结" class="headerlink" title="1.4小结"></a>1.4小结</h2><ul><li><p>到此为止我们分析了为什么getForObject()返回的只有响应体，而getForEntity()返回的包括了响应体 响应头  响应状态</p></li><li><p>而getForEntity()和exchange()返回的都是ResponseEntity对象，因此第二点引出二者的区别</p></li><li><p>get和post请求只有一个区别，后续会演示如何使用API<img src="https://img-blog.csdnimg.cn/2692bd692fd5477994460bb07621cbd1.png"></p></li></ul><h1 id="2-exchange-和xxxtForEntity"><a href="#2-exchange-和xxxtForEntity" class="headerlink" title="2.exchange()和xxxtForEntity()"></a>2.exchange()和xxxtForEntity()</h1><ul><li>可以看出区别就是<code>requestEntity</code>请求参数</li><li>至于请求方法method不是主要矛盾</li><li>这三个方法，参数所对应的含义如下：<br>第一个：url<br>对于exchange，第二个参数是请求方式自定义<br>第三个：请求体参数，exchange和post有，get没有，<strong>用map或dto或requestEntity封装</strong><br>第四个：返回值类型<br>第五个：路径参数，对应的是@RequestParam和@PathVariable，<strong>使用方式是在url中用{}占位</strong>，类似logger的{}，也类似String.format()中的%s占位，因此Object…uriVariables是一个可变数组</li></ul><p><img src="https://img-blog.csdnimg.cn/805cd29b3f874c5db1447b8403cc378b.png"></p><p><img src="https://img-blog.csdnimg.cn/4b0a8113b4814064af683d591efa2f3e.png"></p><p>这里找了一个写的比较全的API演示：<a href="https://blog.csdn.net/u012843361/article/details/79893638">参考链接</a></p><h2 id="2-1get占位符和可变数组"><a href="#2-1get占位符和可变数组" class="headerlink" title="2.1get占位符和可变数组"></a>2.1get占位符和可变数组</h2><h3 id="2-1-1-RequestParam案例"><a href="#2-1-1-RequestParam案例" class="headerlink" title="2.1.1@RequestParam案例"></a>2.1.1@RequestParam案例</h3><p>请求的接口有两个@RequestParam参数，通过姓名和性别获取图片的一个例子</p><pre><code>    ResponseEntity&lt;byte[]&gt; responseEntity =            restTemplate.getForEntity(&quot;http://localhost:8080/pic/pic1?name=&#123;name&#125;&amp;sex=&#123;sex&#125;&quot;, byte[].class,                    &quot;名字&quot;, &quot;性别&quot;);    ServletOutputStream os = response.getOutputStream();    os.write(responseEntity.getBody());</code></pre><p>当然对于@RequestParam最好的做法是放在最后一个形参中，传一个map，在后面会提到</p><h3 id="2-1-2-PathVariable案例"><a href="#2-1-2-PathVariable案例" class="headerlink" title="2.1.2@PathVariable案例"></a>2.1.2@PathVariable案例</h3><p>大同小异</p><pre><code> restTemplate.getForEntity(&quot;http://localhost:8080/pic/pic1/&#123;name&#125;/&#123;sex&#125;&quot;, byte[].class,                    &quot;名字&quot;, &quot;性别&quot;);</code></pre><h2 id="2-2post携带请求体"><a href="#2-2post携带请求体" class="headerlink" title="2.2post携带请求体"></a>2.2post携带请求体</h2><h3 id="2-2-1当本地有dto代码时-直接使用"><a href="#2-2-1当本地有dto代码时-直接使用" class="headerlink" title="2.2.1当本地有dto代码时-直接使用"></a>2.2.1当本地有dto代码时-直接使用</h3><p>当本地有dto代码的时候，第二个形参直接用dto就好</p><pre><code>    //当本地有dto的代码时,可以直接用dto来作为第二个请求体形参    People people = new People();    people.setAge(22);    people.setName(&quot;张三&quot;);    people.setTall(181);    //最后一个可变数组的形参不用指定    ResponseEntity&lt;byte[]&gt; res =            restTemplate.postForEntity(&quot;http://localhost:8080/pic/people/pic1&quot;, people, byte[].class);    ServletOutputStream os = response.getOutputStream();    os.write(res.getBody());</code></pre><p>但不一定是任何时候都有这个dto代码，如果没有这个dto代码，去调用其他的服务器，还需要写一个dto吗？不需要</p><h3 id="2-2-2-不能使用HashMap"><a href="#2-2-2-不能使用HashMap" class="headerlink" title="2.2.2 不能使用HashMap"></a>2.2.2 不能使用HashMap</h3><p>使用HashMap虽然在语法上没有问题<strong>，但是会导致请求体对应不上去</strong>，被请求的接口收不到请求体参数</p><p>例如：</p><pre><code>      HashMap&lt;String, String&gt; hashMap = new HashMap&lt;&gt;();    hashMap.put(&quot;name&quot;,&quot;张三&quot;);    hashMap.put(&quot;age&quot;,&quot;1&quot;);    hashMap.put(&quot;tall&quot;,&quot;181&quot;);    //最后一个可变数组的形参不用指定    ResponseEntity&lt;byte[]&gt; res =            restTemplate.postForEntity(&quot;http://localhost:8080/pic/people/pic1&quot;, hashMap, byte[].class);    ServletOutputStream os = response.getOutputStream();    os.write(res.getBody());</code></pre><h3 id="2-2-3-使用SpringMVC下的map"><a href="#2-2-3-使用SpringMVC下的map" class="headerlink" title="2.2.3 使用SpringMVC下的map"></a>2.2.3 使用SpringMVC下的map</h3><p><code>MultiValueMap&lt;String, String&gt; map = new LinkedMultiValueMap&lt;String, String&gt;();</code></p><p><strong>他是org.springframework.util包下的一个Map<br>他兼容了类型匹配，与SpringMVC的适配性很好</strong></p><pre><code>    MultiValueMap&lt;String, String&gt; map = new LinkedMultiValueMap&lt;String, String&gt;();    map.add(&quot;name&quot;,&quot;张三&quot;);    map.add(&quot;age&quot;,&quot;11&quot;);    map.add(&quot;tall&quot;,&quot;181&quot;);    //最后一个可变数组的形参不用指定    ResponseEntity&lt;byte[]&gt; res =            restTemplate.postForEntity(&quot;http://localhost:8080/pic/people/pic1&quot;, map, byte[].class);    ServletOutputStream os = response.getOutputStream();    os.write(res.getBody());</code></pre><h3 id="2-2-4-同时设置请求体and请求头"><a href="#2-2-4-同时设置请求体and请求头" class="headerlink" title="2.2.4 同时设置请求体and请求头"></a>2.2.4 同时设置请求体and请求头</h3><ul><li><p>请求体写在<code>MultiValueMap</code></p></li><li><p>请求头写在<code>HttpHeaders</code></p></li><li><p>最终用<code>HttpEntity</code>封装，需要注意泛型的指定就是MultiValueMap</p><pre><code>      MultiValueMap&lt;String, String&gt; map = new LinkedMultiValueMap&lt;String, String&gt;();      map.add(&quot;name&quot;,&quot;张三&quot;);      map.add(&quot;age&quot;,&quot;11&quot;);      map.add(&quot;tall&quot;,&quot;181&quot;);      HttpHeaders httpHeaders = new HttpHeaders();      //按需求自行添加  //        httpHeaders.setContentType();  //        httpHeaders.setExpires();      //这个Entity包含了请求体 和 请求头      //泛型的指定即：map的类型      HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt; entity = new HttpEntity&lt;&gt;(map,httpHeaders);      //最后一个可变数组的形参不用指定      ResponseEntity&lt;byte[]&gt; res =              restTemplate.postForEntity(&quot;http://localhost:8080/pic/people/pic1&quot;, entity, byte[].class);      ServletOutputStream os = response.getOutputStream();      os.write(res.getBody());</code></pre></li></ul><h3 id="2-2-5同时请求体-请求参数"><a href="#2-2-5同时请求体-请求参数" class="headerlink" title="2.2.5同时请求体 请求参数"></a>2.2.5同时请求体 请求参数</h3><p>有两种写法，一种是url拼接，利用最后一个参数是可变数组</p><pre><code>ResponseEntity&lt;byte[]&gt; res = restTemplate.exchange(&quot;http://localhost:8080/pic/withbody?param1=&#123;param1&#125;&quot;, HttpMethod.POST,    httpEntity, byte[].class, &quot;请求参数1&quot;);</code></pre><p>第二种是最后一个参数用一个map</p><pre><code>HashMap&lt;String, String&gt; urls = new HashMap&lt;&gt;();urls.put(&quot;param1&quot;,&quot;测试1&quot;);ResponseEntity&lt;byte[]&gt; res = restTemplate.exchange(&quot;http://localhost:8080/pic/withbody&quot;, HttpMethod.POST,    httpEntity, byte[].class, urls);</code></pre><h1 id="3-工具类"><a href="#3-工具类" class="headerlink" title="3.工具类"></a>3.工具类</h1><ul><li>根据公司业务写了一个工具类，可以根据需要，对<code>baseByteTractor</code>和<code>baseJsonTractor</code>进行封装</li><li>可根据业务，携带param、body、header请求接口，并可选择是否将其响应数据的header和statusCode写入响应体</li><li>工具类没有选择使用Spring Bean，而是使用安全的单例模式，移植性更强</li></ul><h2 id="3-1完整代码："><a href="#3-1完整代码：" class="headerlink" title="3.1完整代码："></a>3.1完整代码：</h2><pre><code>import java.io.BufferedOutputStream;import java.io.IOException;import java.util.Iterator;import java.util.List;import java.util.Map;import java.util.Map.Entry;import javax.servlet.ServletOutputStream;import javax.servlet.http.HttpServletResponse;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.ResponseEntity;import org.springframework.lang.Nullable;import org.springframework.util.LinkedMultiValueMap;import org.springframework.util.MultiValueMap;import org.springframework.web.client.RestClientException;import org.springframework.web.client.RestTemplate;/** * @Description RestTemplate工具类 * 1.getByte() postByte()是用来下载流的，因此形参必须有HttpResponseBody * 2.getJson() postJson()是用来获取json的，形参可以不带response * 3.每个方法最后一个形参requireBodyOnly默认true，即只需要响应体，一般建议设为true， *     否则可能造成因header自动解析产生的问题 * 4.post请求可以额外携带请求体 * 5.可能产生EOFException异常，正常，可以全局捕获日志记录 *  * @Author zjh * @Date 17:04 2022/7/28 **/public class RestTemplateUtils &#123;  private static          Logger       logger = LoggerFactory.getLogger(&quot;RestLogger&quot;);  private volatile static RestTemplate restTemplate;  /**   * RestTemplate单例 懒汉 双检锁   **/  public static RestTemplate getSingleRestTemplate() &#123;    if (restTemplate == null) &#123;      synchronized (RestTemplateUtils.class) &#123;        if (restTemplate == null) &#123;          restTemplate = new RestTemplate();        &#125;      &#125;    &#125;    return restTemplate;  &#125;  /**   * 基础方法，下载文件二进制流到response输出流   *   * @param url 不包含请求参数 即 ?param=&#123;&#125;   * @param method POST或GET   * @param requestHeaders 请求头，可为空   * @param requestParams 请求参数，可为空   * @param requestBody 请求体，可为空   * @param requireBodyOnly 是否是只需要响应体,默认true，true：只需要响应体  false：同时返回响应状态 响应头  响应体   * @return void   **/  public static void baseByteTractor(String url, HttpMethod method,      @Nullable Map&lt;String, String&gt; requestHeaders,      @Nullable Map&lt;String, Object&gt; requestParams,      @Nullable Map&lt;String, Object&gt; requestBody,      HttpServletResponse response,      @Nullable Boolean requireBodyOnly) &#123;    if (requireBodyOnly == null) &#123;      requireBodyOnly = true;    &#125;    MultiValueMap&lt;String, Object&gt; params  = new LinkedMultiValueMap&lt;String, Object&gt;();    MultiValueMap&lt;String, Object&gt; body    = new LinkedMultiValueMap&lt;String, Object&gt;();    HttpHeaders                   headers = new HttpHeaders();    //1.设置请求参数    if (requestParams != null &amp;&amp; !requestParams.isEmpty()) &#123;      Iterator&lt;Entry&lt;String, Object&gt;&gt; paramsIterator = requestParams.entrySet().iterator();      Entry&lt;String, Object&gt;           nextParam      = null;      while (paramsIterator.hasNext()) &#123;        nextParam = paramsIterator.next();        params.add(nextParam.getKey(), nextParam.getValue());      &#125;    &#125;    //2.设置请求头    if (requestHeaders != null &amp;&amp; !requestHeaders.isEmpty()) &#123;      Iterator&lt;Entry&lt;String, String&gt;&gt; headersIterator = requestHeaders.entrySet().iterator();      Entry&lt;String, String&gt;           nextHeader      = null;      while (headersIterator.hasNext()) &#123;        nextHeader = headersIterator.next();        headers.add(nextHeader.getKey(), nextHeader.getValue());      &#125;    &#125;    //3.设置请求体    if (requestBody != null &amp;&amp; !requestBody.isEmpty()) &#123;      Iterator&lt;Entry&lt;String, Object&gt;&gt; bodyIterator = requestBody.entrySet().iterator();      Entry&lt;String, Object&gt;           bodyNext     = null;      while (bodyIterator.hasNext()) &#123;        bodyNext = bodyIterator.next();        body.add(bodyNext.getKey(), bodyNext.getValue());      &#125;    &#125;    //4.请求体 请求头封装到HttpEntity    HttpEntity&lt;MultiValueMap&lt;String, Object&gt;&gt; entity = new HttpEntity&lt;&gt;(body, headers);    //5.执行    RestTemplate         restTemplate = getSingleRestTemplate();    BufferedOutputStream bos          = null;    try &#123;      ResponseEntity&lt;byte[]&gt; exchange = restTemplate.exchange(url, method, entity, byte[].class, params);      if (!requireBodyOnly &amp;&amp; response != null) &#123;        //响应状态码        response.setStatus(exchange.getStatusCodeValue());        //响应头,可能存在一个key对应多个value,本方法中会将同名header合并        HttpHeaders                           resHeaders         = exchange.getHeaders();        Iterator&lt;Entry&lt;String, List&lt;String&gt;&gt;&gt; resHeadersIterator = resHeaders.entrySet().iterator();        while (resHeadersIterator.hasNext()) &#123;          Entry&lt;String, List&lt;String&gt;&gt; headersNext = resHeadersIterator.next();          response.setHeader(headersNext.getKey(), headersNext.getValue().toString());        &#125;      &#125;      //响应体      ServletOutputStream os = response.getOutputStream();      bos = new BufferedOutputStream(os);      byte[] buf = exchange.getBody();      bos.write(buf);      bos.flush();    &#125; catch (IOException e) &#123;      logger.error(&quot;RestTemplateUtils获取接口二进制流异常&quot;);    &#125; catch (RestClientException e) &#123;      logger.error(&quot;远程调用接口异常&#123;&#125;&quot;, e);    &#125; finally &#123;      try &#123;        bos.close();      &#125; catch (IOException e) &#123;        logger.error(&quot;RestTemplateUtils流关闭异常&quot;);      &#125;    &#125;  &#125;  /**   * 基础方法，请求接口，返回JSON   *   * @param url 不包含请求参数 即 ?param=&#123;&#125;   * @param method POST或GET   * @param requestHeaders 请求头，可为空   * @param requestParams 请求参数，可为空   * @param requestBody 请求体，可为空   * @param requireBodyOnly 是否是只需要响应体,默认true，true：只需要响应体  false：同时返回响应状态 响应头  响应体   * @return String Json   **/  public static String baseJsonTracktor(String url, HttpMethod method,      @Nullable Map&lt;String, String&gt; requestHeaders,      @Nullable Map&lt;String, Object&gt; requestParams,      @Nullable Map&lt;String, Object&gt; requestBody,      @Nullable HttpServletResponse response,      @Nullable Boolean requireBodyOnly) &#123;    if (requireBodyOnly == null) &#123;      requireBodyOnly = true;    &#125;    MultiValueMap&lt;String, Object&gt; params  = new LinkedMultiValueMap&lt;String, Object&gt;();    MultiValueMap&lt;String, Object&gt; body    = new LinkedMultiValueMap&lt;String, Object&gt;();    HttpHeaders                   headers = new HttpHeaders();    //1.设置请求参数    if (requestParams != null &amp;&amp; !requestParams.isEmpty()) &#123;      Iterator&lt;Entry&lt;String, Object&gt;&gt; paramsIterator = requestParams.entrySet().iterator();      Entry&lt;String, Object&gt;           nextParam      = null;      while (paramsIterator.hasNext()) &#123;        nextParam = paramsIterator.next();        params.add(nextParam.getKey(), nextParam.getValue());      &#125;    &#125;    //2.设置请求头    if (requestHeaders != null &amp;&amp; !requestHeaders.isEmpty()) &#123;      Iterator&lt;Entry&lt;String, String&gt;&gt; headersIterator = requestHeaders.entrySet().iterator();      Entry&lt;String, String&gt;           nextHeader      = null;      while (headersIterator.hasNext()) &#123;        nextHeader = headersIterator.next();        headers.add(nextHeader.getKey(), nextHeader.getValue());      &#125;    &#125;    //3.设置请求体    if (requestBody != null &amp;&amp; !requestBody.isEmpty()) &#123;      Iterator&lt;Entry&lt;String, Object&gt;&gt; bodyIterator = requestBody.entrySet().iterator();      Entry&lt;String, Object&gt;           bodyNext     = null;      while (bodyIterator.hasNext()) &#123;        bodyNext = bodyIterator.next();        body.add(bodyNext.getKey(), bodyNext.getValue());      &#125;    &#125;    //4.请求体 请求头封装到HttpEntity    HttpEntity&lt;MultiValueMap&lt;String, Object&gt;&gt; entity = new HttpEntity&lt;&gt;(body, headers);    //5.执行    RestTemplate restTemplate = getSingleRestTemplate();    String       bodyJson     = &quot;&quot;;    try &#123;      ResponseEntity&lt;String&gt; exchange = restTemplate.exchange(url, method, entity, String.class, params);      if (!requireBodyOnly &amp;&amp; response != null) &#123;        //响应状态码        response.setStatus(exchange.getStatusCodeValue());        //响应头,可能存在一个key对应多个value,本方法中会将同名header合并        HttpHeaders                           resHeaders         = exchange.getHeaders();        Iterator&lt;Entry&lt;String, List&lt;String&gt;&gt;&gt; resHeadersIterator = resHeaders.entrySet().iterator();        while (resHeadersIterator.hasNext()) &#123;          Entry&lt;String, List&lt;String&gt;&gt; headersNext = resHeadersIterator.next();          response.setHeader(headersNext.getKey(), headersNext.getValue().toString());        &#125;      &#125;      bodyJson = exchange.getBody();    &#125; catch (RestClientException e) &#123;      logger.error(&quot;远程调用接口异常&#123;&#125;&quot;, e);    &#125;    return bodyJson;  &#125;  /**   * GET请求 下载流   *   * @param url 不包含请求参数 即 ?param=&#123;&#125;   * @param requestParams 请求参数，可为空   * @param requireBodyOnly 是否是只需要响应体,默认true，true：只需要响应体  false：同时返回响应状态 响应头  响应体   * @return void   **/  public static void getByte(String url, HttpServletResponse response,      @Nullable Map&lt;String, Object&gt; requestParams,      @Nullable Boolean requireBodyOnly) &#123;    if (requireBodyOnly == null) &#123;      requireBodyOnly = true;    &#125;    baseByteTractor(url, HttpMethod.GET, null, requestParams, null, response, requireBodyOnly);  &#125;  /**   * POST请求 下载流   *   * @param url 不包含请求参数 即 ?param=&#123;&#125;   * @param requestParams 请求参数，可为空   * @param requestBody 请求体，可为空   * @param requireBodyOnly 是否是只需要响应体,默认true，true：只需要响应体  false：同时返回响应状态 响应头  响应体   * @return void   **/  public static void postByte(String url, HttpServletResponse response,      @Nullable Map&lt;String, Object&gt; requestParams,      @Nullable Map&lt;String, Object&gt; requestBody,      @Nullable Boolean requireBodyOnly) &#123;    if (requireBodyOnly == null) &#123;      requireBodyOnly = true;    &#125;    baseByteTractor(url, HttpMethod.POST, null, requestParams, requestBody, response, requireBodyOnly);  &#125;  /**   * GET请求 获取JSON   *   * @param url 不包含请求参数 即 ?param=&#123;&#125;   * @param requestParams 请求参数，可为空   * @param requireBodyOnly 是否是只需要响应体,默认true，true：只需要响应体  false：同时返回响应状态 响应头  响应体   * @return void   **/  public static String getJson(String url,      @Nullable HttpServletResponse response,      @Nullable Map&lt;String, Object&gt; requestParams,      @Nullable Boolean requireBodyOnly) &#123;    if (requireBodyOnly == null) &#123;      requireBodyOnly = true;    &#125;    String resJson = baseJsonTracktor(url, HttpMethod.GET, null, requestParams, null, response, requireBodyOnly);    return resJson;  &#125;  /**   * POST请求 获取JSON   *   * @param url 不包含请求参数 即 ?param=&#123;&#125;   * @param requestParams 请求参数，可为空   * @param requestBody 请求体，可为空   * @param requireBodyOnly 是否是只需要响应体,默认true，true：只需要响应体  false：同时返回响应状态 响应头  响应体   * @return void   **/  public static String postJson(String url,      @Nullable HttpServletResponse response,      @Nullable Map&lt;String, Object&gt; requestParams,      @Nullable Map&lt;String, Object&gt; requestBody,      @Nullable Boolean requireBodyOnly) &#123;    if (requireBodyOnly == null) &#123;      requireBodyOnly = true;    &#125;    String resJson = baseJsonTracktor(url, HttpMethod.POST, null, requestParams, requestBody, response, requireBodyOnly);    return resJson;  &#125;&#125;</code></pre><h2 id="3-2演示"><a href="#3-2演示" class="headerlink" title="3.2演示"></a>3.2演示</h2><p><img src="https://img-blog.csdnimg.cn/466841ea1eb54688a58f13f5a91da1c6.png" alt="BYTE"><br><img src="https://img-blog.csdnimg.cn/2aaa7850f1574bdaaa2e86b11e302dc2.png" alt="JSON"></p><h1 id="4-小插曲"><a href="#4-小插曲" class="headerlink" title="4.小插曲"></a>4.小插曲</h1><p>在决定写下这篇文章之前，其实是在解决一个业务需求时碰到的问题，问题很简单，粗心导致的，但是反正都已经debug看了分析了源码了，所以干脆写下了上面的源码分析文章和工具类。。。</p><h2 id="4-1环境模拟"><a href="#4-1环境模拟" class="headerlink" title="4.1环境模拟"></a>4.1环境模拟</h2><h3 id="4-1-2接口提供"><a href="#4-1-2接口提供" class="headerlink" title="4.1.2接口提供"></a>4.1.2接口提供</h3><p>提供一个接口，设置一个请求头给response，把图片二进制流写入response</p><pre><code>@GetMapping(&quot;/pic1&quot;)public void getPic(HttpServletRequest request,HttpServletResponse response) throws IOException &#123;    response.setHeader(&quot;keyy&quot;,&quot;valuee&quot;);    System.out.println(response.getHeader(&quot;keyy&quot;));    File file = new File(&quot;C:\\Users\\zhangjiahao\\Desktop\\图片.jpg&quot;);    FileInputStream fis = new FileInputStream(file);    BufferedInputStream bis = new BufferedInputStream(fis);    byte[] buf = new byte[2048];    ServletOutputStream os = response.getOutputStream();    BufferedOutputStream bos = new BufferedOutputStream(os);    while(bis.read(buf) != -1)&#123;        bos.write(buf);    &#125;    bos.flush();    bos.close();    bis.close();   &#125;</code></pre><h2 id="4-2源码分析思路"><a href="#4-2源码分析思路" class="headerlink" title="4.2源码分析思路"></a>4.2源码分析思路</h2><h3 id="4-2-1方法本身区别"><a href="#4-2-1方法本身区别" class="headerlink" title="4.2.1方法本身区别"></a>4.2.1方法本身区别</h3><p><strong>调用exchange()的时候，内部调用的方法是需要携带请求参数的，不过可以设为null</strong></p><p><img src="https://img-blog.csdnimg.cn/f4d74fc424e2449ab72a25e7dd853729.png" alt="getForEntity"><br><img src="https://img-blog.csdnimg.cn/cd8896e0622c45e48e6e2b73d9a86778.png" alt="exchange"><br>两个方法本身的区别就是：<code>requestEntity</code>，即请求参数</p><h3 id="4-2-2分别看两个内部的方法"><a href="#4-2-2分别看两个内部的方法" class="headerlink" title="4.2.2分别看两个内部的方法"></a>4.2.2分别看两个内部的方法</h3><h3 id="4-2-2-1-exchange-带参的：httpEntityCallback"><a href="#4-2-2-1-exchange-带参的：httpEntityCallback" class="headerlink" title="4.2.2.1 exchange-带参的：httpEntityCallback"></a>4.2.2.1 exchange-带参的：httpEntityCallback</h3><p><img src="https://img-blog.csdnimg.cn/5e4711f12bab4fc5971de022cbf8a823.png"></p><p>到目前为止没有看到对返回值response进行操作的内容<br><img src="https://img-blog.csdnimg.cn/ec598eb6550f4dc2a2cc44e9a2a37423.png"></p><h3 id="4-2-2-2getFroEntity-无参：acceptHeaderRequestCallback"><a href="#4-2-2-2getFroEntity-无参：acceptHeaderRequestCallback" class="headerlink" title="4.2.2.2getFroEntity-无参：acceptHeaderRequestCallback"></a>4.2.2.2getFroEntity-无参：acceptHeaderRequestCallback</h3><p><img src="https://img-blog.csdnimg.cn/c966fb07a8c34b6685ce62f58bc03d81.png"><br><img src="https://img-blog.csdnimg.cn/6fef8e3477fc4c51a64dba0f2ea602ad.png"></p><h2 id="4-3到此没有分析出异常，则看request回调相关的execute"><a href="#4-3到此没有分析出异常，则看request回调相关的execute" class="headerlink" title="4.3到此没有分析出异常，则看request回调相关的execute"></a>4.3到此没有分析出异常，则看request回调相关的execute</h2><h3 id="4-3-1分析理由"><a href="#4-3-1分析理由" class="headerlink" title="4.3.1分析理由"></a>4.3.1分析理由</h3><p>因为两个方法的区别就是在于回调<code>RequestCallback</code>，本身分析不出来问题，就去找其他<code>RequestCallback</code>相关的即<code>execute()</code>执行方法本身<img src="https://img-blog.csdnimg.cn/bc1f4bfe85644f90a190de7c7b214726.png"></p><h3 id="4-3-2doExecute"><a href="#4-3-2doExecute" class="headerlink" title="4.3.2doExecute()"></a>4.3.2doExecute()</h3><p>doWithRequest()对于这两个方法来说，其实都是会执行的</p><p><img src="https://img-blog.csdnimg.cn/1e0853997c16464c8753fd8b296bd15d.png"><br>debug的时候能正常进去</p><p><img src="https://img-blog.csdnimg.cn/f226121a4b514ef7afcc5be894fa83f9.png"></p><p>虽然这里没有指定requestEntity</p><p><img src="https://img-blog.csdnimg.cn/717c0b61574448ee96c3aa0bf051d3aa.png">但是内部造了一个requestCallBack，和requestEntity没有关系</p><p><img src="https://img-blog.csdnimg.cn/d072a85dd9694ea59111d2f50aa6a542.png"></p><h2 id="4-4定位到doWithRequest（）"><a href="#4-4定位到doWithRequest（）" class="headerlink" title="4.4定位到doWithRequest（）"></a>4.4定位到doWithRequest（）</h2><p><img src="https://img-blog.csdnimg.cn/ea860a58bf7d43f5bf0ae992610ed1c7.png"></p><p>这两个实现类其实是父子类关系，都会调用（内部用的super）<img src="https://img-blog.csdnimg.cn/e6927c9c1bc443c6b02d6352e3399664.png" alt="两个实现类"></p><h3 id="4-4-1-debug-发现支持的媒体类型"><a href="#4-4-1-debug-发现支持的媒体类型" class="headerlink" title="4.4.1 debug 发现支持的媒体类型"></a>4.4.1 debug 发现支持的媒体类型</h3><p>发现在使用getForEntity()的时候，走到这里是false，因此没有指定返回值的类型<br><img src="https://img-blog.csdnimg.cn/0d970c9b6b524a30b58c069d25b7831f.png"><br>而正常正确的应该是这样</p><p><img src="https://img-blog.csdnimg.cn/0883ff19327b418291e7fe957edbaeba.png"></p><h3 id="4-4-2回去看参数是否正确"><a href="#4-4-2回去看参数是否正确" class="headerlink" title="4.4.2回去看参数是否正确"></a>4.4.2回去看参数是否正确</h3><p>发现这里给responseType指定为了null，那么问题来了，为什么参数写错了但是没提示？</p><p><img src="https://img-blog.csdnimg.cn/4696156abb0744b7a0fd8accd3786a96.png"><br><strong>这是因为最后最后一个形参是<code>Object... uriVariables</code>，这种形参放在最后一位就支持这种很多逗号的写法</strong></p><h2 id="4-5修改参数"><a href="#4-5修改参数" class="headerlink" title="4.5修改参数"></a>4.5修改参数</h2><p><img src="https://img-blog.csdnimg.cn/9aae1ca4f8df43b1aee39106e1e3707b.png"></p><p>然后就跑通了</p><h2 id="4-6结论"><a href="#4-6结论" class="headerlink" title="4.6结论"></a>4.6结论</h2><p>其实这两个方法本质只有“是否携带请求参数”的区别，其他的所有东西都一样，执行的过程一样，返回值一样，返回值的使用方式一样。<br>唯一值得需要注意的是，<strong>以后遇到这种最后一个形参是<code>Object... uriVariables</code>的，就要对形参的个数比较敏感一点</strong></p>]]></content>
      
      
      <categories>
          
          <category> 源码 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>短信服务被攻击解决方案</title>
      <link href="/zjh/2022/08/03/%E7%9F%AD%E4%BF%A1%E6%9C%8D%E5%8A%A1%E8%A2%AB%E6%94%BB%E5%87%BB%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
      <url>/zjh/2022/08/03/%E7%9F%AD%E4%BF%A1%E6%9C%8D%E5%8A%A1%E8%A2%AB%E6%94%BB%E5%87%BB%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
      
        <content type="html"><![CDATA[<h1 id="1-需求背景"><a href="#1-需求背景" class="headerlink" title="1.需求背景"></a>1.需求背景</h1><ul><li>开放平台短信接口被攻击</li><li>生成图片验证码的功能在一个公共项目中，开放平台没有加图片验证，因此短信服务被别人恶意攻击接口<h2 id="1-1远程服务"><a href="#1-1远程服务" class="headerlink" title="1.1远程服务"></a>1.1远程服务</h2></li><li>发送图片验证码的功能写在一个公共项目中（前后端分离，无xss攻击风险；但复用的图片验证码组件是servlet写的）</li><li>开放平台（前后端不分离，使用java volatile，虽有防攻击框架，但不排除有xss攻击风险）</li></ul><h2 id="1-2历史遗留问题"><a href="#1-2历史遗留问题" class="headerlink" title="1.2历史遗留问题"></a>1.2历史遗留问题</h2><ul><li>当年没有开源的图片验证码生成工具，因此在公共项目中直接复用了以前的Servlet代码（生成图片验证码）</li><li>Servlet提供接口，生成图片验证码；通过Filter进行拦截校验；验证的答案存在session中</li></ul><h2 id="1-3开放平台解决方案"><a href="#1-3开放平台解决方案" class="headerlink" title="1.3开放平台解决方案"></a>1.3开放平台解决方案</h2><ul><li>准备直接调用公共平台的接口生成图片验证码（读取二进制流，答案经过非对称加密后写到响应头）</li><li>从响应头取出加密后的答案存入本地session，校验的时候从开放平台（本地）取session</li></ul><h3 id="1-3-1为何不复用公共项目的Filter"><a href="#1-3-1为何不复用公共项目的Filter" class="headerlink" title="1.3.1为何不复用公共项目的Filter"></a>1.3.1为何不复用公共项目的Filter</h3><ul><li>因为涉及远程调用，两次调用的jsessionid其实是不一样的，也就不能共享公共平台中的session域进行校验。。</li><li>虽然后续自己复盘的时候通过反射小改了以下web框架获取session的逻辑，但是业务复杂度提升了————链接: <a href="https://zjhblog.gitee.io/zjh/2022/08/03/%E5%8F%8D%E5%B0%84%E4%BF%AE%E6%94%B9jsessionid%E5%AE%9E%E7%8E%B0session%E5%85%B1%E4%BA%AB/">共享Session的方案</a></li></ul><h3 id="1-3-2防止XSS攻击"><a href="#1-3-2防止XSS攻击" class="headerlink" title="1.3.2防止XSS攻击"></a>1.3.2防止XSS攻击</h3><ul><li>开放平台使用Java volatile，可能会收到<code>XSS攻击</code>，例如<code>#if($!session.getAttribute(&quot;Key&quot;))</code>从而直接获取到图片验证码的答案</li><li>但是远程调用接口的时候，答案已经用内部工具进行非对称加密</li></ul><h3 id="1-3-3补：公共项目Servlet使用SpringBean不便"><a href="#1-3-3补：公共项目Servlet使用SpringBean不便" class="headerlink" title="1.3.3补：公共项目Servlet使用SpringBean不便"></a>1.3.3补：公共项目Servlet使用SpringBean不便</h3><p>这个很好解决，我的另一篇文章提出了4种在Servlet中使用Bean的方法。分别使用的思想是：</p><ul><li><code>SpringBeanAutowiringSupport.processInjectionBasedOnServletContext(this, servletConfig.getServletContext()</code>Servlet初始化时，把自己（this）交给Spring容器进行托管</li><li> <code>WebApplicationContextUtils.getWebApplicationContext(servletContext).getBean()</code>将指定的Bean对象地址交给Servlet</li><li><code>ApplicationContext.getBean()</code>将指定的Bean对象地址交给Servlet</li><li>在@Config类中利用Servlet<code>构造函数 or Set</code>方法，将Bean的地址传给Servlet</li></ul><p>链接: <a href="https://zjhblog.gitee.io/zjh/2022/08/03/%E5%9B%9B%E7%A7%8D%E6%96%B9%E6%B3%95Servlet%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8Spring%E7%9A%84Bean%E5%AF%B9%E8%B1%A1/">四种方法Servlet容器使用Spring的Bean对象</a></p><h1 id="2-远程调用方：开放平台的解决方案"><a href="#2-远程调用方：开放平台的解决方案" class="headerlink" title="2.远程调用方：开放平台的解决方案"></a>2.远程调用方：开放平台的解决方案</h1><p>因为涉及到远程调用，临时学了下RestTemplate的用法，后续复盘的时候补充了一个工具类</p><h2 id="2-1撸了一个RestTemplateUtils工具类"><a href="#2-1撸了一个RestTemplateUtils工具类" class="headerlink" title="2.1撸了一个RestTemplateUtils工具类"></a>2.1撸了一个RestTemplateUtils工具类</h2><p>远程调用获取图片，并取出响应Header中的图片验证码答案，存入本地session，用于后续校验</p><p>链接: <a href="https://zjhblog.gitee.io/zjh/2022/08/03/RestTemlate%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8F%8A%E5%B7%A5%E5%85%B7%E7%B1%BB%E8%AE%BE%E8%AE%A1/">RestTemplateUtils工具类及源码分析</a></p><h2 id="2-2接口复用"><a href="#2-2接口复用" class="headerlink" title="2.2接口复用"></a>2.2接口复用</h2><p>因为注册、忘记密码、编辑、验证旧号、验证新号逻辑大体一致，因此在一个接口上进行处理，<strong>通过URI的不同</strong>，<strong>设置的手机验证码的key不同</strong></p><h1 id="3-小结"><a href="#3-小结" class="headerlink" title="3.小结"></a>3.小结</h1><ul><li>开放平台 请求 公共服务，同时获取二进制流与响应header中的加密答案</li><li>答案经过非对称加密，提升了XSS攻击的难度</li><li>虽然有通过反射session共享的方案，但业务复杂度较高因此没有用</li></ul><h1 id="4-复盘反思"><a href="#4-复盘反思" class="headerlink" title="4.复盘反思"></a>4.复盘反思</h1><ul><li>如果让我来写，非对称加密的方案不应该把密钥写死在前后端，应该每次会话自动生成一对密钥，降低XSS攻击风险。</li><li>用户请求服务器A，调用服务器B的接口，调用两次是两个不同的session，如果想要共享session内容需要通过反射改造session获取逻辑 <a href="https://zjhblog.gitee.io/zjh/2022/08/03/%E5%8F%8D%E5%B0%84%E4%BF%AE%E6%94%B9jsessionid%E5%AE%9E%E7%8E%B0session%E5%85%B1%E4%BA%AB/">共享Session的方案</a></li><li>公共服务不应该用Servlet写，应该更换目前的开源MVC组件，用Servlet写的功能在Spring项目中维护起来有点恶心。。。</li><li>相似功能，相同逻辑的服务可以写为一个MVC方法，通过url来进行细微的命名区分</li><li>涉及到图片验证码这种类似的功能，每次请求需要覆盖以前的答案</li><li>对于像手机验证码这种<strong>需要花钱</strong>的服务，如果让我来做一个业务层，我会将<strong>最近一段时间的所有手机验证码存入一个list</strong>，每次比对的时候跟list进行比对而不只是当前最新的验证码。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>四种方法Servlet容器使用Spring的Bean对象</title>
      <link href="/zjh/2022/08/03/%E5%9B%9B%E7%A7%8D%E6%96%B9%E6%B3%95Servlet%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8Spring%E7%9A%84Bean%E5%AF%B9%E8%B1%A1/"/>
      <url>/zjh/2022/08/03/%E5%9B%9B%E7%A7%8D%E6%96%B9%E6%B3%95Servlet%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8Spring%E7%9A%84Bean%E5%AF%B9%E8%B1%A1/</url>
      
        <content type="html"><![CDATA[<p>今天在做一个需求的时候，需要在Servlet接口中调用一个Spring的Bean对象，因为Servlet和Spring生命周期不同，所被管理的容器不同，因此不能直接通过@Autowire注入</p><p>以下三个方案，思路分别是：</p><ul><li>在初始化这个Servlet类接口的时候，<strong>重写init()方法</strong>，允许Servlet扫描Bean对象</li><li>在初始化这个Servlet类接口的时候，<strong>重写init()方法</strong>，指定获取bean：getBean()</li><li>在利用配置类在装载Servlet的时候，将<strong>bean对象地址</strong>作为形参传给Servlet</li></ul><h1 id="0-Servlet结构演示"><a href="#0-Servlet结构演示" class="headerlink" title="0.Servlet结构演示"></a>0.Servlet结构演示</h1><p>这里做演示用的StringRedisTemplate 本身不是一个SpringBean对象，但是由于项目中有配置将其扫描为了bean，所以这里直接用StringRedisTemplate 来做演示</p><pre><code>public class ValidateCodeServlet extends HttpServlet &#123;//@Autowiredprivate StringRedisTemplate stringRedisTemplate;//    public ValidateCodeServlet() &#123;//    &#125;//    public ValidateCodeServlet(StringRedisTemplate stringRedisTemplate) &#123;//        this.stringRedisTemplate = stringRedisTemplate;//    &#125; @Override    protected void doGet(HttpServletRequest request, HttpServletResponse response) &#123;....&#125;    @Override    public void init(ServletConfig config) throws ServletException &#123;.....    &#125;</code></pre><h1 id="1-允许Servlet扫描Bean对象"><a href="#1-允许Servlet扫描Bean对象" class="headerlink" title="1.允许Servlet扫描Bean对象"></a>1.允许Servlet扫描Bean对象</h1><pre><code>@Overridepublic void init(ServletConfig config) throws ServletException &#123;    // 父类不初始化会导致getServletContext()空指针异常    super.init(config);    // 将当前this 的 Servlet交给Spring托管，因此该Servlet可以用@Autowired    SpringBeanAutowiringSupport.processInjectionBasedOnServletContext(this, config.getServletContext());&#125;</code></pre><h2 id="1-1SpringBeanAutowiringSupport类"><a href="#1-1SpringBeanAutowiringSupport类" class="headerlink" title="1.1SpringBeanAutowiringSupport类"></a>1.1SpringBeanAutowiringSupport类</h2><p>通过这个类的名字，结合注释可以知道，这个类主要的作用是对@Autowired进行增强<br>看注释中的如下部分，<strong>通过@Autowired将Spring的Bean对象解析到当前的Web上下文(Servlet上下文)</strong><br><img src="https://img-blog.csdnimg.cn/3b56013f4c68405b909f7c44524eb547.png"></p><h2 id="1-2processInjectionBasedOnServletContext"><a href="#1-2processInjectionBasedOnServletContext" class="headerlink" title="1.2processInjectionBasedOnServletContext"></a>1.2processInjectionBasedOnServletContext</h2><p>Servlet注入Spring的Bean对象，最终的执行方法是<code>processInjection()</code></p><p><img src="https://img-blog.csdnimg.cn/76d97cee3eb04f5d99097ec79e3d81b8.png"></p><h3 id="1-2-1processInjection"><a href="#1-2-1processInjection" class="headerlink" title="1.2.1processInjection()"></a>1.2.1processInjection()</h3><p><img src="https://img-blog.csdnimg.cn/acc487e186a24230843850ad1a5e2804.png"></p><h1 id="2-get指定的bean"><a href="#2-get指定的bean" class="headerlink" title="2.get指定的bean"></a>2.get指定的bean</h1><pre><code>@Overridepublic void init(ServletConfig config) throws ServletException &#123;     ServletContext servletContext = this.getServletContext();     WebApplicationContext context = WebApplicationContextUtils.getWebApplicationContext(servletContext);     this.stringRedisTemplate = (StringRedisTemplate) context.getBean(&quot;StringRedisTemplate&quot;);     &#125;</code></pre><p>如果目标类本身没有直接注入Spring容器而是配置扫描，会报错，所以不推荐这种做法，更推荐方法1</p><h2 id="2-1WebApplicationContextUtils工具类"><a href="#2-1WebApplicationContextUtils工具类" class="headerlink" title="2.1WebApplicationContextUtils工具类"></a>2.1WebApplicationContextUtils工具类</h2><p>在SpringBeanAutowiringSupport类的注释中有提到<br>WebApplicationContextUtils类允许基于ServletContext轻松访问Spring根web应用程序上下文。<br><img src="https://img-blog.csdnimg.cn/a52db8aefb894fb5afb02f07622a1fa5.png"></p><h1 id="3-配置类传递bean地址"><a href="#3-配置类传递bean地址" class="headerlink" title="3.配置类传递bean地址"></a>3.配置类传递bean地址</h1><p>bean对象本质上也是一个java的对象，只要能获取其地址值，就可以正常使用</p><p><img src="https://img-blog.csdnimg.cn/e56c9456d3d746ee9eec7089826b1dc6.png"></p><p><img src="https://img-blog.csdnimg.cn/509aaea83be74091b540716a4a5d3ec1.png"><br>这样配置就不需要写inti()了</p><h1 id="4-同样的，对于Filter"><a href="#4-同样的，对于Filter" class="headerlink" title="4.同样的，对于Filter"></a>4.同样的，对于Filter</h1><p>Filter也是Servlet的产物，他的上下文环境也不同于Spring上下文，同样还是这个需求里面用的是Filter对其进行校验，也需要注入Srping的Bean对象，当然不能直接@Autowired</p><p><img src="https://img-blog.csdnimg.cn/a0c4fd70e8b4495aaa67edea8b4d1820.png"><br><img src="https://img-blog.csdnimg.cn/385af820bedc467c9955b319aaf5f37e.png"></p><h1 id="5-普通类调用bean工具类"><a href="#5-普通类调用bean工具类" class="headerlink" title="5.普通类调用bean工具类"></a>5.普通类调用bean工具类</h1><pre><code> @Componentpublic class SpringContexUtil implements ApplicationContextAware &#123;private static ApplicationContext applicationContext;@Overridepublic void setApplicationContext(ApplicationContext context) throws BeansException &#123;applicationContext = context;&#125;//静态加载applicationContextpublic static ApplicationContext getApplicationContext() &#123;return applicationContext;&#125;//通过反射获取Beanpublic static &lt;T&gt; T getBean(Class&lt;T&gt; requiredType)&#123;return getApplicationContext().getBean(requiredType);&#125;//通过id名获取beanpublic static &lt;T&gt; T getBean(String name)&#123;return (T) getApplicationContext().getBean(name);&#125;&#125;</code></pre><p>把Servlet或者Filter当普通类，直接用工具类调用即可</p><h1 id="需要注意的点"><a href="#需要注意的点" class="headerlink" title="需要注意的点"></a>需要注意的点</h1><p>因为项目启动时装载在前，很多修改“装载过程”的地方不能通过热部署来reload，需要重启项目</p><h1 id="6-小结"><a href="#6-小结" class="headerlink" title="6.小结"></a>6.小结</h1><p>在使用Servlet对象之前，将其需要注入的SpringBean作为形参，在配置类中（即启动时装载）指定SpringBean对象的地址值给Servlet或Filter的形参即可</p>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>(蔚来)复杂链表的复制</title>
      <link href="/zjh/2022/07/29/(%E8%94%9A%E6%9D%A5)%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6/"/>
      <url>/zjh/2022/07/29/(%E8%94%9A%E6%9D%A5)%E5%A4%8D%E6%9D%82%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%8D%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>2022-07-28蔚来提前批算法第一题，已AC，剑指相似的题，笔试要多判断random指针为空的情况</p><p>笔试的时候是直接一个while循环搞定，这里贴出另外一个解法</p><p>请实现 copyRandomList 函数，复制一个复杂链表。在复杂链表中，每个节点除了有一个 next 指针指向下一个节点，还有一个 random 指针指向链表中的任意节点或者 null。</p><p> <img src="https://img-blog.csdnimg.cn/684077f34afa495b91ed7add08e1e53e.png"><br><img src="https://img-blog.csdnimg.cn/dc54fe25f2a94db38c1b8e0f65063629.png"><br><img src="https://img-blog.csdnimg.cn/10eddcdb7b8a49cab0687f20789c01db.png"></p><pre><code>/*// Definition for a Node.class Node &#123;    int val;    Node next;    Node random;    public Node(int val) &#123;        this.val = val;        this.next = null;        this.random = null;    &#125;&#125;*//**法1：用hashMap来维护 */class Solution &#123;    public Node copyRandomList(Node head) &#123;        if(head == null)        return null;        HashMap&lt;Node,Node&gt; hs = new HashMap&lt;Node,Node&gt;();        Node curr = head;        while(curr != null)&#123;            hs.put(curr,new Node(curr.val));            curr = curr.next;        &#125;        curr = head;        while(curr != null)&#123;            hs.get(curr).next = hs.get(curr.next);            hs.get(curr).random = hs.get(curr.random);            curr = curr.next;        &#125;        return hs.get(head);    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>字符串：替换、左旋、缺失</title>
      <link href="/zjh/2022/07/20/%E5%AD%97%E7%AC%A6%E4%B8%B2%EF%BC%9A%E6%9B%BF%E6%8D%A2%E3%80%81%E5%B7%A6%E6%97%8B%E3%80%81%E7%BC%BA%E5%A4%B1/"/>
      <url>/zjh/2022/07/20/%E5%AD%97%E7%AC%A6%E4%B8%B2%EF%BC%9A%E6%9B%BF%E6%8D%A2%E3%80%81%E5%B7%A6%E6%97%8B%E3%80%81%E7%BC%BA%E5%A4%B1/</url>
      
        <content type="html"><![CDATA[<h1 id="1-替换空格"><a href="#1-替换空格" class="headerlink" title="1.替换空格"></a>1.替换空格</h1><pre><code>请实现一个函数，把字符串 s 中的每个空格替换成&quot;%20&quot;。示例 1：输入：s = &quot;We are happy.&quot;输出：&quot;We%20are%20happy.&quot;限制：0 &lt;= s 的长度 &lt;= 10000</code></pre><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><pre><code>class Solution &#123;    public String replaceSpace(String s) &#123;        StringBuffer dest = new StringBuffer();        for(int i = 0 ; i &lt; s.length() ; i++)&#123;            if(s.charAt(i) != &#39; &#39;)                dest.append(s.charAt(i));            else                    dest.append(&quot;%20&quot;);    &#125;        return dest.toString();    &#125;&#125;</code></pre><h1 id="2-0-n-1缺失数字"><a href="#2-0-n-1缺失数字" class="headerlink" title="2.    0~n-1缺失数字"></a>2.    0~n-1缺失数字</h1><pre><code>一个长度为n-1的递增排序数组中的所有数字都是唯一的，并且每个数字都在范围0～n-1之内。在范围0～n-1内的n个数字中有且只有一个数字不在该数组中，请找出这个数字。示例 1:输入: [0,1,3]输出: 2示例 2:输入: [0,1,2,3,4,5,6,7,9]输出: 8</code></pre><h2 id="二分思想"><a href="#二分思想" class="headerlink" title="二分思想"></a>二分思想</h2><pre><code>class Solution &#123;    public int missingNumber(int[] nums) &#123;        int left = 0 ;        int right = nums.length - 1 ;        int middle;        while(left &lt;= right)&#123;            middle = (left + right)&gt;&gt;1;            if(nums[middle] == middle)&#123;//那就是后半段的问题                left  = middle+1;//范围缩小到右边            &#125;else&#123;//前半段出错                right  = middle-1;//范围缩小到左边            &#125;        &#125;        return left;    &#125;&#125;</code></pre><h1 id="3-左旋转字符串"><a href="#3-左旋转字符串" class="headerlink" title="3.左旋转字符串"></a>3.左旋转字符串</h1><pre><code>字符串的左旋转操作是把字符串前面的若干个字符转移到字符串的尾部。请定义一个函数实现字符串左旋转操作的功能。比如，输入字符串&quot;abcdefg&quot;和数字2，该函数将返回左旋转两位得到的结果&quot;cdefgab&quot;。示例 1：输入: s = &quot;abcdefg&quot;, k = 2输出: &quot;cdefgab&quot;示例 2：输入: s = &quot;lrloseumgh&quot;, k = 6输出: &quot;umghlrlose&quot;</code></pre><h2 id="暴力split"><a href="#暴力split" class="headerlink" title="暴力split"></a>暴力split</h2><pre><code>class Solution &#123;    public String reverseLeftWords(String s, int n) &#123;        StringBuffer rep = new StringBuffer();        for(int i = 0 ; i &lt; n ; i++)&#123;            rep.append(s.charAt(i));        &#125;        return rep.insert(0,s.split(rep.toString(),2)[1]).toString();    &#125;&#125;</code></pre><h2 id="（耗时短）两次for，不用split"><a href="#（耗时短）两次for，不用split" class="headerlink" title="（耗时短）两次for，不用split"></a>（耗时短）两次for，不用split</h2><pre><code>class Solution &#123;    public String reverseLeftWords(String s, int n) &#123;        StringBuffer rep = new StringBuffer();        for(int i = n ; i &lt; s.length() ; i++)&#123;            rep.append(s.charAt(i));        &#125;        for(int i = 0 ; i &lt; n ; i++)&#123;            rep.append(s.charAt(i));        &#125;        return rep.toString();            &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>三种情况的层序遍历</title>
      <link href="/zjh/2022/07/20/%E4%B8%89%E7%A7%8D%E6%83%85%E5%86%B5%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86/"/>
      <url>/zjh/2022/07/20/%E4%B8%89%E7%A7%8D%E6%83%85%E5%86%B5%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86/</url>
      
        <content type="html"><![CDATA[<h1 id="1-连续遍历"><a href="#1-连续遍历" class="headerlink" title="1.连续遍历"></a>1.连续遍历</h1><h2 id="1-1题目描述"><a href="#1-1题目描述" class="headerlink" title="1.1题目描述"></a>1.1题目描述</h2><p><img src="https://img-blog.csdnimg.cn/4161f56620434b5bae127fdcd7fde2cf.png"></p><p><a href="https://leetcode.cn/problems/cong-shang-dao-xia-da-yin-er-cha-shu-lcof/solution/mian-shi-ti-32-i-cong-shang-dao-xia-da-yin-er-ch-4/">参考答案</a></p><h2 id="1-2解题思路"><a href="#1-2解题思路" class="headerlink" title="1.2解题思路"></a>1.2解题思路</h2><ul><li><p><strong>层序遍历BFS一般都是需要用<code>队列</code>来辅助实现</strong>，不同于深度优先DFS，BFS一般是不用递归的。递归会导致越来越深入，不符合广度优先</p></li><li><p>第一行入队————》pop取queue中的node——》取值——》node的left  right 入队</p></li><li><p>此时队列中的顺序符合BFS</p></li><li><p>循环，queue继续pop取node——》取值——》该node的left right继续入队</p></li><li><p>如此循环pop并入队，队列中的顺序一直符合BFS</p></li></ul><h3 id="1-2-1创建Queue的技巧"><a href="#1-2-1创建Queue的技巧" class="headerlink" title="1.2.1创建Queue的技巧"></a>1.2.1创建Queue的技巧</h3><ul><li>Queue是一个接口，不能直接实例化</li><li>因为LinkedList实现了Queue接口，可以用其实例化</li><li>{<code>外部这个大括号表示匿名对象,可以在这一层进行@Overide</code>  {<code>内部这个大括号相当于在外面调用this.add()</code>}   }</li></ul><pre><code>    LinkedList&lt;Integer&gt; integers = new LinkedList&lt;Integer&gt;() &#123;//匿名对象        @Override public boolean add(Integer integer) &#123;            return super.add(66666);//这会导致所有的add都是添加66666        &#125;        &#123;//这一层的&#123;&#125;相当于在外层写add            add(1);            add(2);            add(3);        &#125;    &#125;;    integers.add(4);    integers.add(5);    integers.add(6);    integers.add(7);    System.out.println(integers);//一共有3+4=7条    //[66666, 66666, 66666, 66666, 66666, 66666, 66666]</code></pre><p>因此我们可以直接</p><pre><code>    Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;()&#123;        &#123;            add(root);        &#125;    &#125;;</code></pre><h3 id="1-2-2需要注意的点"><a href="#1-2-2需要注意的点" class="headerlink" title="1.2.2需要注意的点"></a>1.2.2需要注意的点</h3><ul><li>返回一个空int[ ] 是直接<code>return new int[]&#123;&#125;</code>；</li><li>队列的弹出API是 queue.<code>poll()</code></li></ul><p>最终代码</p><pre><code>/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123;    public int[] levelOrder(TreeNode root) &#123;        //第一步永远是判断是否空        if(root == null) return new int[]&#123;&#125;;        //ArrayList方便添加元素，最后转int[]即可        ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;();        //用Queue来存储BFS的节点,利用匿名对象内部&#123;&#125;初始化        Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;()&#123;            &#123;                add(root);            &#125;        &#125;;        //因为最开始 每次循环只pop一次，但是可能会添加多次        //最后一次pop时早已没有添加的        //所以可以用!queue.isEmpty()作为判断条件        while(!queue.isEmpty())&#123;            TreeNode now = queue.poll();//当前节点            list.add(now.val);            //添加完成当前节点值后，往queue增加节点            if(now.left != null) queue.add(now.left);            if(now.right != null) queue.add(now.right);        &#125;        int[] dest = new int[list.size()];        for(int i = 0 ; i &lt; list.size() ; i++)&#123;            dest[i] = list.get(i);        &#125;        return dest;    &#125;&#125;</code></pre><h1 id="2-分层遍历"><a href="#2-分层遍历" class="headerlink" title="2.分层遍历"></a>2.分层遍历</h1><h2 id="2-1题目描述"><a href="#2-1题目描述" class="headerlink" title="2.1题目描述"></a>2.1题目描述</h2><p><img src="https://img-blog.csdnimg.cn/120db7e3decd449d88728c5146bfc183.png"></p><p>与上一题不同，这一题需要一层一行，最终返回一个二维list<br><img src="https://img-blog.csdnimg.cn/c75421394cdb445dad9d613a44ec8f0b.png"><br>其内层的每个List，都是二叉树的一整层</p><p><a href="https://leetcode.cn/problems/cong-shang-dao-xia-da-yin-er-cha-shu-ii-lcof/solution/mian-shi-ti-32-ii-cong-shang-dao-xia-da-yin-er-c-5/">参考答案</a></p><h2 id="2-2解题思路"><a href="#2-2解题思路" class="headerlink" title="2.2解题思路"></a>2.2解题思路</h2><ul><li><p>while每次循环都必须要new一个内层List</p></li><li><p>while每次循环都要把这个new出来的内层List填满</p><h3 id="2-2-1分析和第一题的差异"><a href="#2-2-1分析和第一题的差异" class="headerlink" title="2.2.1分析和第一题的差异"></a>2.2.1分析和第一题的差异</h3></li><li><p>第一题中，while中没有new 一个List</p><pre><code>      while(!queue.isEmpty())&#123;          TreeNode now = queue.poll();//当前节点          list.add(now.val);          //添加完成当前节点值后，往queue增加节点          if(now.left != null) queue.add(now.left);          if(now.right != null) queue.add(now.right);      &#125;</code></pre></li><li><p>第一次改造，发现每次while循环只往temp中添加了一个元素</p><pre><code>      while(!queue.isEmpty())&#123;  ——————————》    ArrayList&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;();          TreeNode now = queue.poll();//当前节点   ——————————》       temp.add(now.val);          if(now.left != null) queue.add(now.left);          if(now.right != null) queue.add(now.right);      &#125;</code></pre></li><li><p>第二次改造，每次把<strong>当前queue</strong>中的元素全部poll到temp中<code>要先固定for循环的次数</code></p><pre><code>      while(!queue.isEmpty())&#123;          ArrayList&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;();     ————》 for(int i = 0 ; i &lt; queue.size() ; i++)&#123;//因为for循环的内部会往queue添加元素，所以要先固定for循环的次数          TreeNode now = queue.poll();//当前节点            temp.add(now.val);          if(now.left != null) queue.add(now.left);          if(now.right != null) queue.add(now.right);     ————》     &#125;      &#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/7cc91d44855f43f3983541ac049ae43e.png"></p></li></ul><h3 id="2-2-2需要注意的点（集合for循环的开始条件）"><a href="#2-2-2需要注意的点（集合for循环的开始条件）" class="headerlink" title="2.2.2需要注意的点（集合for循环的开始条件）"></a>2.2.2需要注意的点（集合for循环的开始条件）</h3><p><img src="https://img-blog.csdnimg.cn/e1adac2f5dcd47b78bfdf4d368ec20cc.png"></p><p>所有跟集合相关的for循环开始条件，都必须先<code>int i = size()</code>，因为size可能会在for循环的过程中变动</p><h3 id="2-2-3最终结果"><a href="#2-2-3最终结果" class="headerlink" title="2.2.3最终结果"></a>2.2.3最终结果</h3><pre><code>/** * Definition for a binary tree node. * public class TreeNode &#123; *     int val; *     TreeNode left; *     TreeNode right; *     TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123;    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;        List&lt;List&lt;Integer&gt;&gt; destList =  new ArrayList&lt;List&lt;Integer&gt;&gt;();        //先判断root==null的情况        if(root == null) return destList;        //创建TreeNode的队列        Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;()&#123;            &#123;                add(root);//初始化            &#125;        &#125;;        //while循环 内层for循环填满每个temp        while(!queue.isEmpty())&#123;            ArrayList&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;();          //  for(int i = 0 ; i &lt; queue.size() ; i++)&#123;queue.size()在随元素弹出的过程中动态变化            for(int i = queue.size() ; i &gt; 0 ; i--)&#123;//固定for循环的次数,保证循环的是本层            TreeNode now = queue.poll();            temp.add(now.val);            //往queue中添加下一层的元素（完整的for循环之后，queue中刚好只有下一层的所有元素）            if(now.left != null) queue.add(now.left);//防止被这两条影响temp长度            if(now.right != null) queue.add(now.right);//防止被这两条影响temp长度            &#125;            destList.add(temp);        &#125;        return destList;    &#125;&#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/7d43a9c2faed4360a0c2d4cfb11a5571.png"></p><h1 id="3-分层交叉遍历"><a href="#3-分层交叉遍历" class="headerlink" title="3.分层交叉遍历"></a>3.分层交叉遍历</h1><p><img src="https://img-blog.csdnimg.cn/7adcfa2252c0464992ef60c07d002163.png"></p><h2 id="3-1简单粗暴直接reverse"><a href="#3-1简单粗暴直接reverse" class="headerlink" title="3.1简单粗暴直接reverse()"></a>3.1简单粗暴直接reverse()</h2><h3 id="3-1-1取余位运算"><a href="#3-1-1取余位运算" class="headerlink" title="3.1.1取余位运算"></a>3.1.1取余位运算</h3><p><code>当x=2^n(n为自然数)时，</code></p><p><code>a % x = a &amp; (x  - 1 )</code></p><h3 id="3-1-2Collections-reverse"><a href="#3-1-2Collections-reverse" class="headerlink" title="3.1.2Collections.reverse()"></a>3.1.2Collections.reverse()</h3><p><img src="https://img-blog.csdnimg.cn/e3ac409d55fa4ff3a6120ce9c2eed88d.png"></p><p>但是leetcode中用不了Collections工具包</p><h2 id="3-2最终写法-链表（双端队列）"><a href="#3-2最终写法-链表（双端队列）" class="headerlink" title="3.2最终写法:链表（双端队列）"></a>3.2最终写法:链表（双端队列）</h2><p><img src="https://img-blog.csdnimg.cn/70470ac93bbf4ae89b65aa2c87c04029.png"></p>]]></content>
      
      
      <categories>
          
          <category> 数据结构算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>内存区域、类的加载</title>
      <link href="/zjh/2022/07/19/%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E3%80%81%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD/"/>
      <url>/zjh/2022/07/19/%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%E3%80%81%E7%B1%BB%E7%9A%84%E5%8A%A0%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="0-JVM和字节码"><a href="#0-JVM和字节码" class="headerlink" title="0.JVM和字节码"></a>0.JVM和字节码</h1><ul><li>JVM实际上现在已经成为了<strong>跨语言平台</strong>，只要按字节码生成规则，都可以在JVM上运行</li><li>JVM规范中最具含金量的虚拟机实现是HotSpot也是JDK1.3至今的默认虚拟机，其他的还有JRockit、IBM J9等</li><li>JDK9之后 G1垃圾回收器完全替代了CMS</li><li>编译成规范的字节码的好处是：一次编译，到处运行</li></ul><h2 id="0-1JVM和传统虚拟机"><a href="#0-1JVM和传统虚拟机" class="headerlink" title="0.1JVM和传统虚拟机"></a>0.1JVM和传统虚拟机</h2><ul><li>传统意义上的虚拟机如VMware，它是在硬件层面模拟了一个操作系统</li><li>而JVM是在操作系统之上，<strong>解释运行字节码文件</strong>的一个细粒度的虚拟机。<strong>它没有和硬件直接交互</strong></li><li>他们的层次是: 硬件——操作系统——JVM——字节码 </li></ul><h2 id="0-2三种虚拟机"><a href="#0-2三种虚拟机" class="headerlink" title="0.2三种虚拟机"></a>0.2三种虚拟机</h2><p><img src="https://img-blog.csdnimg.cn/b4d3c3fb6a394e389c92832eb6adbe28.png" alt="引用"></p><p><img src="https://img-blog.csdnimg.cn/4b6c72d00e104b0d8fe71bdeeb8d8692.png" alt="引用"></p><p><img src="https://img-blog.csdnimg.cn/860d9efd535c422ca9c6c693a7d75946.png" alt="引用"></p><h1 id="1-内存管理概述"><a href="#1-内存管理概述" class="headerlink" title="1.内存管理概述"></a>1.内存管理概述</h1><ul><li>对于Java程序员来说，在<code>JVM自动内存管理机制</code>的帮助下，不需要为每一个new出来的对象配对<code>delete/free</code>去释放内存，<strong>不容易出现出现内存泄漏和内存溢出问题。</strong><br>但是一旦出现了这方面的问题，不了解JVM是怎么使用内存的话就很难排查错误。</li><li><code>HotSpot是</code>JVM概念的一个实现，最初由Sun开发，现在由Oracle拥有。 还有其他JVM规范的实现，如<code>JRockit ， IBM J9</code>等等。 </li></ul><h1 id="2-运行时数据区"><a href="#2-运行时数据区" class="headerlink" title="2.运行时数据区"></a>2.运行时数据区</h1><p>JVM运行时会把它所管理的内存划分为若干个不同的数据区，有的区域随JVM启动而一直存在，有的区域依赖用户线程的启动和结束。它包括了以下几种运行时数据区。<br>（按相关性和逻辑顺序依次介绍）</p><h2 id="2-1程序计数器"><a href="#2-1程序计数器" class="headerlink" title="2.1程序计数器"></a>2.1程序计数器</h2><p>首先：JVM的多线程是靠<code>线程轮流切换、分配处理器执行时间</code>来实现的，那么在切换的过程中，如何确定当前线程执行到哪里了呢？</p><ul><li><code>线程私有</code>：每个线程都有自己独立的程序计数器，独立存储，互不影响</li><li>程序计数器占用的内存空间很小</li><li><code>字节码解释器</code>就是通过改变程序计数器的值，<strong>来选取下一条需要执行的字节码指令</strong></li><li><strong>分支、循环、跳转、异常处理、线程恢复</strong>等功能都依赖于程序计数器</li></ul><h2 id="2-2虚拟机栈"><a href="#2-2虚拟机栈" class="headerlink" title="2.2虚拟机栈"></a>2.2虚拟机栈</h2><h3 id="2-2-1概念"><a href="#2-2-1概念" class="headerlink" title="2.2.1概念"></a>2.2.1概念</h3><ul><li><code>线程私有</code>，其生命周期和线程相同</li><li>每一个方法被执行的时候，JVM都会同步创建一个<code>栈帧</code></li><li><code>栈帧</code>用于存储：<strong>局部变量、操作数栈、动态连接、方法出口等信息</strong></li><li>每一个方法从调用到结束，对应一个栈帧的入栈出栈</li></ul><h3 id="2-2-2局部变量表"><a href="#2-2-2局部变量表" class="headerlink" title="2.2.2局部变量表"></a>2.2.2局部变量表</h3><p>虚拟机栈一般都用来指<code>局部变量表</code>，一般包括：</p><ul><li>8种基本数据类型（其中long和double占用<strong>两个局部变量槽Slot</strong>）</li><li>对象引用,如People p = new People()种的p；int[] arr = new int[]{}中的arr</li><li>因此虚拟机栈的大小<strong>是可以完全确定的</strong>，如果线程请求的虚拟机栈深度&gt;JVM允许的最大深度，则会报错<code>StackOverflowError</code>即俗称的<code>爆栈</code>，在递归调用的时候较为容易出现爆栈的情况</li></ul><h2 id="2-3本地方法栈"><a href="#2-3本地方法栈" class="headerlink" title="2.3本地方法栈"></a>2.3本地方法栈</h2><ul><li><code>线程私有</code></li><li>本地：native：即指编写JDK所用到底层C++库</li><li>它和虚拟机栈大同小异，区别就是：<strong>虚拟机栈调用的是Java方法的字节码，本地方法栈调用的是C++的库</strong></li><li>JVM的HotSpot实现将它们二者合二为一了</li></ul><h2 id="2-4堆"><a href="#2-4堆" class="headerlink" title="2.4堆"></a>2.4堆</h2><blockquote><p>一般Java程序员在没有了解JVM的情况下，喜欢把JVM粗略的分为堆和栈，这种分法来自于C++，但JVM规范中的划分更加复杂</p></blockquote><ul><li><code>多线程共享</code></li><li>堆是JVM管理内存中最大的一块，<code>几乎所有</code>的对象实例都存放于此</li><li>对于大的对象（典型如数组）一般都是使用连续的内存空间</li><li>Java堆是可扩展的，一般通过设置<code>-Xmx和-Xms</code>，超过最大限度后报错OutOfMemoryError，即俗称的<code>OOM</code></li><li>Java堆也叫<code>GC堆，因为其是垃圾收集器管理内存的区域</code></li></ul><h2 id="2-5方法区和元空间"><a href="#2-5方法区和元空间" class="headerlink" title="2.5方法区和元空间"></a>2.5方法区和元空间</h2><blockquote><p>在JDK8以前，很多程序员喜欢使用HotSpot来开发Java程序，HotSpot将<strong>分代设计</strong>拓展至了方法区，因此很多人将方法区和永久代混为一谈。此外永久代也出现了很多严重的内存泄露BUG，因此目前被摒弃</p></blockquote><blockquote><p>对于JRockit、IBM J9虚拟机来说，永久代被完全摒弃，取而代之的是<code>元空间</code>，同理<strong>方法区是HotSpot独有的</strong></p></blockquote><ul><li> <code>多线程共享</code></li><li>准确来说，<strong>永久代实现了方法区，在JDK8之后替换为了元空间实现方法区</strong>。二者效果相近。</li><li>对于以前永久代中的<code>静态变量、字符串常量池</code>，目前是放在了堆Heap中</li><li>元空间使用本地内存也就意味着只要本地内存足够，就不会出现OOM的错误。</li><li>Java1.8的运行时数据区域如图所示。方法区已经不见了踪影，多出来的是叫做元数据区的区域。<br><img src="https://img-blog.csdnimg.cn/d66f7775a3224bba8821b9b060fe650e.png" alt="引用"></li></ul><h2 id="2-6运行时常量池"><a href="#2-6运行时常量池" class="headerlink" title="2.6运行时常量池"></a>2.6运行时常量池</h2><p>Class常量池(又称常量池) :主要用于存放两大类常量:字面量(Literal)和符号引用量(Symbolic References)。</p><p>字面量相当于Java语言层面常量的概念,如文本<strong>字符串</strong>，声明为<strong>final</strong>的常量值等；</p><p>符号引用则属于编译原理方面的概念，包括了<strong>三种类型的常量</strong>:<strong>类和接口的全限定名</strong>、<strong>字段名称和描述符</strong>、<strong>方法名称和描述符</strong>。</p><p><img src="https://img-blog.csdnimg.cn/33f7c62d082d4f19bdc62bd846934edc.png" alt="引用"></p><h2 id="2-7-直接内存"><a href="#2-7-直接内存" class="headerlink" title="2.7*直接内存"></a>2.7*直接内存</h2><p>这个直接内存并不是JVM运行时数据区的一部分，它是JDK4引入的<strong>NIO的一种缓冲优化策略：</strong><br>可以将Native库直接分配到堆外内存，然后通过Java堆中的一个缓冲对象来引用，<strong>避免了反复在Java堆和Native堆的复制数据。</strong></p><h1 id="3-类的加载"><a href="#3-类的加载" class="headerlink" title="3.类的加载"></a>3.类的加载</h1><h2 id="3-1"><a href="#3-1" class="headerlink" title="3.1"></a>3.1</h2>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Restful风格真的有必要吗？</title>
      <link href="/zjh/2022/07/19/Restful%E9%A3%8E%E6%A0%BC%E7%9C%9F%E7%9A%84%E6%9C%89%E5%BF%85%E8%A6%81%E5%90%97/"/>
      <url>/zjh/2022/07/19/Restful%E9%A3%8E%E6%A0%BC%E7%9C%9F%E7%9A%84%E6%9C%89%E5%BF%85%E8%A6%81%E5%90%97/</url>
      
        <content type="html"><![CDATA[<p>到现在经过了两段实习，也因为喜欢网上冲浪，认识了不少大厂的朋友。反正大家的一致意见都是Restful利大于弊。我查了几天资料，稍微总结一下</p><h1 id="为什么不用Restful"><a href="#为什么不用Restful" class="headerlink" title="为什么不用Restful"></a>为什么不用Restful</h1><h2 id="1-浏览器方面"><a href="#1-浏览器方面" class="headerlink" title="1.浏览器方面"></a>1.浏览器方面</h2><ul><li>浏览器普遍对GET和POST的支持最好</li><li>浏览器表单form提交只支持GET和POST</li></ul><h2 id="2-SpringMVC方面"><a href="#2-SpringMVC方面" class="headerlink" title="2.SpringMVC方面"></a>2.SpringMVC方面</h2><ul><li><strong>SpringMVC解析POST请求可以自动解析param和body，不需要加注解，而PUT DELETE请求必须加@RequestParam、@PathVariable、@RequestBody注解</strong>，虽然Spring3支持对PUT请求体的映射，但是需要在web.xml或者WebMvcConfigurerAdapter中进行配置————————这一点确实很好用，我现在维护的这个项目时间长了觉得真的很方便，很多没必要去字段匹配的直接写就好了</li></ul><h2 id="3-业务方面"><a href="#3-业务方面" class="headerlink" title="3.业务方面"></a>3.业务方面</h2><ul><li>一个“删”“改”操作不一定会那么干净，里面可能会夹杂很多的“查”“增”操作，但用一个PUT连基本RESTful的优势都成了劣势</li><li>增删改查的不同操作可以通过url的最后一项来区分：例如 */deleteXxxx或editXxxx</li><li>Restful只是一种风格，不是规范，对业务没有帮助</li></ul><h2 id="4-Http协议方面"><a href="#4-Http协议方面" class="headerlink" title="4.Http协议方面"></a>4.Http协议方面</h2><ul><li>同时，<strong>POST请求在大多数浏览器中默认提交两次tcp包，在网络环境差的情况下更保险</strong></li><li><strong>PUT和DELETE在http协议中本质和POST一样，没有任何优势</strong>，反而在SpringMVC中容易出现一些问题</li></ul><h1 id="什么时候能用Restful"><a href="#什么时候能用Restful" class="headerlink" title="什么时候能用Restful"></a>什么时候能用Restful</h1><p>当且仅当</p><ul><li><strong>幂等修改删除</strong>可以用put，delete；不幂等用post</li><li>删除就是删除，修改就是修改，不会影响其他的业务数据</li><li>培训机构忽悠小白时</li></ul><h1 id="Get和Post的一些区别"><a href="#Get和Post的一些区别" class="headerlink" title="Get和Post的一些区别"></a>Get和Post的一些区别</h1><ul><li>“是否提交大量数据”的功能可以直接由POST和GET来区分，GET不能放body参数，数据只能裸露放在url上，但浏览器url的长度大多限制为2kb，可以用POST来放body参数。</li><li>GET请求的请求数据可能被浏览器缓存</li><li>如果非幂等请求用GET，结果如果被缓存就会出错，可以通过请求<strong>参数带时间戳等不重复无关参数</strong>来强制防止缓存</li><li>如果敏感信息用GET，那你的敏感信息就可能被完整的保存在了本地浏览器。当然，可以通过加密手段解决</li></ul>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>气象cv-地基云图云系分割</title>
      <link href="/zjh/2022/07/17/%E6%B0%94%E8%B1%A1cv-%E5%9C%B0%E5%9F%BA%E4%BA%91%E5%9B%BE%E4%BA%91%E7%B3%BB%E5%88%86%E5%89%B2/"/>
      <url>/zjh/2022/07/17/%E6%B0%94%E8%B1%A1cv-%E5%9C%B0%E5%9F%BA%E4%BA%91%E5%9B%BE%E4%BA%91%E7%B3%BB%E5%88%86%E5%89%B2/</url>
      
        <content type="html"><![CDATA[<h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><h2 id="1-1-题目概述"><a href="#1-1-题目概述" class="headerlink" title="1.1 题目概述"></a>1.1 题目概述</h2><p>卫星云图包含丰富的云信息，从中可以形象直观地看到云系的形状和演变情况，卫星云图的应用也非常广泛，例如天气分析、降水估计和暴雨短时预报系统中，也要求输入云图信息。为使云图判识客观化、自动化，扩展卫星云图在天气预报、环境监测中的应用，进行云图定量自动判识研究是必要的。云图自动判识包括云图分割和识别两部分，对云图的分割研究一直处于摸索中，存在着诸多困难，基于对自动识别云图、对云进行自动分割这种技术的需要，本文主要对地基云图云系分割技术开展探索研究。</p><h2 id="1-2-研究意义"><a href="#1-2-研究意义" class="headerlink" title="1.2 研究意义"></a>1.2 研究意义</h2><p>随着科学技术的不断发展，气象观测领域的计算机技术、传感技术有了很大的进步，目前对温度、气压、湿度以及风的观测方法已基本实现了自动化，可在云的观测中，只对云高的测量实现了自动化，对云状、对于卫星云图的自动分割技术还处于探索阶段，它的难点在于，一幅云图上常常有多种不同的云系存在，而且云系的灰度随云系的种类、地域和时间而变，同时云系的形状很不规则，不能简单地用阈值或形状将不同云系分割开。<br>目前关于对云图的研究工作，大部分都集中在卫星云图方面，而对从地面向上所拍摄的地基云图研究比较少。目前对云图云系的分割还需要进行手动分割，这会带来很多缺陷，首先手动分割会耗费大量的人力与精力，其次，人工分割对于图像边缘或者单独小块的云难以分割清楚，这就会带来一定的精度误差，影响云识别的准确性。因此本研究对于实现地基云图的自动分割具有一定价值。</p><h1 id="2-数据准备"><a href="#2-数据准备" class="headerlink" title="2. 数据准备"></a>2. 数据准备</h1><h2 id="2-1-数据准备"><a href="#2-1-数据准备" class="headerlink" title="2.1 数据准备"></a>2.1 数据准备</h2><h3 id="2-1-1-数据集介绍"><a href="#2-1-1-数据集介绍" class="headerlink" title="2.1.1 数据集介绍"></a>2.1.1 数据集介绍</h3><p>本实验采用了给定的卫星云图数据集。该数据集共有六百张分辨率为 256*256 的彩色 jpg 图片，我们发现地基云图是观测到的覆盖了多种不同地形的各种云图，其中包含了高山、海面、稻田、山脊等各种地形，识别难度较大。同时了解到地基云观测数据主要包括云量、云状、云底高度，根据<br>三者的不同表现可以将云分为 3 族、10 属、29 类，具有种类多、变化快、相似、易与天空背景融合等特点。因此本实验考虑到要适用于各种地形，所以在选择训练集和测试集的时候，进行了初步的筛选。在考虑到了地形、云量等影响因素，在进行了筛选之后，我们选择了 cloud101-cloud300、cloud401-cloud500 以及 cloud601-cloud700 作为我们的训练集，其余的作为测试集。部分原始数据如下所示。</p><p><img src="https://img-blog.csdnimg.cn/2e4139b48d14476fb0b1ec9fdc9d30e9.png"></p><h3 id="2-1-2-数据增强"><a href="#2-1-2-数据增强" class="headerlink" title="2.1.2 数据增强"></a>2.1.2 数据增强</h3><p>有了原始数据后，还需要相应的标签才能构建完整训练数据集。一般处理图像类的卷积神经网络输入都是图像，而标签(或言之输出结果)是根据任务而定的。以分类任务为例，标签就是一个单一类别，以目标检测为例，输出是 4 维向量。语义分割结合了图像分类、目标检测和图像分割，通过一定的方法将图像分割成具有一定语义含义的区域块，并识别出每个区域块的语义类别，实现从底层到高层的语义推理过程，最终得到一幅具有逐像素语义标注的分割图像。其本质是对图像中每一个像素进行分类，对图像中每个像素都打上一个标签就是语义分割的标注过程。一般情况下，这个工作需要我们手工完成且工作量极大，本文研究内容是对卫星云图里面的云系进行识别，即是云和不是云的判断，是一个二分类任务。所以选取的云图分割标签如下所示<br><img src="https://img-blog.csdnimg.cn/2989337b5e6645e391c66a48fa19219f.png" alt="表 1 云图分割标签"><br>本文使用 MATLAB 的标注工具箱 imageLabeler 进行人工完整标注，在利用其做好云标注后，利用 python 转换出相应 PNG 格式的标注图像。在图像标注过程中由于是人工标注，因此在云边界标注上有所欠缺，相应部分标注结果图如下所示。<img src="https://img-blog.csdnimg.cn/6b3e69b0aad8466dae10fc476c809589.png"></p><h1 id="3-模型构建"><a href="#3-模型构建" class="headerlink" title="3. 模型构建"></a>3. 模型构建</h1><h2 id="3-1-设计思路"><a href="#3-1-设计思路" class="headerlink" title="3.1 设计思路"></a>3.1 设计思路</h2><p>基于地基云图的分割属于计算机视觉问题中语义分割的应用。语义分割结合了图像分类、目标检测和图像分割，通过一定的方法将图像分割成具有一定语义含义的区域块，并识别出每个区域块的语义类别，实现从底层到高层的语义推理过程，最终得到一幅具有逐像素语义标注的分割图像。<br>在地基云图进行分割，即需要将属于云的像素分为一类，属于天空的像素分为一类。由于缺少气象专业知识，我们仅进行云图的语义分割，没有再进一步划分不同云类的实例分割。<br>由于深度学习在语义分割上得到巨大的成功，我们选择基于深度学习的语义分割模型。常用的语义分割模型包括 FCN、SegNet、DeepLab 系列模型。<br>语义分割模型建立在利用 CNN 网络提取特征分类的基础上，所以面临着需要提升感受野和选择恰当的空间信息的问题。我们选择利用空洞卷积来减少下采样率同时保证感受野的 DeepLabv3+模型。<br>DeepLabv3+模型属于谷歌团队提出的语义分割算法 DeepLab 系列最新改进的版本。其具有速度快、准确度高、模块简单等优点。且其在应用于地基云图分割中，具有不俗的表现，超过 PSPNet、AdapNet 等深度学习算法。[1]</p><h2 id="3-2-模型介绍"><a href="#3-2-模型介绍" class="headerlink" title="3.2 模型介绍"></a>3.2 模型介绍</h2><p>DeeplabV3+主要在模型的架构上引入了可任意控制编码器提取特征的分辨率，通过空洞卷积平衡精度和耗时。DeeplabV3+在 Encoder 部分引入了大量的空洞卷积，在不损失信息的情况下，加大了感受野，让每个卷积输出都包含较大范围的信息。其网络结构图如下所示。</p><p><img src="https://img-blog.csdnimg.cn/6f485ace49b447789d89e9b5a3612fd8.png"><br>由图可以看到他是 Encoder-Decoder 网络结构。接下来我们主要分成 Encoder 和 Decoder 进行解析。<br>Input 经过骨干网络（backbone，也就是图中标注 DCNN Atrous Conv 的部分）得到两个输出：一个是 low-level feature，这是个 output=4x 的输出；另一个是高级特征，给 ASPP 的输出，这是个output=16x 的输出。<br>在 Encoder 中，高级特征经过 ASPP 的 5 个不同的操作得到 5 个输出，其中 1 个 1×1 卷积，3 个不同 rate 的 dillation conv，1 个 ImagePooling。这里要注意 ImagePooling 是全局平均池化之后再上采样到原来大小。这 5 个输出经过 concatenate 操作和 1×1 卷积得到 output stride=16x 的输出。使用<br>deeplabv3 作为编码器。网络中的空洞卷积提取特征，获取多尺度的上下文信息，同时替代了下采样，使输出的 feature map 的 output_stride=16。ASPP 模块使用了多个平行的空洞卷积，配合了图像级特征（即全局平均池化）。</p><p>在这里 ， 一方面 encoder 输 出 的 feature(output_stride=16)经 过 双 线 性 上 采 样 4 倍 得 到FA(output_stride=4), 再取 encoder 中对应着相同分辨率(即 output_stride=4)的特征层，经过 1×1 卷积降通道，此时输出的 feature 记为 FBF。这里经过 1×1 卷积降通道，是因为此分辨率的特征通道较多(256<br>或 512)，而 FA 输出只有 256，故降通道以保持与 FA 所占比重，利于模型学习。将 FA 和 FB 做 concat，再经过一个 3×3 卷积细化 feature，最终再双线性上采样 4 倍得到预测结果。<br>另一方面，encode 主体部分，替换成深度扩张分离卷积网络。深度可分离卷积是把标准卷积分解成深度卷积(depthwise convolution)和逐点卷积(pointwise convolution)。深度卷积对每个通道独立使用空间卷积，逐点卷积用于结合深度卷积的输出。深度分离卷积可以大幅度降低参数量和计算量。<br>deeplabv3+将扩张卷积和深度分离卷积结合到一起，即扩张分离卷积。扩张分离卷积能够显著的减少模型的计算复杂度并维持相似的表现， 如下图：</p><p><img src="https://img-blog.csdnimg.cn/dc183a96f2c94aea85d45b54aea36653.png"><br>在 Decoder 中，两个输入分别操作：low-level featur 经过 1x1 卷积调整维度（output stride=4x），论文 4.1 节介绍实验结果表明 low-level feature 调整到 48 channels 时效果最好；Encoder 输出上采样 4倍（output stride 从 16x 变为 4x）。将两个 4x 特征 concatenate，后面接一些 3×3 卷积，再上采样 4 倍得到 Dense Prediction。论文 4.1 节介绍实验结果表明 decoder 两个 4x 输出特征 concatenate，后面接2 个 out_channels=256 的 3x3 卷积，输出效果较好，可采用这种设计。Decoder 里面所有的 Upsample都是用双线性差值。得到最终的有效特征层后，利用一个 1x1 卷积进行通道调整，调整到 Num_Classes；然后利用resize 进行上采样使得最终输出层，宽高和输入图片一样。</p><h1 id="4-模型训练"><a href="#4-模型训练" class="headerlink" title="4. 模型训练"></a>4. 模型训练</h1><h2 id="4-1-训练环境"><a href="#4-1-训练环境" class="headerlink" title="4.1 训练环境"></a>4.1 训练环境</h2><p>本文中涉及程序在 matlab 中实现。下表所示为运行环境的配置。</p><p><img src="https://img-blog.csdnimg.cn/5ad01a79537c4a0b8220d66bdb400ad9.png"></p><h2 id="4-2-超参数设置"><a href="#4-2-超参数设置" class="headerlink" title="4.2 超参数设置"></a>4.2 超参数设置</h2><p>因为需要足够大且含有人工标定标签的训练样本来训练网络，我们选择使用迁移学习来训练神经网络。选择 mobilenetv2 作为图像特征选取网络，因为该模型使用 ImageNet 数据集进行预训练，将该模型的参数作为初始化参数。迁移学习能提高训练的效率。本实验采用微调的方法，即把预训<br>练好的模型用于数据，使参数适应自己的数据集。<br>在训练过程中，批处理大小为 1，根据图像大小，定义网络输入大小为 256x256x3。选择 adam优化器，其具有实现简单、计算高效、对内存需求少并且其参数的更新不受梯度的伸缩变换影响的优点。而且我们发现其超参数具有很好的解释性，且通常无需调整或仅需很少的微调。将初始学习率设置为 1e-3，同时设置根据迭代的代数自动调整学习率，每 20 代学习率降低 0.4。选择 L2 范数作为损失函数进行正则化，保持较小的权重，防止模型过拟合。L2 正则化因子设置为 0.005。训练集最大得带次数为 40 次，每次训练迭代的最小批次为 8，在每个训练时期前都将数据进行重新排序。将测试集数据作为训练期间用于验证的数据，同时验证指标评估的迭代 2 次。</p><h2 id="4-3-训练过程"><a href="#4-3-训练过程" class="headerlink" title="4.3 训练过程"></a>4.3 训练过程</h2><p><img src="https://img-blog.csdnimg.cn/b38800ee8f4a4d85adeeb37e3ed7740e.png"></p><h1 id="5-模型测试与结果分析"><a href="#5-模型测试与结果分析" class="headerlink" title="5. 模型测试与结果分析"></a>5. 模型测试与结果分析</h1><h2 id="5-1-模型测试"><a href="#5-1-模型测试" class="headerlink" title="5.1 模型测试"></a>5.1 模型测试</h2><p><img src="https://img-blog.csdnimg.cn/0bfdc32d55ae4180b4a599c714419d32.png"><br><img src="https://img-blog.csdnimg.cn/077a4234208a41d8b31a9a77996a0c70.png"><br><img src="https://img-blog.csdnimg.cn/d092039c2d22455796ed5ec243fb561a.png"><br><img src="https://img-blog.csdnimg.cn/7ab7ee3370ff4d64bf09cb8ff72d9320.png"><br><img src="https://img-blog.csdnimg.cn/1c6eea866e764d71b007eefd7013bf21.png"><br>选取了 5 张测试图使用网络测试，结果如上。可以发现，对比之前浅色区域识别不佳的情况，在增加训练集数量后，明显提高了识别度。然而，仍有将白色建筑错误识别成云的情况，因此在后续的过程中，可以将云的块状特征以及不规则特征进行提取，将形状规则的、体积较小的白色建筑物在识别过程中剔除。<br>观察训练网络的过程，开始准确度上升极快，到后期准确度几乎不发生变化，甚至有降低，因此可以降低迭代的次数，来进行更多参数的测试。</p><h1 id="6-总结与展望"><a href="#6-总结与展望" class="headerlink" title="6. 总结与展望"></a>6. 总结与展望</h1><p>通过阅读文献与相关资料，我们对卫星云图分割的研究内容及其研究现状有了一定的了解。云图分割是地基云图云系处理过程中非常重要的环节，在实际生活中得到非常广泛的应用。云图分割效果好坏直接影响对图像的进一步分析、识别以及分类的有效性和准确性，因此具有非常重要的意义。<br>通过对地基云图特点的分析，以及对各种分割算法特点的了解，提出了一种基于 DeepLabv3+模型的地基云图分割算法，由于受到各方面因素的影响，使图像的质量好坏不一以及图像本身复杂度增大，使得很难有一种适用于所有地基云图的分割方法，因此对地基云图的分割方法的研究还有很长的路要走。<br>此次研究报告我们选择通过 DeepLabv3+模型对地基云图云系进行语义分割，并搭建了Encoder-Decoder 网络结构使用迁移学习来训练神经网络，在研究过程中调整超参数的二设置来使模型训练达到最好效果，例如 mobilenetv2 作为图像特征，选择 adam 优化器，找到最好的学习率等等。<br>本文只是对地基云图分割的基本内容进行了一些简单的尝试，由于图像分割所涉及的研究内容很广泛，分割方法也是多种多样，受到水平和时间的限制，本文所研究的工作还有很多不足之处，还需要进一步深入研究。</p><h1 id="7-参考文献"><a href="#7-参考文献" class="headerlink" title="7. 参考文献"></a>7. 参考文献</h1><p>[1]刘普. 基于深度学习的地基云图分类与分割研究[D].南京信息工程大学,2020</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>支持向量机枣类遗传的回归预测</title>
      <link href="/zjh/2022/07/17/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E6%9E%A3%E7%B1%BB%E9%81%97%E4%BC%A0%E7%9A%84%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B/"/>
      <url>/zjh/2022/07/17/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E6%9E%A3%E7%B1%BB%E9%81%97%E4%BC%A0%E7%9A%84%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<pre><code>import numpy as npimport pandas as pdfrom lazypredict.Supervised import LazyClassifierfrom sklearn.metrics import classification_report, confusion_matrixfrom sklearn.preprocessing import LabelEncoderfrom sklearn.preprocessing import StandardScalerfrom sklearn.model_selection import train_test_splitfrom sklearn.svm import LinearSVCimport seaborn as snsimport matplotlib.pyplot as plt# 读取数据集raw=pd.read_csv(r&#39;code/水果数据集.csv&#39;)# 使用sklearn的编码器，将Class文本类型标签转换为数值类型label_encoder=LabelEncoder()encoded=pd.DataFrame(label_encoder.fit_transform(raw[&#39;Class&#39;]), columns=[&#39;Encoded&#39;])# 复制一份数据集，将编码后的列数据合并df_encoded=raw.copy()df_encoded=pd.concat([df_encoded, encoded], axis=1)# 对空数据进行补全df_encoded[&#39;Encoded&#39;].fillna(0, inplace=True)df_encoded.drop(columns=[&#39;Class&#39;], axis=1, inplace=True)# 自变量和因变量赋值x=df_encoded.drop([&#39;Encoded&#39;], axis=1)y=df_encoded[&#39;Encoded&#39;]# 使用标准归一化方法将数据归一化SS=StandardScaler()x=SS.fit_transform(x)# 划分训练集与测试集，划分比例为6：4x_train,x_test,y_train,y_test =train_test_split(x,y,test_size=0.4, random_state=0)# 使用机器学习包选取最优的预测模型clf = LazyClassifier(predictions=True)models, predictions = clf.fit(x_train, x_test, y_train, y_test)print(models)print(predictions) # 可以看到最优的模型是LinearSVC模型</code></pre><p>运行结果：<br><img src="https://img-blog.csdnimg.cn/f01ae9bb0c314550afd25f68994be86d.png"></p><pre><code># 使用线性支持向量机svc = LinearSVC()# 拟合数据svc.fit(x_train,y_train)y_pre=svc.predict(x_test)# 生成预测报告print(classification_report(y_test,y_pre))# 生成混淆矩阵sns.heatmap(confusion_matrix(y_test,y_pre),annot=True,cmap=&#39;YlGnBu_r&#39;)plt.show()</code></pre><p>运行结果：<br><img src="https://img-blog.csdnimg.cn/724cbaf9fd334370a5ba84004e7365e9.png"><br>混淆矩阵：<br><img src="https://img-blog.csdnimg.cn/6c0bdfe3a13c43499fef9f2e7c038c2a.png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>气象大数据分析</title>
      <link href="/zjh/2022/07/17/%E6%B0%94%E8%B1%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
      <url>/zjh/2022/07/17/%E6%B0%94%E8%B1%A1%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>降水情况的预测对城市管理、居民生活都有巨大影响。本文利用逻辑回归、支持向量机、决策树分类、随机森林四种方法对洛杉矶的天气进行预测，并对这几种方法的预测准确度进行比较。<br><strong>关键词</strong>  回归预测；逻辑回归；支持向量机；决策树分类；随机森林      </p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract:"></a>Abstract:</h1><p>The forecast of precipitation had a huge impact on urban management, residents live. This paper, by us-ing logistic regression, support vector machines, decision tree classification, gaussian naive bayes, gradient in-creasing tree, random forests, XGBoost, CatBoost several methods to predict the weather of the Los Angeles, and prediction accuracy of these methods were compared.<br>Key words: Regression prediction; Logistic regression; SVM; decision tree classification; Random forests</p><p>  目前降水季节趋势预报主要分为统计学、动力学和动力统计相结合三类方法。统计方法充分利用历史资料规律，选取有明确物理意义和显著相关的因子进行建模。但由于各预测因子相互作用过程复杂，不同时间尺度的预测信号不一致，加大了预测的难度。随着数值模式的发展，动力模式成为气候预测的主要工具，许多国家建立了数值预报模式。近年来，我国季节预测模式对大气环流、ENSO(El Niňo-Southern Oscillation)现象、亚洲夏季风等的预测能力已有明显提升,但对降水预测技巧依然有限，特别是对东亚地区夏季降水的预报技巧相对较低。<br>  机器学习强调从历史数据中学习规则，对新数据进行推理和预测。区别于传统统计方法，机器学习擅长处理非线性问题，利用机器学习的优势可以从地球系统中发现并提取新的相互关联信号(贺圣平等，2021)。近年来，机器学习在气象领域的应用越来越广泛，常用的机器学习算法有支持向量机、贝叶斯算法、神经网络、决策树算法等。随着计算能力的提高和深度学习理论的发展，以卷积神经网络(Convolutional Neural Networks, CNN)和长短期时间记忆网络(Long Short-Term Memory, LSTM)为代表的深度学习方法在气候领域得到应用。<br>  洛杉矶降水时空分布不均，影响因子复杂，当前对其机理和预测的研究还存在短板，动力模式预测水平与业务服务需求存在差距，有必要利用机器学习的优势进一步提高当地预测水平。本文采用逻辑回归、支持向量机、决策树分类、高斯朴素贝叶斯、梯度提升树、随机森林、XGBoost、CatBoost，建立适用于洛杉矶的降水统计预测方法。</p><h1 id="1-资料和方法"><a href="#1-资料和方法" class="headerlink" title="1 资料和方法"></a>1 资料和方法</h1><h2 id="1-1-数据介绍"><a href="#1-1-数据介绍" class="headerlink" title="1.1 数据介绍"></a>1.1 数据介绍</h2><p>数据来源kaggle的[Precipitation Prediction in LA] 。<br>本次处理的天气数据有如下特征：<br>PRCP = 降水量（十分之一毫米）<br>TMAX = 最高温度（十分之一摄氏度）<br>TMIN = 最低温度（十分之一摄氏度）<br>PGTM = 阵风高峰时间（小时和分钟，即 HHMM）<br>AWND = 每日平均风速（每秒十分之一米）<br>TAVG = 平均温度（十摄氏度）<br>WDFx = 最快 x 分风向（度）<br>WSFx = 最快 x 分钟风速（每秒十分之一米）<br>WT = 天气类型 </p><h2 id="1-2-数据预处理"><a href="#1-2-数据预处理" class="headerlink" title="1.2 数据预处理"></a>1.2 数据预处理</h2><p>使用pandas框架导入数据并对其进行进一步分析。<br>使用seaborn库将数据分析的结果进行可视化。<br>首先处理PRCR列（目标列），降雨量为0的不下雨情况标记为标签0，降雨量不为0的下雨情况标记为标签1，处理后发现不下雨的天数过多，柱状图可视化天数后如图1-1</p><p><img src="https://img-blog.csdnimg.cn/b15a5402a48947fa931a5571ba20127e.png" alt="图1-1  0为不下雨，1为下雨，纵轴为天数计数"><br>清楚地看到，降水发生时的样本数量远小于降水不发生的情况。因此，存在阶级失衡，于是采用smote方法对数据过采样，增多下雨天数来平衡不下雨和下雨的计数。<br>通过热力图检查缺失值发现，缺失值很多，如图1-2：<br><img src="https://img-blog.csdnimg.cn/2e9d4389e54345db945cf52998fc3945.png" alt="图 1-2  热力图"><br>根据热力图看出，白色的部分是缺失值，由此可知，PGTM和TAVG属性空值过多，应当删除，其余属性的空值使用缺失值处理。</p><p>在数据中，站点名和地区名相同，因此对实验的预测没有影响，可以删除此两列，此外，此次分析的气象数据不具有季节性，所以是否下雨与日期值无关，所以删除此列。<br>将缺失值标记为NA，再使用众数进行填补，最后删除重复值，对处理后的数据使用热力图进行检查：<br><img src="https://img-blog.csdnimg.cn/38918d16034f49dda2b8c89db6bc509c.png" alt="图 1-3  热力图"></p><h1 id="2-特征选择和数据规范化"><a href="#2-特征选择和数据规范化" class="headerlink" title="2 特征选择和数据规范化"></a>2 特征选择和数据规范化</h1><p>基本方法是使用卡方检验进行特征选择和使用 MinMaxScaler 对数据进行规范化。</p><h2 id="2-1-特征选择"><a href="#2-1-特征选择" class="headerlink" title="2.1 特征选择"></a>2.1 特征选择</h2><p>卡方检验介绍：<br>基本思想：根据样本数据推断总体分布与期望分布是否有显著性差异，或者推断两个分类变量是否相关或者独立。<br>一般可以设原假设为：察频数与期望频数没有差异，或者两个变量相互独立不相关。<br>实际应用中，我们先假设原假设成立，计算出卡方值，卡方表示观察值与理论值间的偏离程度。</p><p>通过卡方检验进行特征选择，其中p-value值依据不同特征进行可视化：<br><img src="https://img-blog.csdnimg.cn/1309a8d811f643bf8be3345cfef3f2ce.png" alt="图 2-1  p-value值可视化"></p><p>由于WT02具有高p_value值(显著&gt;0.05)，因此表示此变量与PRCP无关，可以不用考虑用于模型训练，并删除特征’WT02’。</p><h2 id="2-2-归一化"><a href="#2-2-归一化" class="headerlink" title="2.2 归一化"></a>2.2 归一化</h2><p>归一化是指将数据集中的要素设置比例。此实验中随机划分x和y的训练集和测试集，对训练集里面样本数量较少的类别（PRCP=1）进行过采样，合成新的样本来缓解类不平衡。并且将数据映射到[0~1]的区间。</p><h1 id="3-不同模型的实现"><a href="#3-不同模型的实现" class="headerlink" title="3 不同模型的实现"></a>3 不同模型的实现</h1><h2 id="3-1-逻辑回归"><a href="#3-1-逻辑回归" class="headerlink" title="3.1 逻辑回归"></a>3.1 逻辑回归</h2><h3 id="3-1-1-原理"><a href="#3-1-1-原理" class="headerlink" title="3.1.1 原理"></a>3.1.1 原理</h3><p>对率回归属于监督学习。在对率回归分类器中，先输入样本和对应的标签，对率回归就是根据样本的特征值，把样本映射为 区间中的一个值（以下称这个值为回归值），在根据回归值的大小进行分类。本次二分类任务是把回归值在 区间中的样本归为标签为0的类，回归值在 中的样本归为标签为1的类。<br>下面给出具体的数学原理解释：<br>假设一组样本具有n维的属性，且属性值 与回归值之间满足线性关系：<br><img src="https://img-blog.csdnimg.cn/34debef3003042848cb49d6edc59c7b7.png"><br><img src="https://img-blog.csdnimg.cn/aeefe07da04349608fd563be423bc587.png" alt="word复制粘贴没公式了~"><br>这就是常见的Logistic模型表达式，X是自变量，p是因变量的函数图像如下：</p><p><img src="https://img-blog.csdnimg.cn/4a1185d9c9eb43589158d16b51ea6a73.png" alt="图 3-1"><br>可见，在二分类任务中，当对每一个输入特征 都给定一个权值 ，对特征值进行加权，再通过logistic模型(1-1)得到<br>样本属于1类别的概率：<br><img src="https://img-blog.csdnimg.cn/004bf18e22414b8a9b7237c6cdd5d7a1.png"></p><h3 id="3-1-2-实验结果"><a href="#3-1-2-实验结果" class="headerlink" title="3.1.2 实验结果"></a>3.1.2 实验结果</h3><p>偏置值为51.8，惩罚值为12，ROC_AUC得分为0.97，两类错误矩阵及其可视化如下：<br><img src="https://img-blog.csdnimg.cn/8f37bccf5dad4732850e4d3547e4532e.png"><br><img src="https://img-blog.csdnimg.cn/00e1de1f15dc447189e0621c7b42d558.png"></p><h2 id="3-2-支持向量机"><a href="#3-2-支持向量机" class="headerlink" title="3.2 支持向量机"></a>3.2 支持向量机</h2><h3 id="3-2-1-原理"><a href="#3-2-1-原理" class="headerlink" title="3.2.1 原理"></a>3.2.1 原理</h3><p>支持向量机 (SVM)是一组用于分类、 回归和异常值检测的监督学习方法。<br>支持向量机的优点是：</p><ul><li>   在高维空间中有效。</li><li>   在维度数大于样本数的情况下仍然有效。</li><li>   在决策函数中使用训练点的子集（称为支持向量），因此它也具有内存效率。</li><li>   通用性：可以为决策函数指定不同的内核函数提供了通用内核，但也可以指定自定义内核。</li></ul><p>支持向量机的缺点包括：</p><ul><li>   如果特征数量远大于样本数量，在选择核函数时避免过度拟合，正则化项至关重要。</li><li>   SVM 不直接提供概率估计，这些是使用昂贵的五折交叉验证计算的（参见下面的分数和概率）。</li></ul><p>SVM学习的基本想法是求解能够正确划分训练数据集（下图中实心黑点与空心点）并且几何间隔最大的分离超平面。如下图所示， w·x+b=0即为分离超平面作为决策边界，对于线性可分的数据集来说，这样的超平面有无穷多个（即感知机），但是几何间隔最大的分离超平面却是唯一的。<br><img src="https://img-blog.csdnimg.cn/185ac387b50d43379a9bdcd73807fb3a.png" alt="图3-3 SVM可视化解释"><br>在几何中，超平面是一个空间的子空间，它是维度比所在空间小一维的空间。 如果数据空间本身是三维的，则其超平面是二维平面，而如果数据空间本身是二维的，则其超平面是一维的直线。在二分类问题中，如果一个超平面能够将数据划分为两个集合，其中每个集合中包含单独的一个类别，我们就说这个超平面是数据的“决策边界“。<br>SVM目标是”找出边际最大的决策边界”，听起来是一个十分熟悉的表达，这是一个最优化问题，而最优化问题往往和损失函数联系在一起。和逻辑回归中的过程一样，SVM也是通过最小化损失函数来求解一个用于后续模型使用的重要信息：决策边界。<br>这里梳理一下这整个过程：<br><img src="https://img-blog.csdnimg.cn/3309f69df7974fae97d5a521fe0c2882.png"></p><h3 id="3-2-2-实验结果"><a href="#3-2-2-实验结果" class="headerlink" title="3.2.2 实验结果"></a>3.2.2 实验结果</h3><p>支持向量机最优参数：惩罚系数C=100，选择kernel=rbf，gamma=1<br>ROC_AUC得分为0.95<br>两类错误矩阵及其可视化如下：<br><img src="https://img-blog.csdnimg.cn/9d8ba90c358148018056fce138898cbb.png"><br><img src="https://img-blog.csdnimg.cn/adbafaf756e949a7b08068d0114dc2f7.png"></p><h2 id="3-3-决策树分类"><a href="#3-3-决策树分类" class="headerlink" title="3.3 决策树分类"></a>3.3 决策树分类</h2><h3 id="3-3-1-原理"><a href="#3-3-1-原理" class="headerlink" title="3.3.1 原理"></a>3.3.1 原理</h3><p>决策树(Decision Tree)是在已知各种情况发生概率的基础上，通过构建决策树来 进行分析的一种方式，是一种直观应用概率分析的一种图解法；决策树是一种预 测模型，代表的是对象属性与对象值之间的映射关系；决策树是一种树形结构， 其中每个内部节点表示一个属性的测试，每个分支表示一个测试输出，每个叶节 点代表一种类别；决策树是一种非常常用的有监督的分类算法。<br>决策树的决策过程就是从根节点开始，测试待分类项中对应的特征属性，并按照 其值选择输出分支，直到叶子节点，将叶子节点的存放的类别作为决策结果。<br>决策树分为两大类：分类树和回归树，前者用于分类标签值，后者用于预测连续值，常用算法有ID3、C4.5、CART等<br>构建步骤如下：</p><ul><li>   将所有的特征看成一个一个的节点；</li><li>   遍历每个特征的每一种分割方式，找到最好的分割点；将数据划分为不同的子节点，eg： N1、N2…； 计算之后所有子节点的’纯度’信息；</li><li>   对第二步产生的分割，选择出最优的特征以及最优的划分方式；得出最终的子节点: N1、N2…Nm</li><li>   对子节点N1、N2…Nm分别继续执行2-3步，直到每个最终的子节点都足够’纯’。</li></ul><p>决策树特征属性类型</p><ul><li>   属性是离散值，而且不要求生成的是二叉决策树，此时一个属性就是一个分支</li><li>   属性是离散值，而且要求生成的是二叉决策树，此时使用属性划分的子集进行测试，按照 “属于此子集”和“不属于此子集”分成两个分支</li><li>   属性是连续值，可以确定一个值作为分裂点split_point，按照&gt;split_point和 &lt;=split_point生成两个分支<h3 id="3-3-2-实验结果"><a href="#3-3-2-实验结果" class="headerlink" title="3.3.2 实验结果"></a>3.3.2 实验结果</h3>两类错误矩阵及其可视化如下：ROC_AUC=0.81<br><img src="https://img-blog.csdnimg.cn/75de8e18c0d3499da2fb5a7adb72885a.png"><br><img src="https://img-blog.csdnimg.cn/c761115217af4234b556ed6103508a4b.png"></li></ul><h2 id="3-4-随机森林"><a href="#3-4-随机森林" class="headerlink" title="3.4 随机森林"></a>3.4 随机森林</h2><h3 id="3-4-1-原理"><a href="#3-4-1-原理" class="headerlink" title="3.4.1 原理"></a>3.4.1 原理</h3><p>随机森林算法是由Breiman于2001年提出的一种基于Bagging重复采样技术，将多棵决策树进行组合的方法。该方法由随机向量θ构成一个组合模型：{h(X,θi),i=1,…,k}，θ服从独立同分布，X为自变量，k为决策树的数量。一般按照8:2的比例将原始数据集分为训练集和测试集，在训练集中建立随机森林模型，对特征变量重要性进行分析，在测试集中对模型评估效果进行检验。<br>随机森林模型对于数据的容忍度较强，并且可以很好地处理存在异常值和缺失值的数据。在对特征变量进行重要性程度分析时，区别于线性回归模型，随机森林算法具有分类速度快、抗噪音能力强、不会出现过度拟合、不需对函数形式进行事先假定等优点。模型会选择一个噪声随机加入特征变量中，并观察结果是否会出现差异，通过比较方差大小来判断是否存在差异，并确定该变量的重要性程度。<br>随机森林包含分类和回归两种技术，本文研究的保值率影响因素问题属于回归预测问题。回归的基本思路是：<br>(1）在n个原始样本数据基础上，应用bootstrap有放回地随机抽取K个自助样本集，并以此构建K棵回归树，每次抽样时未被抽到的样本又组成K个袋外数据，组成随机森林的测试样本；<br>(2）假设原始数据变量个数为N，在每棵回归树的每个节点处随机抽取mtry个变量作为备选分支变量，然后根据最优分支原则选取最优分支数。同时由于树可以最大化地生长，因此无需采取剪枝操作；</p><h3 id="3-4-2-实验结果"><a href="#3-4-2-实验结果" class="headerlink" title="3.4.2 实验结果"></a>3.4.2 实验结果</h3><p>准确率为95.62%，两类错误矩阵及其可视化如下：<br><img src="https://img-blog.csdnimg.cn/0f130e60235b429c80bc5c34bad7885d.png"><br>AUC值为0.95427，结果可视化如下：</p><p><img src="https://img-blog.csdnimg.cn/fad6f11b67a1412bb9d5504fdee69c5e.png"></p><h1 id="4-模型比较"><a href="#4-模型比较" class="headerlink" title="4 模型比较"></a>4 模型比较</h1><p>模型的MLA Train Accuracy、MLA Test Accuracy、MLA Precission、MLA Recall、MLA AUC比较如下表：<br><img src="https://img-blog.csdnimg.cn/9f7386a1ddaf4778993ce5e26f3bde35.png"></p><h1 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h1><p>天气数据最常见的问题是数据的缺失和异常，所以在数据的处理上要采用合适的方法。从预测结果来看，LR测试集极低的准确度可以看出天气特征随是否降雨呈非线性关系。并且从社会意义上来看，降雨预测的高准确率可以对城市的管理及居民的生活产生极大的效益。传统的天气预报方法已经发展的很完善，在短时间内很难有质的飞跃，数值预报技术是气象预报工作中重要的预报方式，但该技术的运行速度和预报准确率都有待提高，且还存在着一些弱点和问题需要解决。近年来，机器学习方法在很多领域中得到广泛使用，且在诸多方面取得了突破性的进展，但是有些理论和方法不够完善，需要进一步探索出更有实效性的机器学习方法来提高天气预报能力。这些机器学习方法也被应用于临近预报中。<br>由于不同的机器学习方法的构建方式不同，运算机理也不同，临近预报结果的好坏很大程度上依赖于机器学习方法本身及初始参数的设定，这些都增加使用不同机器学习方法临近预报时的不确定性。目前本文的研究仅针对是否降雨使用不同的机器学习方法进行临近降雨预报及不同预报方法之间的预报效果比较，还有更多的问题需要研究和探索。<br>机器学习方法还处于不断发展的阶段，许多方法还未被挖掘使用，有些方法的理论也还不够完善。机器学习方法训练模型时各内部各参数的最优配置也因训练数据集的不同而发生变化，另外训练数据集的分布情况及数量等也影响机器学习方法临近预报的效果。如何提高临近预报的准确率、预报的质量，探究有效的适应复杂气象数据特点的预报方法都是今后还需要深入研究的问题。</p><h1 id="参考文献（References）"><a href="#参考文献（References）" class="headerlink" title="参考文献（References）"></a>参考文献（References）</h1><p>[1]陈明轩,俞小鼎,等.对流天气临近预报技术的发展与研究进展[J.应用气象学报,200415(6):754-766<br>[2]Eilts M D,Johnson J T,et al.Severe warning decision support system[J].18th Conf on severe local storms,Amer Meteor Soc,San Fransisco,CA,1996:536-540AA.<br>[3]Dixon M.TITAN:Thunderstorm identification,tracking,analysis,and nowcasting aradar-based methodolo-gy[J].Atoms Oceanic Technol,1993,8:467-476.<br>[4]Golding B W.Nimrod:A system for generating automated very short range forecasts [J]Meteor Appl,1998,5:1-16.<br>[5]Wilson J W,Ebert EE,Saxen T R,et al.Sydney 2000 forecast demonstration project:convective storm nowcast-ing[J].Weather and Forecasting,2004,19:131-150.<br>[6]Pierce C E,Collier C G,et al.GANDOLF:a system for generating automated now casts of convective precipita-tion[J].Meteor Appl,2000,7:341-360.<br>[7]陈云浩,史培军,李晓兵.不同热力背景对城市降雨(暴雨)的影响()一基于人工神经网络的集成预报模型[J.自然灾害学报,2001,10(3):26-31<br>[8]熊聪聪,王静,宋鹏,等.遗传算法在多模式集成天气预报中的应用[.天津科技大学学报,2008,23(4):80-84.<br>[9]吴清佳,张庆平,万健.遗传神经网络的智能天气预报系统[J.计算机工程,2005,31(14):176-177<br>[10]吴建生,金龙,汪灵枝.遗传算法进化设计BP神经网络气象预报建模研究[).热带气象学报,2006,22(4):411-416.<br>[11]陈永义,俞小鼎,等.处理非线性分类和回归问题的一种新方法(1)一支持向量机方法简[J.应用气象学报,2004,15(3):345-354<br>[12]冯汉中,陈永义.处理非线性分类和回归问题的一种新方法一支持向量机方法在天气预报中的应用[J).应用气象学报,2004,15(3):335-365.<br>[13]李智才,马文瑞.支持向量机在短期气候预测中的应用[J.气象,2016,32(5):58-60.<br>[14]熊秋芬,曾晓青.SVM方法在降水预报中的应用及改进[J.气象,2008,34(12):90-95.<br>[15]贺佳佳,陈劲松等.一种多时间尺度SVM局部短时临近降雨预测方法).气象,2017,43(4):402-412.</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络单图超分辨率的深度学习方法</title>
      <link href="/zjh/2022/07/17/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8D%95%E5%9B%BE%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/"/>
      <url>/zjh/2022/07/17/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8D%95%E5%9B%BE%E8%B6%85%E5%88%86%E8%BE%A8%E7%8E%87%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>我们提出了一种用于单图像超分辨率（SR）的深度学习方法。 我们的方法直接学习低或高分辨率图像之间的端到端映射。 映射被表示为深度卷积神经网络（CNN），其将低分辨率图像作为输入和输出高分辨率。我们进一步表明，还可以将传统的稀疏编码的SR方法视为深卷积网络。 但与传统方法不同，这些方法单独处理每个组件，我们的方法都会共同优化所有层。 我们的深层卷积神经网络具有轻量级结构，但展示了最先进的恢复质量，并实现了实际在线使用的快速速度。 我们探索不同的网络结构和参数设置，以实现性能和速度之间的权衡。 此外，我们将网络扩展到同时应对三种颜色通道，并显示出更好的整体重建质量。</p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>We propose a deep learning method for single image hyperresolution (SR). Our method directly learns end-to-end mapping between low- or high resolution images. The mapping is represented as a deep convolutional neural network (CNN), which uses low resolution images as input and output high resolution. We further show that<br>traditional sparsely encoded SR methods can also be regarded as deep convolutional networks. However, unlike traditional methods, these methods deal with each component separately, and our methods will jointly optimise all layers. Our deep convolutional neural network has a lightweight structure, but it shows the most advanced recovery quality and realises the fast speed of actual online use. We explore different network structures and parameter settings to realise the trade off between performance and speed. In addition, we have expanded the network to deal with three colour channels at the same time, and show a better overall reconstruction quality.</p><p>目录<br>摘要    2<br>1.前言及研究背景    4<br>1.1图像的超分辨率问题    4<br>1.2传统方法    4<br>1.3 本报告提出的方法    5<br>1.4 优越性    5<br>2.实验过程    5<br>2.1实验方法    5<br>使用深卷积网络进行图像的超级分辨率（SRCNN）：    5<br>2.2 SRCNN的结构特性：    6<br>2.3论证稀疏编码表示在RSCNN中的可行性    7<br>2.4损失函数    8<br>3.实验结果    8<br>3.1调整参数    8<br>3.2评价指标：    9<br>3.3对颜色通道的实验结果：    9<br>4.实验结论    11</p><h1 id="1-前言及研究背景"><a href="#1-前言及研究背景" class="headerlink" title="1.前言及研究背景"></a>1.前言及研究背景</h1><h2 id="1-1图像的超分辨率问题"><a href="#1-1图像的超分辨率问题" class="headerlink" title="1.1图像的超分辨率问题"></a>1.1图像的超分辨率问题</h2><p>图像分辨率指图像中存储的信息量，是每英寸图像内有多少个像素点，分辨率的单位为PPI(Pixels Per Inch)，通常叫做像素每英寸。一般情况下，图像分辨率越高，图像中包含的细节就越多，信息量也越大。图像分辨率分为空间分辨率和时间分辨率。通常，分辨率被表示成每一个方向上的像素数量，例如64*64的二维图像。但分辨率的高低其实并不等同于像素数量的多少，例如一个通过插值放大了5倍的图像并不表示它包含的细节增加了多少。图像超分辨率重建关注的是恢复图像中丢失的细节，即高频信息。 在大量的电子图像应用领域，人们经常期望得到高分辨率（简称HR）图像。但由于设备、传感器等原因，我们得到的图像往往是低分辨率图像（LR）。因此,将LR映射到HR的函数空间非常大,学习一个好的解是非常困难的。而且低分辨率图像往往缺失图像超分辨率最需要的高频信息和纹理特征,却包含大量的低频信息来阻碍超分辨率重建,导致图像超分辨率是一个极具挑战性的任务。近年来,深度学习方法在计算机视觉领域大放异彩,同时也给图像超分辨率提供了新的解决方案。【1】增加空间分辨率最直接的解决方法就是通过传感器制造技术减少像素尺寸（例如增加每单元面积的像素数量）；另外一个增加空间分辨率的方法是增加芯片的尺寸，从而增加图像的容量。因为很难提高大容量的偶合转换率，所以这种方法一般不认为是有效的，因此，引出了图像超分辨率技术。<br>针对深度卷积神经网络对特征信息利用不足的问题和基于像素损失的网络无法克服重建图像伪影和平滑的问题进行研究,对深度卷积神经网络的特定结构、网络模块、损失函数等进行分析,通过构建信息蒸馏和密集特征融合模块加强了网络内部信息的流动效率;引入改进的生成对抗网络来改善重建图像的伪影和过于平滑的问题。【2】<br>超分辨率问题本质是不适定的或者说欠定逆问题，也就是图像超分辨率的解是不唯一的。对于任何给定的低分辨率像素都存在多重解，所以对于这个问题通常用强先验信息约束解空间来缓解，为了学习强先验信息，主要有两种思路：<br>（1）利用同一图像的内部相似性；<br>（2）从外部低分辨率和高分辨率样例图片对中学习映射函数</p><h2 id="1-2传统方法"><a href="#1-2传统方法" class="headerlink" title="1.2传统方法"></a>1.2传统方法</h2><p>传统基于稀疏编码的超分辨率方法是基于外部实例方法的一种方法，该方法流程如下：<br>（1）从输入图片中密集地进行采样形成大量的重叠的patches，并且对这些patch进行预处理（例如减去均值、标准化）；<br>（2）用一个低分辨率的字典对patches进行编码；<br>（3）稀疏系数被传递到一个高分辨率字典中，用来重构高分辨率的patches；<br>（4）将重叠的patches进行聚合（平均权重）产生最终的输出；</p><h2 id="1-3-本报告提出的方法"><a href="#1-3-本报告提出的方法" class="headerlink" title="1.3 本报告提出的方法"></a>1.3 本报告提出的方法</h2><p>这篇课程设计报告的实验是基于2015年由何恺明博士、汤晓鸥教授等发表于TPAMI的关于图像超分辨率的一篇论文《Image Super-resolution Using Deep Convolutional Networks (SRCNN)》，同时也是世界上较早的将深度学习应用在图像超分辨率的工作【3】，文中提出了一种用于单图像超分辨率的三层卷积网络，即SRCNN来实现图像的超分辨率的深度学习方法，相较于传统的基于稀疏表示的字典学习方法，一定程度上提升了图像重建的质量。</p><h2 id="1-4-优越性"><a href="#1-4-优越性" class="headerlink" title="1.4 优越性"></a>1.4 优越性</h2><p>针对低分辨率图像在预处理时使用双三次插值导致图像丢失一些重要的高频纹理细节以及网络模型优化问题,文章提出了连分式插值结合卷积神经网络的超分辨率重建方法。在原有的轻量级基于卷积神经网络的超分辨率重建算法（super-resolution convolutional neural net work, SRCNN）网络模型基础上,首先采用Newton-Thiele型连分式插值函数将低分辨率图像插值到目标尺寸;然后利用3个卷积层进行图像特征提取、非线性映射、重建与优化;该文在网络收敛时利用Radam优化算法自适应地调整梯度,并且采用余弦衰减法逐渐降低学习率。实验结果表明,该网络模型能够在轻量级的卷积神经网络下获得更丰富的纹理细节和更清晰的图像边缘。 【4】<br>与稀疏编码表示的方法相比，SRCNN有诸多优点：<br>①SRCNN没有显式地学习用于modeling the patch space的dictionaries或manifolds，而是通过隐藏层隐式实现的。<br>②patch的提取和聚合也被表示为卷积层，因此也被包含在了优化过程中。<br>③完全是通过学习获得的，几乎没有预处理或后处理。<br>④结构简单而且准确率还比一些基于实例的先进方法的高；<br>⑤有合适的卷积核数和层数，即便使用CPU，也能有很快的速度；<br>⑥SRCNN是完全前馈的网络，在使用中不需要解决任何优化问题，因此要快于其他基于实例的方法；<br>⑦当数据集更大、更多样化或者模型更大、更深时，网络的恢复质量可以进一步提高；<br>⑧SRCNN可以同时处理彩色图像的三通道，提高了超分辨率性能</p><h1 id="2-实验过程"><a href="#2-实验过程" class="headerlink" title="2.实验过程"></a>2.实验过程</h1><h2 id="2-1实验方法"><a href="#2-1实验方法" class="headerlink" title="2.1实验方法"></a>2.1实验方法</h2><p>使用深卷积网络进行图像的超级分辨率（SRCNN）：<br>简单来讲，SRCNN的原理可以概括为：直接学习低/高分辨率图像之间的端到端映射。 这一映射被表示为深度卷积神经网络（CNN），其将低分辨率图像作为输入，经映射后输出高分辨率图形，达到了很好的效果，同时证明了传统基于稀疏编码的SR方法也可以看作是一个深度卷积网络。其区别在于，传统方法是分别处理每个组件，而SRCNN则是联合优化所有层。SRCNN网络问世后,它在图像超分辨重建的应用使得深度学习在图像处理领域得到扩展。2014年,深度学习模型SRCNN一经提出,为深度学习解决图像压缩领域的像素问题开创了新纪元。【5】</p><p><img src="https://img-blog.csdnimg.cn/d6f664b731e942f68e464da586d23829.png" alt="图1 论文中展示的三种方法效果比较"><br><img src="https://img-blog.csdnimg.cn/6d16c36c60a84707b52124b535d30fd4.png" alt="图2 用demo code复现进行图片测试SRCNN的超分辨率效果"></p><h2 id="2-2-SRCNN的结构特性："><a href="#2-2-SRCNN的结构特性：" class="headerlink" title="2.2 SRCNN的结构特性："></a>2.2 SRCNN的结构特性：</h2><p>SRCNN具有三层网络结构，在具有轻量结构的同时，还具有最先进的恢复质量，并实现了快速的在线使用，作者在论文中探索了不同的网络结构和参数设置，以实现性能和速度之间的权衡。从处理过程来看，SRCNN可以同时处理RGB三个颜色通道，从而表现出更好的整体重建质量。<br><img src="https://img-blog.csdnimg.cn/92c13c1bf2274db7a5759b18ccea5bf5.png" alt="图3 SRCNN的三层网络结构图解"></p><ul><li><p>第一卷积层：提取一组特征映射<img src="https://img-blog.csdnimg.cn/363154deb0e54a16b083f89aee64e2a7.png"><br>W1表示为滤波器，B1表示为偏差；</p></li><li><p>第二卷积层：映射这些特征非线性地映射到高分辨率表示<img src="https://img-blog.csdnimg.cn/8daf3bbc7de1444ab954b4b0148444dd.png"></p></li><li><p>第三卷积层：结合了空间邻域内的预测重建，以产生最终的高分辨率图像<img src="https://img-blog.csdnimg.cn/40545e99569d4c94aeaac35694a7ae64.png"><br>W3是一组线性滤波器</p></li></ul><h2 id="2-3论证稀疏编码表示在RSCNN中的可行性"><a href="#2-3论证稀疏编码表示在RSCNN中的可行性" class="headerlink" title="2.3论证稀疏编码表示在RSCNN中的可行性"></a>2.3论证稀疏编码表示在RSCNN中的可行性</h2><p><img src="https://img-blog.csdnimg.cn/9ae717db7900475b8e91774846c4bbea.png" alt="图4 基于稀疏编码的方法的例证在卷积神经网络的视图中"><br>①左半部分：可以看作是把f1×f1低分辨率的patch看成是从输入图片提取出来的，稀疏编码将patch投影到一个字典上，如果这个字典的大小为n1，那么相当于在输入图片上使用n1个大小f1×f1的卷积核进行卷积运算。<br>②中间部分：稀疏编码会迭代的处理n1维度的向量，从而得到一个n2维度的向量，一般来说n1、n2是相等的，这个时候稀疏编码求解程序起的作用就是一个大小为1×1的非线性映射运算符。<br>③右半部分：最后再对n2维度的向量投影到另一个字典空间目的是产生高分辨率的patch，重叠部分的patch会进行平均操作。</p><h2 id="2-4损失函数"><a href="#2-4损失函数" class="headerlink" title="2.4损失函数"></a>2.4损失函数</h2><p>SRCNN模型的参数有：W1, W2, W3, B1, B2, B3。给定一组高分辨率图片Xi以及对应低分辨率图片Yi，我们使用均方误差MSE（mean squared error）作为损失函数。设为：<img src="https://img-blog.csdnimg.cn/b0901c59b07c40368942b9b1faed0a91.png"><br>其中n是训练样本的数量。<br>损失函数使用随机梯度下降进行优化<br><img src="https://img-blog.csdnimg.cn/8a6539ed46284c5abeaa26324d103740.png"><br>其中的l∈{1，2，3}，i是层和迭代的索引，每层的卷积核权重都由均值为0标准差为0.001的高斯分布进行初始化，每层偏置都初始化为0，η是学习率，前两层的学习率为10^-4 ，最后一层的学习率为10^-5，尤其最后一层使用小的学习率对SRCNN的收敛性能影响较大。</p><p>可见，四层网络收敛的比三层的慢，但若有足够的训练时间，四层网络最终也能赶上三层的网络。论文中实验表明网络并不是越深越好，当使用越深的网络（例如四层或五层的网络），我们发现很难去设置一个合适的学习率来确保网络收敛，即使模型收敛了，也可能陷入一个不好的局部最小值，并且经过足够的训练时间，已学习的卷积核的多样性会变少。而且在图像分类领域，不适当的增加模型深度也会使得准确率的下降或退化。</p><h1 id="3-实验结果"><a href="#3-实验结果" class="headerlink" title="3.实验结果"></a>3.实验结果</h1><h2 id="3-1调整参数"><a href="#3-1调整参数" class="headerlink" title="3.1调整参数"></a>3.1调整参数</h2><p>为了平衡性能和速度，我们的方法选用了f1=9, f2=5, f3=5, n1=64, n2=32,并且在ImageNet上进行训练。并且对每个放大系数∈{2, 3, 4}，都分别训练了一个相应的网络。</p><p><img src="https://img-blog.csdnimg.cn/3ac54a07f1964bb1b5abc70a0ce54c30.png" alt="图5 SET5数据集上的PSNR，SSIM，IFC，NQM，WPSNR和MSSIM的平均结果"></p><h2 id="3-2评价指标："><a href="#3-2评价指标：" class="headerlink" title="3.2评价指标："></a>3.2评价指标：</h2><p>①PSNR（Peak Signal to Noise Ratio）峰值信噪比：PSNR是最普遍，最广泛使用的评鉴画质的客观量测法。但这个指标只是速度快，评价效果一般；<br>②SSIM（Structural SIMilarity）结构相似性：是一种衡量两幅图像相似度的指标，用均值作为亮度的估计，标准差作为对比度的估计，协方差作为结构相似程度的度量。<br>③IFC（information fidelity criterion）信息保真度准则：通过计算待评图像与参考图像之间的互信息来衡量待评图像的质量优劣。<br>④NQM（noise quality measure）噪声质量测量<br>⑤WPSNR(Weighted Peak Signal to Noise Ratio)加权峰值信噪比<br>⑥MSSSIM（Multi Scale Structural SIMilarity ）多尺度结构相似性</p><h2 id="3-3对颜色通道的实验结果："><a href="#3-3对颜色通道的实验结果：" class="headerlink" title="3.3对颜色通道的实验结果："></a>3.3对颜色通道的实验结果：</h2><p><img src="https://img-blog.csdnimg.cn/ee4d3708c9b3454ea5e9d8dda8dca498.png" alt="图6 SET5数据集上的不同通道的平均PSNR（DB）和培训策略"></p><h1 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h1><p>①Y only：基线方法，是一个单通道网络（c=1），只在亮度上进行了训练。对Cb、Cr通道采用双三次插值进行了扩展。<br>②YCbCr：在YCbCr空间的三个通道上进行训练<br>③Y pre-train ：使用Y通道的MSE作为损失来对网络进行预训练。然后利用各通道的MSE对参数进行微调<br>④CbCr pre-train：使用Cb,Cr通道的MSE作为损失来对网络进行预训练，然后对所有通道的参数进行微调<br>⑤RGB：在RGB空间的三个通道上进行训练<br><img src="https://img-blog.csdnimg.cn/cda8a283a8434982a6fb13bd856e56ad.png" alt="图7 具有不同图层的映射"><br><img src="https://img-blog.csdnimg.cn/b010c0acd4a448109a2503f49df64dd0.png"><br><img src="https://img-blog.csdnimg.cn/682183b46c8a4de7b3fbe4d5fe1efbdd.png"></p><h1 id="4-实验结论"><a href="#4-实验结论" class="headerlink" title="4.实验结论"></a>4.实验结论</h1><p>通过这篇论文，学习了SRCNN这种对于单图像进行超分辨率的深度学习方，通过公式演算，一步步探寻到了传统的基于稀疏编码的SR方法可以重构为一个深度卷积神经网络。我们表明，传统的基于稀疏编码的SR方法可以被重新表述为一个深度卷积神经网络。所提出的方法，即SRCNN，可以学习低分辨率和高分辨率图像之间的端到端映射，除了优化之外几乎没有额外的前/后处理。凭借轻量级的结构，SRCNN已经取得了比最先进的方法更出色的性能。我们猜想，通过探索更多的滤波器和不同的训练策略，可以进一步获得额外的性能。此外，所提出的结构具有简单和稳健的优点，可以应用于其他低层次的视觉问题，如图像去模糊化或同步SR+去噪。我们还可以研究一个网络来应对不同的放大系数。<br>SRCNN学习低分辨率和高分辨率图像之间的端到端映射，除了优化之外几乎没有额外的预处理/后处理，由于采用了轻型结构，SRCNN的性能优于目前基于实例的的方法。并进一步探索可以知道更多的卷积核和不同的训练策略，可以获得更好的性能。对于一些低质图片，可以有很大的发挥作用的空间，在人脸识别等领域大展身手。</p><h1 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h1><p>[1]张俊韬. 基于注意力卷积神经网络的图像超分辨率研究[D].哈尔滨工程大学,2021.DOI:10.27060/d.cnki.ghbcu.2021.001483.<br>[2]查体博. 基于深度卷积神经网络的列车检测图像超分辨方法研究[D].西南交通大学,2021.DOI:10.27414/d.cnki.gxnju.2021.002909.<br>[3]Chao Dong,Chen Change Loy,Kaiming He,Xiaoou Tang. Image Super-Resolution Using Deep Convolutional Networks.[J]. CoRR,2015,abs/1501.00092.<br>[4]杨悦,谢辛,何蕾,胡敏.连分式插值结合卷积神经网络的超分辨率重建[J].合肥工业大学学报(自然科学版),2021,44(08):1146-1152.<br>[5]曾诗悦.基于SRCNN模型的图像压缩方法研究[J].信息技术与信息化,2020(09):98-100.</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>疫情港口挂靠数ARIMA时序分析</title>
      <link href="/zjh/2022/07/17/%E7%96%AB%E6%83%85%E6%B8%AF%E5%8F%A3%E6%8C%82%E9%9D%A0%E6%95%B0ARIMA%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/"/>
      <url>/zjh/2022/07/17/%E7%96%AB%E6%83%85%E6%B8%AF%E5%8F%A3%E6%8C%82%E9%9D%A0%E6%95%B0ARIMA%E6%97%B6%E5%BA%8F%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="摘-要"><a href="#摘-要" class="headerlink" title="摘  要"></a>摘  要</h1><ul><li> 新冠肺炎疫情自 2020 年年初爆发以来，传播速度快、传染范围广，截止至 2021 年 3 月底已经造成了 1 亿 2 千多万人感染。对全球各行各业都带来了无法忽视的影响，同时无疑是给世界贸易经济一击重创。而海上运输作为全世界货物流通的最主要运输方式，新冠疫情对航运业的影响是非常明显的。</li><li> 全文研究的是新冠肺炎疫情对集装箱运输市场的影响。首先简述了新冠病毒在全球的扩散范围，简单讲述了 ARIMA 模型建模方法，再分析可能疫情对集装箱市场的影响因素，利用一阶差分得到平稳数据，白噪声检验验证是否是随机序列，利用 ACF 和 PACF 检验在置信区间中选择出合适的 p、 q 值，配合一阶差分的参数 1 进行建模， 建模之后使用 AIC 准则评估模型，残差检验白噪声，用模型预测测试集，最终分析，总结。 </li><li>*关键词**：新冠肺炎疫情；集装箱供需变化；ARIMA； </li></ul><ol><li>绪论……………………………………………………………………………………………………………………………………. 4</li><li>1 选题背景………………………………………………………………………………………………………………………… 4</li><li>2 国内外研究现状 …………………………………………………………………………………………………………….. 4</li><li>疫情对国际集装箱运输的影响波动………………………………………………………………………………. 5</li><li>ARIMA 模型概述………………………………………………………………………………………………………………. 6</li><li>建立 ARIMA 模型的步骤…………………………………………………………………………………………………. 7</li><li>1 时间序列的获取 …………………………………………………………………………………………………………….. 7</li><li>2 时间序列的预处理…………………………………………………………………………………………………………. 7</li><li>2.1 预处理………………………………………………………………………………………………………………………. 7</li><li>2.2 差分得到平稳数据………………………………………………………………………………………………….. 8</li><li>2.3 验证是否随机序列………………………………………………………………………………………………….. 8</li><li>3ACF 和 PACF 检验…………………………………………………………………………………………………………… 8</li><li>4AIC 准则 …………………………………………………………………………………………………………………………… 9</li><li>5 模型评估………………………………………………………………………………………………………………………..10</li><li>6 残差检验………………………………………………………………………………………………………………………..11</li><li>7 模型预测………………………………………………………………………………………………………………………..12</li><li>8 结果可视化…………………………………………………………………………………………………………………….13</li><li>9 结果分析………………………………………………………………………………………………………………………..13</li><li>结论与展望………………………………………………………………………………………………………………………15</li><li>参考文献…………………………………………………………………………………………………………………………..16</li></ol><h1 id="1-绪论"><a href="#1-绪论" class="headerlink" title="1. 绪论"></a>1. 绪论</h1><p>2020 年新年伊始，新冠疫情爆发，在这次冲击下,航运市场整体处于低迷状态，燃油价格、集装箱船队每周平均闲置运力受到明显影响，同时还加剧了集装箱港口的拥堵程度。一项由 11 条分航线指数组成，这些全球重要航线的集装箱运价指数组成了代表国际集装箱运输市场价格走势的重要指标之一——中国出口集装箱运价指数(Chinese Container FreightIndex,CCFI)，能够客观地反映集装箱市场状况。本文通过收集了 2020 年 1 月至 2021 年 3 月<br>的中国集装箱出口运价指数来研究疫情期间集装箱挂靠数的变化情况以及影响因素在航运企业角度，提出规避风险的有效措施。</p><h2 id="1-1选题背景"><a href="#1-1选题背景" class="headerlink" title="1.1选题背景"></a>1.1选题背景</h2><ul><li>航运是全球贸易的大动脉，是世界经济的“晴雨表”，具有成本低、覆盖面广、量大等优势。当中国航运能够在世界舞台上脱颖而出，影响着、并改变着世界。航运需求作为一种派生需求，它是随着全球贸易的发展和货物的海上流通应运而生的，为国际的贸易提供运输服务，因此航运业的发展与全球经济贸易的发展息息相关。集装箱市场作为国际航运市场的重要组成部分，由于货物种类繁多，同时还受到经济发展程度不同、世界政治环境、经济环境和产业结构等等众多因素的影响。</li><li>集装箱运输船的供给是缺乏弹性的。中国出口集装箱运价指数能够直接衡量运力需求和集装箱船供给之间的关系，当运力需求上升时，航运企业此时就会选择采购建造新船，而造船耗时长，成本高，若船造好后赶上运力需求下降，则造好的船只能搁置，一条船的搁置成本很高，然而航运公司并不能通过短期搁置部分船只来暂时减少运力来紧密跟踪市场需求。基于以上原因，在航运业中，当运输能力的供求达到平衡状态时，即使需求有一个细微的正<br>边际增长，也会迅速推高货运指数;相反，一个微小的负边际增量会导致这些指数的暴跌。供给端收缩促进了当前集运行业的复苏，复苏的力度取决于需求，如果需求保持稳定，复苏将是相对温和的；如果需求增长超出预期，将带来强劲的复苏。其中，中国的出口是影响海洋运输需求的重要因素，而中国的进口是影响干散货需求的重要因素。 2020 年底，中国进出口数据超过预期。如果这一趋势能够保持下去，将为航运业的复苏形成强有力的支撑。</li></ul><h2 id="1-2国内外研究现状"><a href="#1-2国内外研究现状" class="headerlink" title="1.2国内外研究现状"></a>1.2国内外研究现状</h2><ul><li>新冠疫情爆发以来，国内外集装箱运输市场纷纷展现出集装箱空箱运输困难、难以周转、多数船舶停航延期、港口拥堵严重、人员调度困难以及运费持续上涨等负面因素，导致全球航运供应链滞塞。通过分析新冠疫情在全球的扩散范围内对集装箱市场的供需两方面影响因素，能够得出燃油价格、集装箱船队每周平均闲置运力和集装箱港口拥堵程度对中国出口集装箱运价指数影响明显，而随着疫情得到有效控制，出口集装箱运价指数在 2020 年底激增并持续较长时间。</li><li>航运作为全球贸易流通的命脉，不少专业机构和专家对疫情下的航运变化展开过研究：2020 年底，海事咨询机构——Sea Intelligence，公布了全球海运运输量的相关数据并加以分析，得出结论，在 2020 年上半年，由于疫情影响，全球海运两总体下降了 25%， 2020 年全年整体下降 10%。截止至 2020 年 9 月底，全球主要挂靠港的集装箱运转量多数显示负增长，但是，在中国，以宁波舟山港为主的集装箱吞吐量却保持不同程度的增长，反映出了中国国内市场的经济恢复较好。</li><li>2020 年交通运输部科学研究院刘宏甲院士、周健院士于交通统计信息与经济运行分析技术实验室发表了《新冠肺炎疫情对水路运价的影响研究及展望》，报告中将此次疫情和SARS 病毒对比，发现新冠比 SARS 对我国航运业产生的影响更严重，表现在了全国居家隔离，小型企业停产甚至倒闭，使的原材料和产品贸易量减少；与此同时，人员返岗困难，导致港口操作人员紧缺。船舶的停泊时间增加。中远海运散货运输有限公司的王婧妍发表了《浅析新冠疫情的世界性爆发对航运业的影响》，该文章指出疫情带来的影响主要展现在了船舶进出港口、航运企业业务运营以及人力资源方面，航运企业还需要在未来的日子里研究初疫情影响运价的机制，采取有力措施来规避运价大幅度波动的影响。</li><li>目前相关数据研究表明， 2020 年中国各港口吞吐量在 1 至 3 月份明显下滑，由于 4 月起国内疫情得到较好的控制，直到 2020 年末，疫情在国外爆发，而中国得到了很好的控制，我国开始大量的出口医疗设施设备，国外船舶选择中国中转，从而促使了中国的出口市场发展向好。</li></ul><h1 id="2-疫情对国际集装箱运输影响波动"><a href="#2-疫情对国际集装箱运输影响波动" class="headerlink" title="2.疫情对国际集装箱运输影响波动"></a>2.疫情对国际集装箱运输影响波动</h1><ul><li>中国出口集装箱数主要收到直接间接两个方面因素的影响，直接影响因素有：供需变化、运输成本变化以及国家调控。而间接影响因素主要有：市场结构、全球经济、国际政治变化以及自然灾害等突发之间因素。而 2020 年突发的新型冠状肺炎疫情正是属于突发自然灾害因素，同时，也在不同程度上波及到了除此之外的其他因素。</li><li>需求首先下降，然后上升，而价格迅速上涨。到 2020 年，全球集装箱运输市场的需求量将先减少后增加。</li></ul><ul><li><p>中国出口集装箱运输市场在第一季度呈下降趋势，在第二季度末稳步反弹，并在第三和第四季度加速上升趋势。自 6 月以来，对集装箱运输的需求迅速恢复，船舶和集装箱在某些路线上开始紧缺，市场逐渐接近卖方市场。即使在第四季度，西方国家对运输的需求仍然很高，国外的流行病导致港口拥挤，收集和交付系统不足，这降低了船舶的运营效率，使返回空集装箱的工作变得困难。 2020 年我国出口集装箱运输指数平均水平为 984.42 点，比上年增长 19.5％。</p></li><li><p>由于疫情爆发时许多国家施加的限制和严格控制，国际贸易下降，对国际运输的需求也下降。因此，在冠状肺炎的全球大规模流行的情况下，航运企业将需要对当前环境进行透彻的分析，积极应对并向前迈进。疫情直接导致韩滚需求先降后升，而整个物流供应链的成本增加了，伴随着增加了额外的运输和劳动力成本，加上由于大量集装箱船舶长期闲置搁浅，短期内国内外集装箱船舶的运力过剩，还是给航运企业经营带来较大困难。</p></li><li><p>供应链的成本增加了。由于新冠疫情，集装箱运输链上的压力越来越大，面临着提供门到门运输的多式联运和综合物流服务提供商。运价成本费用的增加主要反映在以下因素上：其中之一是货运量的增加。其次，由于路线的缩短，运输承运人的成本将增加。此外，根据国际海事组织的有关规定，今年船运公司将开始平均每个集装箱低硫燃料附加费 100-200 美元。第三是预防传染病的材料成本。第四，由于集装箱运输不畅造成的滞期成本。 第五，人工成本增加。第六，集装箱储存成本集装箱航线正在缓慢恢复。自疫情爆发以来，春节期间的贸易量有所下降，航运公司也计划停航。受疫情影响，取消航班较去年同期明显增加。目前，国内沿江航线运力已陆续恢复，与往年相比，春节淡季捉襟见肘，迟迟未能恢复出货。虽然航道正在恢复，但船舶的装货率已经下降。大量集装箱船长期搁浅。这一传染病增加了额外的运输和劳动力成本。短期内，国内外集装箱船舶运力过剩，给航运企业经营带来较大困难。</p></li><li><p>第一季度，中国出口集装箱运输市场行情总体呈下行态势，第二季度末企稳回升，第三、四季度加速上行。自 6 月份开始，集装箱运输需求快速恢复，部分航线开始出现缺船缺箱局面，市场逐渐转向卖方市场。进入第四季度，多数航线现货市场运价进入直线上升阶段。新冠肺炎影响的知识中国经济发展的节奏，中国经济具有实力大、动力足、强力强，发展空间大的特征。疫情发生以来，中国人的消费方式加快了转变，而居家办公也突破了传统的办公方式，客观地来讲，疫情推动航运企业数字化转型，加快了数字化创新的进程。在国际贸易中货物贸易的占比比起服务贸易明显高出许多，此次疫情市场上的生产要素向高端服务转移，大力发展服务贸易的契机。</p></li></ul><h1 id="3-ARIMA模型概述"><a href="#3-ARIMA模型概述" class="headerlink" title="3.ARIMA模型概述"></a>3.ARIMA模型概述</h1><ul><li><p>ARIMA 模型（英语： Autoregressive Integrated Moving Average model），差分整合移动平均自回归模型，又称整合移动平均自回归模型（移动也可称作滑动），是时间序列预测分析方法之一。 ARIMA(p， d， q)中， AR 是“自回归”， p 为自回归项数； MA 为“滑动平均”，q 为滑动平均项数， d 为使之成为平稳序列所做的差分次数（阶数）。 “差分”一词虽未出现在ARIMA 的英文名称中，却是关键步骤。</p></li><li><p>对时间序列数据进行分析和预测比较完善和精确的算法是博克思-詹金斯<br>(Box-Jenkins)方法，其常用模型包括：自回归模型（AR 模型）、滑动平均模型（MA 模型）、（自回归-滑动平均混合模型） ARMA 模型、（差分整合移动平均自回归模型） ARIMA 模型。ARIMA(p， d， q)模型是 ARMA(p， q)模型的扩展。 ARIMA(p， d， q)模型可以表示为：<img src="https://img-blog.csdnimg.cn/e2059db4feae44d3bf1328329751966a.png"></p></li></ul><h1 id="4-建立ARIMA模型的步骤"><a href="#4-建立ARIMA模型的步骤" class="headerlink" title="4.建立ARIMA模型的步骤"></a>4.建立ARIMA模型的步骤</h1><h2 id="4-1时间序列的预处理"><a href="#4-1时间序列的预处理" class="headerlink" title="4.1时间序列的预处理"></a>4.1时间序列的预处理</h2><ul><li>时间序列的预处理包括两个方面的检验，平稳性检验和白噪声检验。能够适用 ARMA 模型进行分析预测的时间序列必须满足的条件是<strong>平稳非白噪声序列</strong>。</li><li>差分的次数就是模型 ARIMA(p,d,q)的阶数，理论上说，差分的次数越多，对时序信息的非平稳确定性信息的提取越充分，但是从理论上说，差分的次数并非越多越好，<strong>每一次差分运算，都会造成信息的损失</strong>，所以应当避免过分的差分，一般在应用中，差分的阶数不超过 2</li></ul><h3 id="4-1-1预处理"><a href="#4-1-1预处理" class="headerlink" title="4.1.1预处理"></a>4.1.1预处理</h3><pre><code>#导入 python 相关模块import warnings warnings.filterwarnings(&quot;ignore&quot;)import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport statsmodels.api as smimport statsmodels.tsa.stattools as ts from statsmodels.graphics.apiimport qqplot from sklearnimport preprocessing from sklearn.metricsimport mean_squared_error#使用 read_csv 方法读取数据集中，列名为‘value’的数据序列train=pd.read_csv(&#39;C:/Users/user/Desktop/ 港 口 靠 挂 数 .csv&#39;, header=0,parse_dates=[0], index_col=0, squeeze=True)#做 adf 单位根检验result = ts.adfuller(train)print(result)</code></pre><p>(-1.6084751426812451, 0.47933490167167303, 18, 426, {‘1%’: -3.4457939940402107,’5%’: -2.8683485906158963, ‘10%’: -2.570396746236417}, 3355.7564277245247)</p><p><strong>结果分析</strong>： adf 单位根检验结果可知， t 统计量不显著大于 1%， 5%， 10%，且 p_value 值显著大于 0.05，因此此时间序列不是平稳序列，需要做一阶差分处理。</p><h3 id="4-1-2差分得到平稳数据"><a href="#4-1-2差分得到平稳数据" class="headerlink" title="4.1.2差分得到平稳数据"></a>4.1.2差分得到平稳数据</h3><pre><code>#因为原数据不平稳，因此做一阶差分train_diff1=train.diff(1).dropna()result = ts.adfuller(train_diff1)print(result) #得出一阶差分后，发现平稳</code></pre><p>(-10.251689978153886, 4.468421753473792e-18, 15, 427, {‘1%’: -<br>3.445757604526768, ‘5%’: -2.8683325885102855, ‘10%’: -2.5703882165206853},3361.719726005615)</p><p><strong>结果分析</strong>：数据经过一阶差分之后，再经过 adf 单位根检验结果可知， t 统计量显著小于 1%，5%， 10%，且 p_value 值显著小于 0.05，因此差分后的数据是平稳的，即可进行下一步操作。</p><h3 id="4-1-3验证是否随机序列"><a href="#4-1-3验证是否随机序列" class="headerlink" title="4.1.3验证是否随机序列"></a>4.1.3验证是否随机序列</h3><pre><code>#白噪声检验 lb_pavlue 和 bp_pvalue 值显著小于 0.05，说明不是纯随机序列from statsmodels.stats.diagnostic import acorr_ljungboxacorr_ljungbox(train_diff1, lags=1,boxpierce=True)</code></pre><p><img src="https://img-blog.csdnimg.cn/18cd0ab2e9004651a2e4cf1480be700e.png"><br><strong>结果分析</strong>：由白噪声检验可知， p_value 和 lb_value 值显著小于 0.05，因此此序列<strong>不是纯随机序列，因此此序列有研究的意义</strong>，可进行下一步操作。</p><h2 id="4-2ACF检验和PACF检验"><a href="#4-2ACF检验和PACF检验" class="headerlink" title="4.2ACF检验和PACF检验"></a>4.2ACF检验和PACF检验</h2><ul><li>ACF 是一个完整的自相关函数，可为我们提供具有滞后值的任何序列的自相关值。简单来说，它描述了该序列的当前值与其过去的值之间的相关程度。时间序列可以包含趋势，季节性，周期性和残差等成分。 ACF 在寻找相关性时会考虑所有这些成分。<br>直观上来说， ACF 描述了一个观测值和另一个观测值之间的自相关，包括直接和间接的相关性信息</li><li>PACF 是部分自相关函数或者偏自相关函数。基本上，它不是找到像 ACF 这样的滞后与当前的相关性，而是找到残差（在去除了之前的滞后已经解释的影响之后仍然存在）与下一个滞后值的相关性。因此，如果残差中有任何可以由下一个滞后建模的隐藏信息，我们可能会获得良好的相关性，并且在建模时我们会将下一个滞后作为特征。请记住，在建模时，我们不想保留太多相互关联的特征，因为这会产生多重共线性问题。因此，我们只需要保留相关功能。</li></ul><p>⚫ 采用自相关函数（ACF）、偏自相关函数（PACF） 来判别 ARMA(p,q)模型的系数和阶数。<br>⚫ 自相关函数(ACF)描述时间序列观测值与其过去的观测值之间的线性相关性。<br>⚫ 偏自相关函数(PACF)描述在给定中间观测值的条件下时间序列观测值与其过去的观测值之间的线性相关性</p><pre><code>#adf 检验,看图得出移动平均模型阶数 q 值为 2 或 3fig = plt.figure(figsize=(12, 8))ax1 = fig.add_subplot(211)fig = sm.graphics.tsa.plot_acf(train_diff1, lags=16, ax=ax1)ax1.xaxis.set_ticks_position(&#39;bottom&#39;)fig.tight_layout()#pacf 检验，看图得出自回归模型阶数 p 值为 5 或 6ax2 = fig.add_subplot(212)fig = sm.graphics.tsa.plot_pacf(train_diff1, lags=16, ax=ax2)ax2.xaxis.set_ticks_position(&#39;bottom&#39;) fig.tight_layout() plt.show()</code></pre><p><img src="https://img-blog.csdnimg.cn/6cb324c779504719bfd0cc94748381ba.png"><br><img src="https://img-blog.csdnimg.cn/d2759f31845d4d2ba70248ad6cf498ba.png"><br><strong>结果分析</strong>：由 pacf 图像可知， p 值为 5 或 6， acf 图像可知 q 值为 2 或 3，因此 arima 模型的备选参数有四组，分别是（5， 1， 2）、（5， 1， 3）、（6， 1， 2）、（6， 1， 3）四组，接下来使用模型评估方法，选取最下 mse 值得参数进行建模。</p><h2 id="4-3AIC准则"><a href="#4-3AIC准则" class="headerlink" title="4.3AIC准则"></a>4.3AIC准则</h2><p>AIC 信息准则即 Akaike information criterion， 是<strong>衡量统计模型拟合优良性</strong>(Goodness oft)的一种标准，由于它为日本统计学家杰池弘欢创立和发展的，因此又称赤池信息量准则。它建立在熵的概念基础上，可以权衡所估计模型的复杂度和此模型拟合数据的优良性。</p><pre><code>    #定义 evaluate_arima_model（），输入 X 为历史数据， arima_order 为备选的（p， q）对    def evaluate_arima_model(X, arima_order):# 选取数据的前 2/3 作为训练集，后 1/3 作为测试集train_size = int(len(X) * 0.66)train, test = X[0:train_size], X[train_size:]history = [x for x in train]#通过训练集输出 predictionpredictions = list()for t in range(len(test)):model = sm.tsa.arima.ARIMA(history, order=arima_order)model_fit = model.fit()yhat = model_fit.forecast()predictions.append(yhat)history.append(test[t])# 将测试集与 prediction 做误差分析，输出误差值error = mean_squared_error(test, predictions)return error</code></pre><p>输出结果： 用 AIC 方法得到最优的 p 值是 8,q 值是 8</p><h2 id="4-4模型评估"><a href="#4-4模型评估" class="headerlink" title="4.4模型评估"></a>4.4模型评估</h2><pre><code>#将输入数据标准化，便于模型检验X=preprocessing.scale(train_diff1)#对三个（p， 1， q）做模型评估，输出误差值 mse，选最小 mse 的参数mse = evaluate_arima_model(X,(5,1,2))print(&quot;p=5,d=1,q=2 mse= %.3f&quot; %mse)mse = evaluate_arima_model(X,(6,1,2))print(&quot;p=6,d=1,q=2 mse= %.3f&quot; %mse)mse = evaluate_arima_model(X,(5,1,3))print(&quot;p=5,d=1,q=3 mse= %.3f&quot; %mse)mse = evaluate_arima_model(X,(6,1,3))print(&quot;p=6,d=1,q=3 mse= %.3f&quot; %mse)mse = evaluate_arima_model(X,(8,1,8))print(&quot;p=8,d=1,q=8 mse= %.3f&quot; %mse)</code></pre><p><img src="https://img-blog.csdnimg.cn/1f584fac2aa74af9988d48fe747d2955.png"><br>结果分析：通过模型评估得到的五组参数选定值，计算出的 mse，选取得到最小 mse=0.533得（8， 1， 8）参数，选定为 arima 模型得 order 值。</p><h2 id="4-5残差检验"><a href="#4-5残差检验" class="headerlink" title="4.5残差检验"></a>4.5残差检验</h2><p>建立模型后，需要对残差序列进行检验。若残差序列为白噪声序列，则说明时间序列中的有用信息已经被提取完毕，剩下的全是随机扰动，是无法预测和使用的，即建模成功，可以进行下一步的预测。</p><pre><code>model=sm.tsa.arima.ARIMA(history,order=(8,1,8)).fit()#产生残差resid=model.resid#自相关图sm.graphics.tsa.plot_acf(resid,lags=15).show()#偏自相关图sm.graphics.tsa.plot_pacf(resid,lags=15).show()#qq 图qqplot(resid, line=&#39;q&#39;, fit=True).show()#LB 检验，说明残差序列是白噪声print(&#39;残差序列的白噪声检验结果为：&#39;,acorr_ljungbox(resid,lags=1,boxpierce=True))</code></pre><p>残差序列的白噪声检验结果为： lb_stat lb_pvalue bp_stat bp_pvalue<br>1 0.062923 0.801934 0.062499 0.802589</p><p><img src="https://img-blog.csdnimg.cn/680b3f6021cd46e9a346ea3e58e14407.png"><br><img src="https://img-blog.csdnimg.cn/019adfcce47e4f549469841c9b906588.png"><br><img src="https://img-blog.csdnimg.cn/cf8c1c5dff3b41ee9664b87099ed462e.png"><br>结果分析：通过残差序列的残差检验可知， p_value 和 lb_value 值都显著大于 0.05，因此表明，残差序列是纯随机序列，即残差序列没有其余信息可以提取，且残差序列符合线性正态分布，因此认为 arima 模型建模预测成功。</p><h2 id="4-6模型预测"><a href="#4-6模型预测" class="headerlink" title="4.6模型预测"></a>4.6模型预测</h2><pre><code>#标准化 train_useX = train_diff1.valuesX=preprocessing.scale(X)train1, test1 = X[0:50], X[51:101]history = [x for x in train1]predictions = list()#使用 ARIMA（8,1,8）进行模型预测for t in range(len(test1)):model = sm.tsa.arima.ARIMA(history, order=(8, 1, 8))model_fit = model.fit()output = model_fit.forecast()yhat = output[0]predictions.append(yhat)obs = test1[t]history.append(obs)#打印 test 和 prediction 的误差error = mean_squared_error(test, predictions)print(&#39;Test MSE: %.3f&#39; % error)</code></pre><p><img src="https://img-blog.csdnimg.cn/2884f522eca04d32a3c016a8d5ca77f2.png"></p><h2 id="4-7数据可视化"><a href="#4-7数据可视化" class="headerlink" title="4.7数据可视化"></a>4.7数据可视化</h2><pre><code># 画图查看结果from matplotlib import pyplotpyplot.figure(figsize=(12,6))pyplot.plot(test,color=&#39;blue&#39;,label=&quot;实际值&quot;)pyplot.plot(predictions, color=&#39;red&#39;,label=&quot;预测值&quot;)pyplot.xlabel(&#39;time&#39;)pyplot.ylabel(&#39;靠港数&#39;)pyplot.legend()pyplot.show()</code></pre><p><img src="https://img-blog.csdnimg.cn/c3289c4856f84523bb56e13c4639ef04.png"></p><h1 id="5-结论与展望"><a href="#5-结论与展望" class="headerlink" title="5.结论与展望"></a>5.结论与展望</h1><p>在 2020 年初，新型冠状动脉肺炎大规模爆发。仅在 2020 年 3 月底，新冠肺炎就横扫了213 个国家和地区，在全世界造成 223 万人感染，超过 10 万人死亡。许多国家已经宣布“紧急状态”。由于疫情爆发时许多国家施加的限制和严格控制，国际贸易下降，对国际运输的需求也下降。因此，在冠状肺炎的全球大规模流行的情况下，航运企业将需要对当前环境进行透彻的分析，积极应对并向前迈进。疫情直接导致需求先降后升，而整个物流供应链的成本增加了，伴随着增加了额外的运输和劳动力成本，加上由于大量集装箱船舶长期闲置搁浅，短期内国内外集装箱船舶的运力过剩，还是给航运企业经营带来较大困难。<br>中国出口集装箱运价指数的变动因素可以给疫情下的各大航运企业提供又一条应对思路。通过透彻分析各个港口拥堵程度，燃油价格以及运力指数对集装箱运价之间的关系，航运企业与当地政府之间相互配合下，一定能共渡难关。尽管我国的新冠状肺炎流行已得到基本控制，但要实现有效的全球控制尚需时日。因此，航运企业还应积极解决锁定问题，提高防疫意识，及时了解疫情的演变，并采取多种措施，确保职工在疫情中的稳定性和安全性，克服困难并做出快速响应。</p><h1 id="6-参考文献"><a href="#6-参考文献" class="headerlink" title="6.参考文献"></a>6.参考文献</h1><p>[1]王婧妍.浅析新冠疫情的世界性爆发对航运业的影响[J].珠江水运， 2020， 05:82-83.<br>[2].刘娜.大连外贸集装箱运价指数编制研究[D].大连:大连海事大学,2007.<br>[3].王辉.交通运输应对新冠肺炎疫情之策[J].交通运输研究， 2020， 6(01):1.<br>[4].周国光.新冠肺炎疫情防控对交通运输行业的影响及其对策研究[J].交通财会,2020,3:4-7.161616</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>OGNL表达式改造以使用索引</title>
      <link href="/zjh/2022/07/15/OGNL%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%94%B9%E9%80%A0%E4%BB%A5%E4%BD%BF%E7%94%A8%E7%B4%A2%E5%BC%95/"/>
      <url>/zjh/2022/07/15/OGNL%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%94%B9%E9%80%A0%E4%BB%A5%E4%BD%BF%E7%94%A8%E7%B4%A2%E5%BC%95/</url>
      
        <content type="html"><![CDATA[<p>一般在Mybatis中用#{}来防止sql注入，但是这种预编译的模式会导致无法调用java的方法，因此在<strong>系统安全性较高的情况下，或绑定的类型不是String</strong>时可以尝试使用${}来调用java方法进行数据处理</p><h1 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h1><p>一个表中关于时间有两个字段</p><ul><li><p>create_date是datetime类型<br>create_time是时间戳类型，但时间戳是13位的long型，这里是11位的int类型(int最大十进制长度)</p></li><li><p>前者没有索引，后者有索引（优势：字段短，索引更快，int比long占内存更小）</p></li><li><p>前者是给DBA看的，后者用于查询</p></li></ul><h1 id="使用OGNL表达式"><a href="#使用OGNL表达式" class="headerlink" title="使用OGNL表达式"></a>使用OGNL表达式</h1><p><a href="https://blog.csdn.net/huayu815/article/details/7446141">OGNL表达式参考</a></p><pre><code>  &lt;select id=&quot;mapper方法名&quot; resultType=&quot;Res对象&quot;&gt;    SELECT source, SUM(IF(type = 0, -amount, amount))    FROM 表    WHERE create_time &lt;![CDATA[ &lt;  ]]&gt; $&#123;endDateTime.toInstant(@java.time.ZoneOffset@of(&quot;+8&quot;)).toEpochMilli()/1000&#125;      AND create_time &lt;![CDATA[ &gt;= ]]&gt; $&#123;startDateTime.toInstant(@java.time.ZoneOffset@of(&quot;+8&quot;)).toEpochMilli()/1000&#125;    GROUP BY source  &lt;/select&gt;</code></pre><p>注：调静态方法时，类和方法都要加@；<br> /1000是为了让本身为long型的13位时间戳变成11位的int以便SELECT，<strong>且本身不是函数，不会导致索引失效</strong></p>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mvcc+按天缓存统计两个收益</title>
      <link href="/zjh/2022/07/15/mvcc+%E6%8C%89%E5%A4%A9%E7%BC%93%E5%AD%98%E7%BB%9F%E8%AE%A1%E4%B8%A4%E4%B8%AA%E6%94%B6%E7%9B%8A/"/>
      <url>/zjh/2022/07/15/mvcc+%E6%8C%89%E5%A4%A9%E7%BC%93%E5%AD%98%E7%BB%9F%E8%AE%A1%E4%B8%A4%E4%B8%AA%E6%94%B6%E7%9B%8A/</url>
      
        <content type="html"><![CDATA[<p>这是上一段电商实习时做的一个需求，也是我第一次实习时思考最多的一个需求，场景如下：</p><h1 id="1-场景"><a href="#1-场景" class="headerlink" title="1.场景"></a>1.场景</h1><p>用户实时收益表：存在虚拟收益、现金收益的<strong>当前值</strong><br>用户收益记录表：存在虚拟收益、现金收益的<strong>记录值</strong></p><p>要求：统计截止某天00:00时，用户的虚拟收益和现金收益</p><p>很显然，可以直接用 实时表的数据 减去 记录表的数据的总和</p><p>但是电商业务数据量很大，每次请求简单的都去查两次库然后相减合适吗？不合适。</p><h1 id="2-幂等方案设计——缓存"><a href="#2-幂等方案设计——缓存" class="headerlink" title="2.幂等方案设计——缓存"></a>2.幂等方案设计——缓存</h1><p>既然这个需求是“截止某天”，今天的“截止2号”和明天的“截止2号”查询的结果应该是幂等的，因此可以考虑在这个功能上添加缓存</p><p>但是这个缓存如何去加？直接加到xx天对应的数据存一个map？？很显然不合适，比如今天是7月15号，我连续查了7月1号~~7月14号的数据，<code>发现每次请求都花了我十几秒的时间</code>，<strong>因为这时候没有缓存，我查一下都会从完整的库中进行<code>SUM()</code></strong>,而在数据量大的情况下，SUM函数是特别耗费时间的，因此需要修改方案</p><h1 id="3-按天加缓存"><a href="#3-按天加缓存" class="headerlink" title="3.按天加缓存"></a>3.按天加缓存</h1><p>既然我们有两张表：实时、记录<br>那我们可以使用“记录表”，来统计<strong>7月1号00:00 到24:00的统计数据</strong><br>举个例子：</p><ul><li>我要查询“截止7月3号00:00的统计情况”</li><li>实时表：查询当前7月15号21:53:000的收益</li><li>记录表：<strong>依次通过SUM函数统计</strong> </br><br>7月3号00:00到7月3号24:00的收益统计</br><br>7月4号00:00到7月4号24:00的收益统计</br><br>7月5号00:00到7月5号24:00的收益统计</br><br>…..</br><br>7月14号00:00到7月14号24:00的收益统计</br></li><li><em><code>并加添加缓存</code>，这时的缓存是幂等的、连续的</em>*</li><li>然后用当前的收益 <code>连续地减去</code> 这12天的，<code>12条缓存数据</code>，再减去用SUM函数统计的今天的那部分数据（<code>今天还没过完，所以不能加缓存</code>）</li></ul><p>然后我再想查询“截止7月2号00:00的统计情况” “截止7月1号00:00的统计情况” ，我们就只有一两天的数据走MySQL，其他的所有统计数据都走的缓存，这一次我们调用接口花费了不到1秒种</p><h1 id="4-按天缓存解决的问题"><a href="#4-按天缓存解决的问题" class="headerlink" title="4.按天缓存解决的问题"></a>4.按天缓存解决的问题</h1><p>大大减少连续了<strong>查询紧挨着的</strong>几天所耗费的时间，也减少了对MySQL的性能消耗</p><p>但也出现的新的问题，我们不能简单的使用“当前收益”去<code>连续减去</code>“多天多条的缓存收益数据”。因为可能出现：获取“当前收益后”，此时<code>对于今天的记录数据变了</code>，今天的那部分走MySQL查询的记录数据变了，即使是过往的缓存正确，此时的数据也不正确了</p><h1 id="5-“今天数据”的一致性问题"><a href="#5-“今天数据”的一致性问题" class="headerlink" title="5.“今天数据”的一致性问题"></a>5.“今天数据”的一致性问题</h1><p>以前那些天数的缓存肯定是没问题的，是幂等的。问题就是出在“如何保证在不加锁的情况下实现<code>今天这部分数据的</code>一致性”</p><h2 id="5-1时间戳方案（pass）"><a href="#5-1时间戳方案（pass）" class="headerlink" title="5.1时间戳方案（pass）"></a>5.1时间戳方案（pass）</h2><ul><li>查询“实时表”后马上获取一个时间戳，带着这个时间戳去“记录表”查这之前的</li><li>Java的时间戳和MySQL时间戳不一致，因此时间戳需要从MySQL中查询</li></ul><p>不过这种方案虽然减少了不一致性的发生，但是也没有完全避免，并且两次查MySQL永远比只查一次更慢</p><h2 id="5-2利用UNION依托mvcc实现一致性"><a href="#5-2利用UNION依托mvcc实现一致性" class="headerlink" title="5.2利用UNION依托mvcc实现一致性"></a>5.2利用UNION依托mvcc实现一致性</h2><pre><code>SELECTSUM( profit_balance ) AS 今天的现金收益总和,SUM( profit_fictitious_balance ) AS 今天的虚拟收益总和 ,0 AS 今天的待减现金收益,0 AS 今天的待减虚拟收益FROM实时收益表UNION ALLSELECT 0 AS 今天的现金收益总和,0 AS 今天的虚拟收益总和,SUM(IF(type=1,profit_balance,-profit_balance)) AS 今天的待减现金收益,SUM(IF(type=1,amount,-amount)) AS 今天的待减虚拟收益FROM收益记录表</code></pre><p>然后这样就可以用一个Dto来装数据，这条SQL语句一共会产生两行，大概长这样</p><table><thead><tr><th>今天的现金收益总和</th><th>今天的虚拟收益总和</th><th>今天的待减现金收益</th><th>今天的待减虚拟收益</th></tr></thead><tbody><tr><td>9000</td><td>8000</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>1000</td><td>2000</td></tr></tbody></table><p>Mybatis对应会生成size=2的一个List，处理一下就得到了今天的数据了</p><h3 id="5-2-1不加锁一致性的实现机制"><a href="#5-2-1不加锁一致性的实现机制" class="headerlink" title="5.2.1不加锁一致性的实现机制"></a>5.2.1不加锁一致性的实现机制</h3><ul><li>因为是用UNION，所以这个数据一定是一致的</li><li>因为是RC（read comitted）级别，RC级别下是有MVCC（多版本并发控制）机制的，所以在SELECT的时候不会加锁，也不会受到当前其他现成读写操作的影响</li></ul>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>压缩打包但不归档，利用response</title>
      <link href="/zjh/2022/07/15/%E5%8E%8B%E7%BC%A9%E6%89%93%E5%8C%85%E4%BD%86%E4%B8%8D%E5%BD%92%E6%A1%A3%EF%BC%8C%E5%88%A9%E7%94%A8response/"/>
      <url>/zjh/2022/07/15/%E5%8E%8B%E7%BC%A9%E6%89%93%E5%8C%85%E4%BD%86%E4%B8%8D%E5%BD%92%E6%A1%A3%EF%BC%8C%E5%88%A9%E7%94%A8response/</url>
      
        <content type="html"><![CDATA[<p>把图片按自定义的层级关系及名称压缩打包，但不放入服务器<br>我的其他文章里有关于这个问题解决方案的小demo</p><h1 id="1-场景"><a href="#1-场景" class="headerlink" title="1.场景"></a>1.场景</h1><p>业务场景：学生提交作品中有很多图片，需要分层级按：活动名》班级》姓名》作品名》作品图片集合  压缩打包，并且<strong>因为这个作品是时常变化的，所以不能把压缩包放到服务器上</strong></p><p>要求：请求接口之后把压缩包发来，不准存服务器然后发url</p><h1 id="2-最终解决方案"><a href="#2-最终解决方案" class="headerlink" title="2.最终解决方案"></a>2.最终解决方案</h1><ul><li>把最终的zip流输出到response.getOutPutStream()中</li><li>在输出之前，先要设置请求头 <code>response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment; filename=&quot; + URLEncoder.encode(activityName) + &quot;.zip&quot;)</code>; ————<strong>用于指定最终输出的zip压缩包的名字</strong>，这个<code>URLEncoder.encode()</code>十分重要，否则中文会乱码</li><li>公司内部框架直接获取图片的byte[] ，遍历写入<code>》》</code>缓冲流write() <code>《《</code> 压缩流<code> 《《</code> response.getOutPutStream()</li><li>SQL查询出来年级、班级、姓名、作品名字、图片url ， 然后putZipEntry(new Entry(<code>用//来分层级</code>))</li><li><strong>业务方面：有的学校的班级是中文，因此必须CONCAT拼接。而为了保证最终文件可排序，因此不用”一年级“ 而用 ”1年级“</strong>  形如：new ZipEntry(“活动测试//1年级1班//张三-开心假期”)</li></ul><br/><h1 id="3-浏览器适配问题"><a href="#3-浏览器适配问题" class="headerlink" title="3.浏览器适配问题"></a>3.浏览器适配问题</h1><br/><ul><li>该方案设置请求头.setHeader(“Content-Disposition”, “attachment; filename=” +）直接<strong>强制在文件的末尾加上zip，可以防止因为不同浏览器无法解析ContentType导致的文件格式错误</strong>（google可以不指定）</li><li>尝试给edge浏览器做适配，发现除了上面的方法，没有其他方法可以设置文件格式</li><li>测试后，无论什么浏览器，压缩包末尾强制 .zip 文件接收后可以直接打开<br><img src="https://img-blog.csdnimg.cn/0e2118dc06b945bca75963d954a89489.png"></li></ul><h1 id="4-可优化的点"><a href="#4-可优化的点" class="headerlink" title="4.可优化的点"></a>4.可优化的点</h1><p>时间紧来不及学NIO，计划等最近的业务忙完了学学NIO，做一个demo，然后把这个业务优化一下 T_T</p>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>124个delete_flag的心酸</title>
      <link href="/zjh/2022/07/15/124%E4%B8%AAdelete-flag%E7%9A%84%E5%BF%83%E9%85%B8/"/>
      <url>/zjh/2022/07/15/124%E4%B8%AAdelete-flag%E7%9A%84%E5%BF%83%E9%85%B8/</url>
      
        <content type="html"><![CDATA[<p>解决delete_flag使用不规范造成的bug</p><h1 id="1-场景"><a href="#1-场景" class="headerlink" title="1.场景"></a>1.场景</h1><p>历史遗留BUG，场景：一共两个mapper，有一百多个sql，<strong>有90%以上的连表JOIN是没有加delete_flag=1条件，导致查询出来的结果会产生笛卡尔积。</strong> 还有一部分的delete_flag加了其中几个，放的位置也很耐人寻味~</p><p>————》由于最开始的业务没有做“删除”功能，导致这么长时间数据一直没有出错</p><br/><h1 id="2-解决方法"><a href="#2-解决方法" class="headerlink" title="2.解决方法"></a>2.解决方法</h1><p>先思考再动手，理清楚SELECT FROM JOIN WHERE之间的数量关系</p><ul><li><p>每次JOIN<strong>关联表</strong>必须带delete_flag = 1，WHERE中本应只写一个<strong>原表</strong>的delete_flag = 1 <img src="https://img-blog.csdnimg.cn/1776a41b5ada4e9a90c798096be771cd.png"></p></li><li><p>先ctrl + F 高亮，alt + J 框选，让JOIN更明显，挨个在JOIN之后加delete_flag = 1</p></li><li><p><strong>加完之后一定存在冗余</strong>，搜索每个WHERE条件，所以在WHERE条件下，一旦找到两个delete_flag = 1 那么一定有多余的<img src="https://img-blog.csdnimg.cn/593eb16d4fc94b859e835bcb42caa367.png"></p></li><li><p>最后核对数量  ctrl + F 搜索数量  <code>JOIN + WHERE = delete_flag</code> </br><br>54 + 16 = 70 另一个个mapper的解决方法同理</p></li></ul><h1 id="3-小结"><a href="#3-小结" class="headerlink" title="3.小结"></a>3.小结</h1><ul><li>每次JOIN都应该<strong>紧随其后</strong>一个AND delete_flag = 1 </li><li>无论当时的业务有没有删除功能，只要是表中有，就应该加上，避免埋炸弹！</li><li>WHERE后跟的 delete_flag = 1 应只有一个，且是针对于原表</li></ul><h1 id="4-根据提交记录再次优化"><a href="#4-根据提交记录再次优化" class="headerlink" title="4.根据提交记录再次优化"></a>4.根据提交记录再次优化</h1><ul><li>打开提交记录发现在21年3月（已经离最开始写过了半年）的时候冷不丁的JOIN了一张表</li><li>但是我又发现，这张表只JOIN了，但是没有做条件筛选（恰好不会影响最终结果）</li><li>盲猜是当时不准备改这个mapper，不小心改错了，提交的时候文件太多忘了取消提交。。。</li></ul><h1 id="5-后续的脏数据问题"><a href="#5-后续的脏数据问题" class="headerlink" title="5.后续的脏数据问题"></a>5.后续的脏数据问题</h1><p>这些都修改完了之后按理说统计的数据是没有问题的，但是测试在查库的时候发现还是有错误的数据。<br>我看了下日期是7月15号下午5点，联想到当时吃饭时听到leader打电话说了个谁谁谁在压测。<br>——————————</p><ul><li>这张表的业务本来只有tpye = 2，多的数据是tpye = 3 </li><li>type = 3是以前的业务，压测的时候用了以前的接口，导致多出来了6W多调 type=3 的数据</li><li>删掉就好了，业务代码写的没问题了~ </li></ul>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>非时序排序下的瀑布流分页</title>
      <link href="/zjh/2022/07/15/%E9%9D%9E%E6%97%B6%E5%BA%8F%E6%8E%92%E5%BA%8F%E4%B8%8B%E7%9A%84%E7%80%91%E5%B8%83%E6%B5%81%E5%88%86%E9%A1%B5/"/>
      <url>/zjh/2022/07/15/%E9%9D%9E%E6%97%B6%E5%BA%8F%E6%8E%92%E5%BA%8F%E4%B8%8B%E7%9A%84%E7%80%91%E5%B8%83%E6%B5%81%E5%88%86%E9%A1%B5/</url>
      
        <content type="html"><![CDATA[<p>设计非时序相关的排序功能。这个需求是对原有接口进行改造，在写思路的时候证明了原来逻辑有严重漏洞</p><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1.引言"></a>1.引言</h1><p>分页查询很常见，在web网页端的分页，和移动端手机下滑的分页逻辑一般都不同</p><ul><li>web端是常规的是<strong>指定页码数</strong>使用`limit #{start} , #{end}</li><li>移动端一般不会指定页码数，而是<strong>根据上一次的最后一个id作为fromId（主键）</strong>，先WHERE xxxid &gt; fromId 然后limit #{size} <strong>这样既符合手机下滑业务场景，也避免了页码过大查询速度降低的问题</strong></li></ul><h1 id="2-移动端可能存在的问题"><a href="#2-移动端可能存在的问题" class="headerlink" title="2.移动端可能存在的问题"></a>2.移动端可能存在的问题</h1><ul><li>如果我们是按时间排序，那么这套逻辑毫无问题！但是如果我们按班级排序（非时序）：</li><li>如果按班级<strong>升序</strong>每次我们查3条数据（<strong>limit 3</strong> ），在<strong>如下表的作品<code>提交</code>顺序</strong>，可能出现的情况是:</li></ul><table><thead><tr><th>班级</th><th>作品id（fromId）（主键）</th></tr></thead><tbody><tr><td>1班</td><td>4 5 7 ， 8 9 10</td></tr><tr><td>2班</td><td>1号作品 2号  3号 ，6 12 13</td></tr></tbody></table><table><thead><tr><th>第n次下拉手机屏幕</th><th>作品id（fromId）（主键）</th></tr></thead><tbody><tr><td>1</td><td>7 （取出1班的4 5 7号作品）</td></tr><tr><td>2</td><td>10 （取出1班的8 9 10号作品）</td></tr><tr><td>3</td><td>12 13（<code>因为fromId &gt; 10，所以前面1 2 3 6数据丢失了</code>）</td></tr></tbody></table><p><img src="https://img-blog.csdnimg.cn/7fd67321bb1b4fe4aaa3002ee92d00c9.png"></p><p>我造的这个数据，无论是升序  还是降序，都会导致数据丢失，因此可以得出结论:</p><h1 id="3-结论"><a href="#3-结论" class="headerlink" title="3.结论"></a>3.结论</h1><p>像班级  年级   等等等 所有的 <strong><code>自增主键和排序依据不是时间线性相关</code>的，都不能使用fromId作为排序依据</strong></p><h1 id="4-补充：：其他业务上的问题"><a href="#4-补充：：其他业务上的问题" class="headerlink" title="4.补充：：其他业务上的问题"></a>4.补充：：其他业务上的问题</h1><h2 id="4-1可能出现的中文排序"><a href="#4-1可能出现的中文排序" class="headerlink" title="4.1可能出现的中文排序"></a>4.1可能出现的中文排序</h2><p>班级字段是VARCHAR，有的学校的班级是中文，因此需要用 <code>正则 + CONCAT拼接</code></p><pre><code>   ORDER BY cg.`grade_no` DESC ,  --grade_no是INTEGER类型    CASE                         --class_no是VARCHAR类型，需要用正则匹配    WHEN cc.`class_no` REGEXP &#39;^[0-9]+$&#39; THEN CONVERT(cc.`class_no`,UNSIGNED INTEGER)    ELSE cc.`class_no` END    ASC;</code></pre><h2 id="4-2pass掉的fromId拼接排序方案"><a href="#4-2pass掉的fromId拼接排序方案" class="headerlink" title="4.2pass掉的fromId拼接排序方案"></a>4.2pass掉的fromId拼接排序方案</h2><p><code>SELECT CONCAT(grade_no , class_no , 作品id) ..........ORDER BY CONCAT(grade_no , class_no , 作品id) </code>这个作品id就是fromId，如果把这个fromId拼在后面，理论上可以实现无遗漏排序，但是</p><ul><li>考虑到grade_no 和 class_no被拼接为字符串后比较 ， 2&gt;11 导致乱序，必须扩充补0；</li><li>考虑到有的班级是中文，更不容易确定这个补0到底补几个</li><li>无法预知未来是否会对按班级排序加索引</li></ul><h2 id="4-3pass掉的rownum方案"><a href="#4-3pass掉的rownum方案" class="headerlink" title="4.3pass掉的rownum方案"></a>4.3pass掉的rownum方案</h2><p>以上的“拼接方案”被pass了，那么是否可以自己实现一个Oracle的<code>rownum</code>来保存当前的行号呢？<br>可行，但是涉及子查询 、存储变量 ，很麻烦，效率低，大概长这样</p><pre><code>set @rownum=0;SELECT    @rownum:=@rownum+1 AS rownum</code></pre><h2 id="4-4耦合业务"><a href="#4-4耦合业务" class="headerlink" title="4.4耦合业务"></a>4.4耦合业务</h2><ul><li>这个service层经过很多次的改动，有些改动后没有改注释，有的地方没注释，包括了管理员鉴权、班主任鉴权、创建者鉴权等等耦合业务，还包括了另一个模块的按投票排序功能</li><li>个人认为既然逻辑不同，就应该把web端和移动端的业务完全隔离，互不影响，投票排序也可以单拎出去，没有必要为了复用而复用，为了减少代码量而减少代码量。</li></ul><p><img src="https://img-blog.csdnimg.cn/6c92d5451c724003acb19ec5b1cd8bab.png"></p><h1 id="5-最终解决方案（更改字段含义）"><a href="#5-最终解决方案（更改字段含义）" class="headerlink" title="5.最终解决方案（更改字段含义）"></a>5.最终解决方案（更改字段含义）</h1><ul><li>移动端利用原有的type区分到“按班级排序”时，将fromId字段含义改为“xx页”————页码数</li><li>这样不影响其他的业务，也能够正确的查询出数据，只是在极端情况下页码数过大时会稍慢（几乎不考虑）</li><li>修改fromId的含义，只需要详细的在前后端代码的注释中体现即可</li></ul>]]></content>
      
      
      <categories>
          
          <category> 工作笔记 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>行程编码压缩图片</title>
      <link href="/zjh/2022/06/25/%E8%A1%8C%E7%A8%8B%E7%BC%96%E7%A0%81%E5%8E%8B%E7%BC%A9%E5%9B%BE%E7%89%87/"/>
      <url>/zjh/2022/06/25/%E8%A1%8C%E7%A8%8B%E7%BC%96%E7%A0%81%E5%8E%8B%E7%BC%A9%E5%9B%BE%E7%89%87/</url>
      
        <content type="html"><![CDATA[<p>因为图片的连续像素点灰度值与色值一般都有很长的相同，例如这是一张图的部分byte[]<img src="https://img-blog.csdnimg.cn/f16b3f6b259245899a054f0cbd7096b5.png"></p><p>因此可以将byte[] 压缩为 <code>值1*行程长度1#值2*行程长度2#</code>的格式，这种压缩算法在证件照、白底画等有大面积连续颜色区域的时候效果很好；而在每个相邻像素点都不同颜色or灰度值的情况下压缩后反而更大</p><h1 id="1-压缩rleEncoder"><a href="#1-压缩rleEncoder" class="headerlink" title="1.压缩rleEncoder"></a>1.压缩rleEncoder</h1><pre><code>public static String rleEncoder(byte[] src)&#123;    //初始化，存入第一个元素    StringBuffer stringBuffer = new StringBuffer(src[0] + &quot;*&quot;);    //遍历 从第二个元素开始    int count = 1;    for(int i = 1 ; i &lt; src.length ; i++)&#123;        //如果跟上一个元素相同        if(src[i] != src[i-1]) &#123;            stringBuffer.append(count);            stringBuffer.append(&quot;#&quot;);//结束标志            stringBuffer.append(src[i]);            stringBuffer.append(&quot;*&quot;);            count = 1;//计数器归位        &#125;else&#123;            //相同元素计数器+1            count++;        &#125;    &#125;    stringBuffer.append(count);    stringBuffer.append(&quot;#&quot;);    return stringBuffer.toString();&#125;</code></pre><h1 id="2-解压rleDecoder"><a href="#2-解压rleDecoder" class="headerlink" title="2.解压rleDecoder"></a>2.解压rleDecoder</h1><pre><code>    public static byte[] rleDecoder(String src)&#123;//此时的src是形如0*2#11*1#2*1#3*1#4*1#55*5#的字符串        String s = src.replaceAll(&quot;\\#&quot;, &quot;*&quot;);//方便分割        String[] split = s.split(&quot;\\*&quot;);        ArrayList&lt;Byte&gt; list = new ArrayList&lt;Byte&gt;();        Byte tempValue = 0;        int tempNumber = 0;        //偶数索引是值  奇数索引是数量        for(int i = 0 ; i &lt; split.length ; i++)&#123;            //偶数是值            if((i&amp;1) == 0)&#123;                tempValue = Byte.parseByte(split[i]);            //奇数是数量            &#125;else&#123;                tempNumber = Integer.parseInt(split[i]);                //确定值和数量之后for循环                for(int j = 0 ; j &lt; tempNumber ; j++)&#123;                    list.add(tempValue);                &#125;            &#125;        &#125;        byte[] bytes = new byte[list.size()];        for(int i = 0 ; i &lt; list.size() ; i++)&#123;            bytes[i] = list.get(i);        &#125;        return bytes;    &#125;</code></pre><h1 id="3-演示"><a href="#3-演示" class="headerlink" title="3.演示"></a>3.演示</h1><pre><code>   String dest = rleEncoder(new byte[]&#123;0,0,0,0,0,0,0,0,0,0,0,0,0,            6,6,6,6,6,6,6,6,6,6,6,6,8,            8,8,8,8,8,8,8,8,8,8,8,8,8,8&#125;);    byte[] bytes = rleDecoder(dest);    System.out.println(new String(bytes));</code></pre><p><img src="https://img-blog.csdnimg.cn/c934270a7b81429581c175c5af1f701f.png"></p>]]></content>
      
      
      <categories>
          
          <category> 数据结构算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>常见排序</title>
      <link href="/zjh/2022/04/21/%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F/"/>
      <url>/zjh/2022/04/21/%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="快排"><a href="#快排" class="headerlink" title="快排"></a>快排</h1><pre><code>public class QuickSort3 &#123;    public static void main(String[] args) &#123;        int[] arr = new int[]&#123;23, 5, 2, 3, 4, 6, 2345, 23, 4, 5, 12, 67, 5, 3, 6, 5, 3, 1&#125;;        sort(arr,0 , arr.length-1);        System.out.println(Arrays.toString(arr));    &#125;    public static void sort(int[] arr, int left, int right) &#123;        if(right&lt;=left)&#123;            return;        &#125;        int l = left;        int r = right;        int base = arr[left];        while (l &lt; r) &#123;            while (r &gt; l &amp;&amp; arr[r] &gt;= base) &#123;                r--;            &#125;            while (l &lt; r &amp;&amp; arr[l] &lt;= base) &#123;                l++;            &#125;            if(l&gt;=r)&#123;                break;            &#125;else&#123;                swap(arr,l , r);            &#125;        &#125;        swap(arr,l , left);        sort(arr,left ,l-1 );        sort(arr, l+1, right);    &#125;    public static void swap(int[] arr, int i, int j) &#123;        int temp = arr[i];        arr[i] = arr[j];        arr[j] = temp;    &#125;&#125;</code></pre><h1 id="插入排序"><a href="#插入排序" class="headerlink" title="插入排序"></a>插入排序</h1><pre><code>public class InsertSort2 &#123;    public static void main(String[] args) &#123;        int[] arr = new int[]&#123;23, 5, 2, 3, 4, 6, 2345, 23, 4, 5, 12, 67, 5, 3, 6, 5, 3, 1&#125;;        sort(arr);        System.out.println(Arrays.toString(arr));    &#125;    public static void sort(int[] arr) &#123;        for (int i = 0; i &lt; arr.length; i++) &#123;            for (int j = i; j &gt; 0; j--) &#123;                if (arr[j] &lt; arr[j - 1])&#123;                    swap(arr, j, j-1);                &#125;            &#125;        &#125;    &#125;    public static void swap(int[] arr, int i, int j) &#123;        int temp = arr[i];        arr[i] = arr[j];        arr[j] = temp;    &#125;&#125;</code></pre><h1 id="希尔排序"><a href="#希尔排序" class="headerlink" title="希尔排序"></a>希尔排序</h1><pre><code>public class ShellSort3 &#123;    public static void main(String[] args) &#123;        int[] arr = new int[]&#123;23, 5, 2, 3, 4, 6, 2345, 23, 4, 5, 12, 67, 5, 3, 6, 5, 3, 1&#125;;        sort(arr);        System.out.println(Arrays.toString(arr));    &#125;    public static void sort(int[] arr) &#123;        int gap = arr.length;        while (gap &gt;= 1) &#123;            gap /= 2;            for (int i = gap; i &lt; arr.length; i++) &#123;                for (int j = i; j &gt;= gap; j -= gap) &#123;                    if(arr[j] &lt; arr[j-gap])&#123;                        swap(arr,j , j-gap);                    &#125;else&#123;                        break;                    &#125;                &#125;            &#125;        &#125;    &#125;    public static void swap(int[] arr, int i, int j) &#123;        int temp = arr[i];        arr[i] = arr[j];        arr[j] = temp;    &#125;&#125;</code></pre><h1 id="冒泡"><a href="#冒泡" class="headerlink" title="冒泡"></a>冒泡</h1><pre><code>public class BubbleSort3 &#123;    public static void main(String[] args) &#123;        int[] arr = new int[]&#123;23, 5, 2, 3, 4, 6, 2345, 23, 4, 5, 12, 67, 5, 3, 6, 5, 3, 1&#125;;        sort(arr);        System.out.println(Arrays.toString(arr));    &#125;    public static void sort(int[] arr) &#123;        for (int i = arr.length - 1; i &gt; 0; i--) &#123;            for (int j = 0; j &lt; i; j++) &#123;                if (arr[j] &gt; arr[j + 1]) &#123;                    swap(arr, j, j + 1);                &#125;            &#125;        &#125;    &#125;    public static void swap(int[] arr, int i, int j) &#123;        int temp = arr[i];        arr[i] = arr[j];        arr[j] = temp;    &#125;&#125;</code></pre><h1 id="堆排"><a href="#堆排" class="headerlink" title="堆排"></a>堆排</h1><pre><code>public class heapSort &#123;    public static void main(String[] args) &#123;        int[] arr = new int[]&#123;1, 2, 4, 5, 1, 2, 4, 3, 2, 54, 23452, 543, 12, 4&#125;;        System.out.println(&quot;最初&quot;);        System.out.println(Arrays.toString(arr));        System.out.println(&quot;生成大顶堆&quot;);        heapMaker(arr);//生成大顶堆        System.out.println(Arrays.toString(arr));        System.out.println(&quot;循环固定，排序后&quot;);        int size = arr.length;        while (size &gt; 1) &#123;            //1,固定最大值            swap(arr, 0, size - 1);            size--;            //2,下沉：修正大顶堆            sink(arr, 0, size);        &#125;        System.out.println(Arrays.toString(arr));    &#125;    //交换    public static void swap(int[] arr, int i, int j) &#123;        int temp = arr[i];        arr[i] = arr[j];        arr[j] = temp;    &#125;    //创建堆：从arr[0]开始，每添加一个元素都和其父元素进行对比    public static void heapMaker(int[] arr) &#123;        for (int i = 0; i &lt; arr.length; i++) &#123;            int currentIndex = i;            int fatherIndex = (i - 1) / 2;            //因为此逻辑并未判断左右子节点之间的大小关系，所以在sink方法中需要进行判断            while (arr[currentIndex] &gt; arr[fatherIndex]) &#123;                //1.交换                swap(arr, currentIndex, fatherIndex);                //2.子索引变父索引，继续向上判断                currentIndex = fatherIndex;                fatherIndex = (fatherIndex - 1) / 2;            &#125;        &#125;    &#125;    //大顶堆的修正(下沉算法)    public static void sink(int[] arr, int index, int size) &#123;//size:最大范围        //1.左右子节点大小对比，        int left = index * 2 + 1;        int right = index * 2 + 2;        int maxValueIndex = 0;//父、左、右的最大值对应的索引        //2.right&lt;size即可保证指针不越界        while (left &lt; size) &#123;            //2.1找出最大值的索引            if (right &lt; size &amp;&amp; arr[right] &gt; arr[left]) &#123;                maxValueIndex = right;            &#125; else &#123;                maxValueIndex = left;            &#125;            if (arr[index] &gt; arr[maxValueIndex]) &#123;                maxValueIndex = index;            &#125;            //2.2判断是否大顶堆            if (index == maxValueIndex) &#123;                break;            &#125;            //2.3交换arr中的值            swap(arr, index, maxValueIndex);            //2.4下一轮            index = maxValueIndex;//一定是左or右            left = index * 2 + 1;            right = index * 2 + 2;        &#125;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Filter的常见用法</title>
      <link href="/zjh/2022/04/21/Filter%E7%9A%84%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95/"/>
      <url>/zjh/2022/04/21/Filter%E7%9A%84%E5%B8%B8%E8%A7%81%E7%94%A8%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<p>Filter 是 JavaEE 中 Servlet 规范的一个组件，位于包javax.servlet 中，它可以在 HTTP 请求到达 Servlet 之前，被一个或多个Filter处理。<br><img src="https://img-blog.csdnimg.cn/493d90f7f4ef457f85942c455a2c75fa.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAempoYmxvZw==,size_19,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="1-案例结构"><a href="#1-案例结构" class="headerlink" title="1.案例结构"></a>1.案例结构</h1><h2 id="1-1first拦截器"><a href="#1-1first拦截器" class="headerlink" title="1.1first拦截器"></a>1.1first拦截器</h2><pre><code>@WebFilter(filterName = &quot;first&quot; , urlPatterns = &quot;/*&quot;)@Order(1)public class FirstFilter implements Filter &#123;  @Override  public void init(FilterConfig filterConfig) throws ServletException &#123;    Filter.super.init(filterConfig);    System.out.println(&quot;first拦截器初始化&quot;);  &#125;  @Override  public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;    HttpServletRequest req = (HttpServletRequest) servletRequest;    System.out.println(&quot;first拦截器获取Attribute&quot;+req.getAttribute(&quot;name&quot;));//无    req.setAttribute(&quot;name&quot;,&quot;第一次设置的name&quot;);//作用范围为：一次请求域，即下次Filter也能取的到    HttpServletResponse res = (HttpServletResponse) servletResponse;    res.setHeader(&quot;firstHeader&quot;,&quot;firstHeader&quot;);//设置请求头，会一直层层传递到控制层的响应头    filterChain.doFilter(req,res);//按Order优先顺序调用下一个Filter，直到Controller层    System.out.println(&quot;firstFilterEnd&quot;);//doFilter内部执行完毕之后，才回来执行这个，类似二叉树的前序遍历  &#125;  @Override  public void destroy() &#123;    Filter.super.destroy();    System.out.println(&quot;first拦截器销毁&quot;);  &#125;&#125;</code></pre><h2 id="1-2second拦截器"><a href="#1-2second拦截器" class="headerlink" title="1.2second拦截器"></a>1.2second拦截器</h2><pre><code>@WebFilter(urlPatterns = &quot;/*&quot;)@Order(2)public class SecondFilter implements Filter &#123;  @Override  public void init(FilterConfig filterConfig) throws ServletException &#123;    Filter.super.init(filterConfig);    System.out.println(&quot;second拦截器初始化&quot;);  &#125;  @Override  public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123;    HttpServletRequest req = (HttpServletRequest) servletRequest;    System.out.println(&quot;second拦截器获取Attribute&quot;+req.getAttribute(&quot;name&quot;));//第一次设置的name    req.setAttribute(&quot;name&quot;,&quot;第二次设置的name&quot;);    HttpServletResponse res = (HttpServletResponse) servletResponse;    res.setHeader(&quot;secondHeader&quot;,&quot;secondeHeader&quot;);    filterChain.doFilter(req,res);//后续没有Filter，调用Controller    System.out.println(&quot;secondFilterEnd&quot;);  &#125;  @Override  public void destroy() &#123;    Filter.super.destroy();    System.out.println(&quot;second拦截器销毁&quot;);  &#125;&#125;</code></pre><h2 id="1-3控制层"><a href="#1-3控制层" class="headerlink" title="1.3控制层"></a>1.3控制层</h2><pre><code>  @PostMapping(&quot;/web&quot;)  public DtoRes webTest(HttpServletRequest request  ,  HttpServletResponse response ,@RequestParam(&quot;userName&quot;) String userName) throws IOException &#123;    System.out.println(&quot;controller&quot;);    return null;  &#125;</code></pre><h2 id="拦截器执行流程"><a href="#拦截器执行流程" class="headerlink" title="拦截器执行流程"></a>拦截器执行流程</h2><h3 id="启动SpringBoot"><a href="#启动SpringBoot" class="headerlink" title="启动SpringBoot"></a>启动SpringBoot</h3><p>firstFilter的@Order更小，优先加载</p><p><img src="https://img-blog.csdnimg.cn/a1f68fc2f98a420488766d3bd609c1e0.png"></p><h3 id="请求接口"><a href="#请求接口" class="headerlink" title="请求接口"></a>请求接口</h3><p><img src="https://img-blog.csdnimg.cn/3d03c1015b4b4878ade729d8ed0bd51c.png"></p><h3 id="关闭SpringBoot"><a href="#关闭SpringBoot" class="headerlink" title="关闭SpringBoot"></a>关闭SpringBoot</h3><p><img src="https://img-blog.csdnimg.cn/844c3a4fc3e5407b877336fa9dd917a8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAempoYmxvZw==,size_15,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="2-主要注解"><a href="#2-主要注解" class="headerlink" title="2.主要注解"></a>2.主要注解</h1><h2 id="WebFilter"><a href="#WebFilter" class="headerlink" title="@WebFilter"></a>@WebFilter</h2><ul><li>无需在web.xml 中注册一个 Filter 来对某个 Servlet 程序进行拦截处理</li><li>@WebFilter 用于<strong>将一个类声明为过滤器</strong>，该注解将会在部署时被容器处理，容器将根据具体的属性配置将相应的类部署为过滤器。该注解具有下表给出的一些常用属性 ( 以下所有属性均为可选属性，但是 value、urlPatterns、servletNames 三者必需至少包含一个，且 value 和 urlPatterns 不能共存，如果同时指定，通常忽略 value 的取值 )</li><li>最重要的就是urlPatterns拦截规则，支持正则，指明需要拦截的路径，多层拦截没有特殊情况</li></ul><p><img src="https://img-blog.csdnimg.cn/517a302755de489bbde1593d1e642557.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAempoYmxvZw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="Order"><a href="#Order" class="headerlink" title="@Order()"></a>@Order()</h2><p>@Order(1)的拦截器优先于@Order(2)，默认值为@Order(2147483647)</p><h2 id="ServletComponentScan"><a href="#ServletComponentScan" class="headerlink" title="@ServletComponentScan"></a>@ServletComponentScan</h2><ul><li>在SpringBootApplication(启动类)上使用</li><li>@ServletComponentScan注解后，Servlet、Filter(过滤器)、Listener(监听器)可以直接通过@WebServlet、@WebFilter、@WebListener注解自动注册，无需其他代码！</li></ul><h1 id="3-Filter的方法"><a href="#3-Filter的方法" class="headerlink" title="3.Filter的方法"></a>3.Filter的方法</h1><h2 id="初始化init"><a href="#初始化init" class="headerlink" title="初始化init"></a>初始化init</h2><ul><li><p>伴随Springboot启动而初始化，只初始化一次</p></li><li><p>会传递一个包含 Filter 的配置和运行环境信息的 FilterConfig 对象。</p></li><li><p>如果初始化代码要使用到 FilterConfig 对象，这些代码只能在 init 方法中编写，而不能在构造方法中编写（尚未调用 init 方法，即并没有创建 FilterConfig 对象，要使用它则必然出错）。</p><pre><code>@Overridepublic void init(FilterConfig filterConfig) throws ServletException &#123;  Filter.super.init(filterConfig);&#125;</code></pre></li></ul><h2 id="进入下一Filter-直至Controller层"><a href="#进入下一Filter-直至Controller层" class="headerlink" title="进入下一Filter(直至Controller层)"></a>进入下一Filter(直至Controller层)</h2><pre><code>@Override  public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain)   throws IOException, ServletException &#123;        filterChain.doFilter(req,res);  &#125;</code></pre><h2 id="销毁destroy"><a href="#销毁destroy" class="headerlink" title="销毁destroy"></a>销毁destroy</h2><p>结束SpringBoot程序时才销毁（不是结束请求）</p><pre><code>  @Override  public void destroy() &#123;    Filter.super.destroy();  &#125;</code></pre><h1 id="4-FilterChain拦截器链"><a href="#4-FilterChain拦截器链" class="headerlink" title="4.FilterChain拦截器链"></a>4.FilterChain拦截器链</h1><ul><li>最后一个<code>filterChain.doFilter(req,res)</code>;方法中调用的 FilterChain.doFilter 方法将激活目标 Servlet的service 方法。</li><li>只要 Filter 链中任意一个 Filter 没有调用 <code>filterChain.doFilter()</code> 方法，则目标 Servlet 的 service 方法都不会被执行。</li><li><code>filterChain.doFilter(req,res)</code>;会自动把FilterChain对象传给下一个<code>Filter.doFilter</code>()</li></ul><h1 id="5-FilterConfig拦截器配置接口"><a href="#5-FilterConfig拦截器配置接口" class="headerlink" title="5.FilterConfig拦截器配置接口"></a>5.FilterConfig拦截器配置接口</h1><ul><li>实现Filter接口后init()方法的形参就是FilterConfig<br><img src="https://img-blog.csdnimg.cn/f7c4668904274f73a0612516a23c2321.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAempoYmxvZw==,size_20,color_FFFFFF,t_70,g_se,x_16" alt="摘自菜鸟"></li></ul><h1 id="6-FilterRegistrationBean和-WebFilter区别"><a href="#6-FilterRegistrationBean和-WebFilter区别" class="headerlink" title="6.FilterRegistrationBean和@WebFilter区别"></a>6.FilterRegistrationBean和@WebFilter区别</h1><p>有2种方式可以实现过滤器</p><p>1：通过FilterRegistrationBean实例注册</p><p>2：通过@WebFilter注解生效</p><p>这里选择第一种，因为第二种不能设置过滤器之间的优先级</p><p>转载自灰信：<br><a href="https://www.freesion.com/article/9482868580/">区别</a></p><h1 id="7-OncePerRequestFilter"><a href="#7-OncePerRequestFilter" class="headerlink" title="7.OncePerRequestFilter"></a>7.OncePerRequestFilter</h1><ul><li>OncePerRequestFilter仍然是需要注入到Spring中，仍然通常采用@WebFilter</li><li>对目标拦截路径的资源仍然正常拦截</li><li>OncePerRequestFilter存在于spring-web模块中org.springframework.web.filter ; 而Filter则在Servlet模块中 javax.servlet</li><li>OncePerRequestFilter是对Filter的扩展，他内部已重写了init() doFilter() destory()，并且还有自己的抽象方法<code>doFilterInternal</code>需要实现类去重写</li><li>内部跳转只拦截一次（一次外部请求只过滤一次）</li><li>在SpringMVC中对于Filter的扩展都是继承了OncePerRequestFilter。其中都是实现了doFilterInternal()的方法扩展。</li></ul><h2 id="重写的doFilter"><a href="#重写的doFilter" class="headerlink" title="重写的doFilter"></a>重写的doFilter</h2><p>源码中的链路调用，调用了抽象方法doFilterInternal，因此需要自己重写才能完成doFilter()的完整逻辑<br><img src="https://img-blog.csdnimg.cn/9f9badeb6ab349e18362cf9d2fa11474.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAempoYmxvZw==,size_20,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="doFilterInternal抽象方法"><a href="#doFilterInternal抽象方法" class="headerlink" title="doFilterInternal抽象方法"></a>doFilterInternal抽象方法</h2><p>用法其实和普通的Filter差不多，但是在接口内部跳转（不加@ResponseBody返回String的接口）时，不会再进行第二次的拦截</p><pre><code>@WebFilter(urlPatterns = &quot;/*&quot;)@Order(-1)public class OnceFilter extends OncePerRequestFilter &#123;  @Override  protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain)      throws ServletException, IOException &#123;    System.out.println(&quot;开始&quot;);    filterChain.doFilter(request,response);    System.out.println(&quot;结束&quot;);  &#125;&#125;</code></pre><h2 id="OncePerRequestFilter执行顺序"><a href="#OncePerRequestFilter执行顺序" class="headerlink" title="OncePerRequestFilter执行顺序"></a>OncePerRequestFilter执行顺序</h2><ul><li>当定义了多个Filter时，<strong>OncePerRequestFilter总是在第一个Filter之后执行</strong></li><li>多个OncePerRequestFilter之间也可以有@Order指定顺序</li><li><strong>所有OncePerRequestFilter按顺序执行完毕之后，才执行第二个Filter</strong></li><li>OncePerRequestFilter也满足Filter队列的出队顺序</li></ul><p>其他参考：<br><a href="https://zhuanlan.zhihu.com/p/166411087">添加链接描述</a><br><a href="https://www.runoob.com/w3cnote/filter-filterchain-filterconfig-intro.html">菜鸟</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Lambda表达式和方法引用</title>
      <link href="/zjh/2022/04/21/Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8/"/>
      <url>/zjh/2022/04/21/Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%92%8C%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>参考:<br><a href="https://blog.csdn.net/ioriogami/article/details/12782141?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164946395516780255216553%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=164946395516780255216553&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-2-12782141.142%5Ev7%5Epc_search_result_cache,157%5Ev4%5Econtrol&utm_term=lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F&spm=1018.2226.3001.4187">1</a><br><a href="https://www.bilibili.com/video/BV1Kb411W75N?p=674&spm_id_from=pageDriver">2</a></p><h1 id="什么是lambda表达式"><a href="#什么是lambda表达式" class="headerlink" title="什么是lambda表达式"></a>什么是lambda表达式</h1><ul><li><p>lambda意为λ，表示是一个函数，而一个函数只有唯一的输入输出映射，因此引出lambda表达式的定义</p></li><li><p><strong>Lambda是一个<code>唯一匿名方法</code></strong></p></li><li><p>一个接口，如果<strong>只有一个显式声明的抽象方法，那么它就是一个函数式接口</strong>。一般用@FunctionalInterface标注出来（也可以不标）</p></li><li><p>因为该接口有一个抽象方法，在new的时候需要@Override这个抽象方法    </p></li></ul><h1 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h1><p><img src="https://img-blog.csdnimg.cn/9eb2a21974c0441b9de4e42cd32db7a2.png"></p><h2 id="什么可以省略？"><a href="#什么可以省略？" class="headerlink" title="什么可以省略？"></a>什么可以省略？</h2><p><strong><code>可推断的都可省略，因此尽可能使用泛型</code></strong></p><p>方框中都可以省略</p><p><img src="https://img-blog.csdnimg.cn/09cef4588f1e4cb68009d2eb80211ee3.png" alt="方框中都可以省略">因为在调用这个方法的时候，public int add(int int ) return 都是<strong>唯一且确定且必须存在的</strong>，因此可以被唯一推断出来，所以可以省略，省略后为</p><p><code>(x,y) -&gt; x+y;</code><br>因为只有一行语句，所以代码块{}可省，return可省</p><h1 id="1-预定义的函数式接口"><a href="#1-预定义的函数式接口" class="headerlink" title="1.预定义的函数式接口"></a>1.预定义的函数式接口</h1><p>在JDK中定义了很多的函数式接口，例如BiFunction接口，就可以传入两个参数，返回一个参数，无需自定义；当然三个传参还是需要自定义的<br><img src="https://img-blog.csdnimg.cn/1fb4162e9e3743de8c6c874e83c16ec7.png"></p><h2 id="1-1"><a href="#1-1" class="headerlink" title="1.1"></a>1.1</h2><h3 id="函数型接口"><a href="#函数型接口" class="headerlink" title="函数型接口"></a>函数型接口</h3><p>1.JDK预定义了很多函数式接口以避免用户重复定义。最典型的是<code>Function</code>：</p><pre><code>@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123;     R apply(T t);&#125;</code></pre><p>这个接口代表一个函数，接受一个T类型的参数，并返回一个R类型的返回值。   </p><h3 id="消费型接口"><a href="#消费型接口" class="headerlink" title="消费型接口"></a>消费型接口</h3><p>2.另一个预定义函数式接口叫做<code>Consumer</code>，跟Function的唯一不同是它没有返回值。</p><pre><code>@FunctionalInterfacepublic interface Consumer&lt;T&gt; &#123;     void accept(T t);&#125;</code></pre><h3 id="供给型接口"><a href="#供给型接口" class="headerlink" title="供给型接口"></a>供给型接口</h3><p>3.<code>Supplier</code> 有一个get(）方法</p><pre><code>@FunctionnallInterfacepublic interface Supplier&lt;T&gt;&#123;    T get();&#125;</code></pre><h3 id="断定型接口"><a href="#断定型接口" class="headerlink" title="断定型接口"></a>断定型接口</h3><p>4.还有一个<code>Predicate</code>断定，用来判断某项条件是否满足。经常用来进行筛滤操作：</p><pre><code>@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123;     boolean test(T t);&#125;</code></pre><h2 id="1-2函数式接口的测试"><a href="#1-2函数式接口的测试" class="headerlink" title="1.2函数式接口的测试"></a>1.2函数式接口的测试</h2><pre><code>public class LambdaTest &#123;    public static void main(String[] args) &#123;//1.Runnale接口测试————run()        Runnable r = () -&gt; System.out.println(&quot;测试&quot;);        r.run();//2.Function接口测试————— T apply(X x)        Function&lt;Integer, Integer&gt; fun = (age) -&gt; &#123;            System.out.println(&quot;年龄为：&quot; + age);//年龄为：21            return age + 1;        &#125;;        System.out.println(&quot;下次过生日的年龄：&quot; + fun.apply(21));//下次过生日的年龄：22//3.Consumer接口测试————accept(T t)        //3.1加泛型，推断s为String类型        Consumer&lt;String&gt; con = (s) -&gt; System.out.println(s + &quot;666666&quot;);//双击关注666666        con.accept(&quot;双击关注&quot;);        //3.2不加泛型需要指定，默认为Object        Consumer con2 = (s) -&gt; System.out.println(s + &quot;777777&quot;);//养猪厂子777777        con2.accept(&quot;养猪厂子&quot;);//4.Supplier接口测试        //4.1不加泛型，则不推断        Supplier sup = () -&gt; &#123;            return new Integer(1);        &#125;;        //4.2加泛型，则可推断返回值为Integer        Supplier&lt;Integer&gt; sup2 = () -&gt; 1;//5.Predicate接口测试        Predicate&lt;Integer&gt; pred = (i) -&gt; i &gt; 10;        System.out.println(pred.test(11));//ture        System.out.println(pred.test(9));//false    &#125;    &#125;</code></pre><h1 id="2-自定义函数式接口"><a href="#2-自定义函数式接口" class="headerlink" title="2.自定义函数式接口"></a>2.自定义函数式接口</h1><p>定义函数式接口，接收多个参数</p><pre><code>@FunctionalInterfacepublic interface MyFunction&lt;X,Y,Z,T&gt; &#123;    T fun(X x,Y y ,Z z);&#125;</code></pre><p>使用</p><pre><code>//6.自定义MyFunction接口        MyFunction&lt;Integer,Integer,Integer,String&gt; myFun =                (age,weight,higth) -&gt; &quot;年龄为：&quot; + age                                    + &quot;体重为：&quot; + weight                                    + &quot;身高为：&quot; + higth;        String myInfo = myFun.fun(21, 145, 181);        System.out.println(myInfo);//年龄为：21体重为：145身高为：181</code></pre><h1 id="3-方法引用"><a href="#3-方法引用" class="headerlink" title="3.方法引用"></a>3.方法引用</h1><ul><li>当实现@FunctionalInterface的函数式接口使用lambda表达式时，<br>如果方法体直接调用 某个类or对象 的 静态or非静态方法，<br>且返回值和形参都高度相同or完全相同，那么就可以使用方法引用</li><li><code>编译看左</code>：类型的推断需要左边函数类的泛型来指定<h2 id="3-1对象-非静态方法"><a href="#3-1对象-非静态方法" class="headerlink" title="3.1对象::非静态方法"></a>3.1对象::非静态方法</h2><code>Function fun = p :: myHight;即把fun中的唯一抽象函数apply() 和 myHight()方法绑定，调用fun.apply(1)相当于调用p.myHight(1)</code></li></ul><pre><code>public class LambdaTest2 &#123;    public static void main(String[] args) &#123;        //0. People的非静态方法myHight()的形参 和 Function类的apply()方法的形参对应        //                            的返回值 和                      的返回值对应        People p = new People(21,&quot;张家豪&quot;);        //1.用 对象p :: 非静态方法        Function&lt;Integer,String&gt; fun = p :: myHight;        //2.此时的fun对象中的apply()方法已经和 p对象中的myHight()方法绑定        System.out.println(fun.apply(181));    &#125;&#125;class People&#123;    int age;    String name;    public  String myHight(Integer hight)&#123;        return &quot;my hight is &quot; + hight;    &#125;&#125;</code></pre><h2 id="3-2类-静态方法"><a href="#3-2类-静态方法" class="headerlink" title="3.2类 :: 静态方法"></a>3.2类 :: 静态方法</h2><pre><code>。。。。。。。。    //编译看左：左边需要指定泛型，才能推断出右边的参数类型        Consumer&lt;Integer&gt; con = People::describe;        con.accept(2);    &#125;&#125;class People &#123;    int age;    String name;    public static void describe2(Integer i) &#123;        System.out.println(&quot;People类有&quot; + i + &quot;个属性参数&quot;);        System.out.println(&quot;一个是name，一个是age&quot;);    &#125;</code></pre><h2 id="3-3类-实例方法"><a href="#3-3类-实例方法" class="headerlink" title="3.3类 :: 实例方法"></a>3.3类 :: 实例方法</h2><p><a href="https://blog.csdn.net/lkforce/article/details/99682885?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164947501216780264034763%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=164947501216780264034763&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-99682885.142%5Ev7%5Epc_search_result_cache,157%5Ev4%5Econtrol&utm_term=%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8&spm=1018.2226.3001.4187">参考</a></p><h1 id="4-构造器引用"><a href="#4-构造器引用" class="headerlink" title="4.构造器引用"></a>4.构造器引用</h1><p>和方法引用类似<br>构造器的形参 = 函数式接口的抽象方法</p><pre><code>        Function&lt;String,People&gt; fun1 = s -&gt; new People(s);        People p1 = fun1.apply(&quot;张豪猪&quot;);                Function&lt;String,People&gt; fun2 = People::new;        People p2 = fun2.apply(&quot;豪猪张&quot;);        BiFunction&lt;Integer,String,People&gt; bifun1 = People::new;        People p3 = bifun1.apply(21, &quot;豪张猪&quot;);    &#125;&#125;@AllConstructorclass People &#123;    int age;    String name;    </code></pre><h1 id="5-数组引用"><a href="#5-数组引用" class="headerlink" title="5.数组引用"></a>5.数组引用</h1><p>数组引用算是构造器引用的一种，可以引用一个数组的构造</p><pre><code>    Function&lt;Integer,People[]&gt; fun1 = p -&gt; new People[p];    People[] arr1 = fun1.apply(10);//创建一个长度为10的People数组        Function&lt;Integer,People[]&gt; fun2 = People[]::new;    fun2.apply(20);&#125;&#125;class People &#123;int age;String name;</code></pre><h1 id="区别与总结"><a href="#区别与总结" class="headerlink" title="区别与总结"></a>区别与总结</h1><h2 id="1-类型推断"><a href="#1-类型推断" class="headerlink" title="1.类型推断"></a>1.类型推断</h2><h3 id="编译看左"><a href="#编译看左" class="headerlink" title="编译看左"></a>编译看左</h3><p>有一个People的静态方法 public static void describe(Integer count) {。。}<br>则必须通过<code> Consumer &lt;Integer&gt; con = People::describe;</code><br>而不能 Consumer con = People::describe;<br>因为后者不能推断出con.accept()需要什么类型的参数</p><h3 id="泛型顺序对应形参顺序"><a href="#泛型顺序对应形参顺序" class="headerlink" title="泛型顺序对应形参顺序"></a>泛型顺序对应形参顺序</h3><p><strong>Function&lt;x,y&gt; fun = 是如何确定谁是形参谁是返回值的呢？</strong></p><ul><li>第一个是形参，第二个是返回值</li></ul><p><img src="https://img-blog.csdnimg.cn/9e28c69a2a504aab9f42270ab7060d65.png"></p><p>而此时因为一一对应，Function&lt;Integer,String&gt;一定是Integer为形参，String为返回值</p><ul><li>》》》当BiFunction&lt;T, U, R&gt; bifun= 时，R是返回值类型，T和U的顺序也已经固定<img src="https://img-blog.csdnimg.cn/25b2e7cf019843209f7785facc863f84.png"></li></ul><h2 id="2-能省则省"><a href="#2-能省则省" class="headerlink" title="2.能省则省"></a>2.能省则省</h2><p>凡是能唯一确定推断的都能省略</p><ul><li><code>(s) -&gt;&#123;return 一个语句&#125; </code>可写为<code> s -&gt; 一个语句</code></li></ul><h2 id="3-代码绑定"><a href="#3-代码绑定" class="headerlink" title="3.代码绑定"></a>3.代码绑定</h2><p>例如：</p><ul><li>Function&lt;Integer,String&gt; fun = p :: myHight<strong>就是把myHight()方法绑定给了fun.apply()</strong></li><li>Supplier<Integer> sup = () -&gt; {…..return i } ; <strong>则是把{…..return i }代码块绑定给sup.get()</strong></li></ul><h2 id="4-方法引用和lambda的联系"><a href="#4-方法引用和lambda的联系" class="headerlink" title="4.方法引用和lambda的联系"></a>4.方法引用和lambda的联系</h2><p>方法引用本质就是lambda表达式，只是在上一个例子中<code>Supplier&lt;Integer&gt; sup = () -&gt; &#123;.....return i &#125; ;</code>里面的<code>&#123;.....return i &#125; </code>如果是被封装到了某一个特定的方法，那么可以直接使用方法引用，而不需要把代码块的内容挨个写出来</p><h2 id="5-构造器引用和方法引用的联系"><a href="#5-构造器引用和方法引用的联系" class="headerlink" title="5.构造器引用和方法引用的联系"></a>5.构造器引用和方法引用的联系</h2><p>构造器引用本质是方法引用，<strong>方法体就是new 一个对象，并返回</strong>，因此形如：<img src="https://img-blog.csdnimg.cn/b26591439cf348949f684e757c2eb215.png"><br>但一定要有new</p><h2 id="6-数组引用和构造引用的联系"><a href="#6-数组引用和构造引用的联系" class="headerlink" title="6.数组引用和构造引用的联系"></a>6.数组引用和构造引用的联系</h2><p>之前的构造引用都是new一个对象，而数组引用是new一个数组，仅此而已，形如：<img src="https://img-blog.csdnimg.cn/7c49fdd38cdc4f15bf1fcc2fb2d6a460.png" alt="创建长度为20的People[] "></p><h1 id="forEach的lambda表达式"><a href="#forEach的lambda表达式" class="headerlink" title="forEach的lambda表达式"></a>forEach的lambda表达式</h1><p><a href="https://blog.csdn.net/shaoyangdd/article/details/78992497?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164946767416780271931413%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=164946767416780271931413&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-78992497.142%5Ev7%5Epc_search_result_cache,157%5Ev4%5Econtrol&utm_term=foreach%E7%9A%84lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F&spm=1018.2226.3001.4187">参考</a></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Mybatis中xml中调java方法OGNL表达式</title>
      <link href="/zjh/2022/04/21/Mybatis%E4%B8%ADxml%E4%B8%AD%E8%B0%83java%E6%96%B9%E6%B3%95OGNL%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
      <url>/zjh/2022/04/21/Mybatis%E4%B8%ADxml%E4%B8%AD%E8%B0%83java%E6%96%B9%E6%B3%95OGNL%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>一般在Mybatis中用#{}来防止sql注入，但是这种预编译的模式会导致无法调用java的方法，因此在系统安全性较高的情况下可以尝试使用${}来调用java方法进行数据处理</p><h1 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h1><ul><li><p>create_date是datetime类型<br>create_time是时间戳类型，但时间戳是13位的long型，这里是11位的int类型(int最大十进制长度)</p></li><li><p>前者没有索引，后者有索引（优势：字段短，索引更快，int比long占内存更小）</p></li><li><p>前者给DBA看，后者用于条件查询</p></li></ul><h1 id="使用OGNL表达式"><a href="#使用OGNL表达式" class="headerlink" title="使用OGNL表达式"></a>使用OGNL表达式</h1><p><a href="https://blog.csdn.net/huayu815/article/details/7446141">OGNL表达式参考</a></p><pre><code>  &lt;select id=&quot;mapper方法名&quot; resultType=&quot;Res对象&quot;&gt;    SELECT source, SUM(IF(type = 0, -amount, amount))    FROM 表    WHERE create_time &lt;![CDATA[ &lt;  ]]&gt; $&#123;endDateTime.toInstant(@java.time.ZoneOffset@of(&quot;+8&quot;)).toEpochMilli()/1000&#125;      AND create_time &lt;![CDATA[ &gt;= ]]&gt; $&#123;startDateTime.toInstant(@java.time.ZoneOffset@of(&quot;+8&quot;)).toEpochMilli()/1000&#125;    GROUP BY source  &lt;/select&gt;</code></pre><p>注：调静态方法时，类和方法都要加@；<br> /1000是为了让本身为long型的13位时间戳变成11位的int以便SELECT，<strong>且本身不是函数，不会导致索引失效</strong></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java注解和反射</title>
      <link href="/zjh/2022/04/21/Java%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/"/>
      <url>/zjh/2022/04/21/Java%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8F%8D%E5%B0%84/</url>
      
        <content type="html"><![CDATA[<h1 id="1-反射与Class类"><a href="#1-反射与Class类" class="headerlink" title="1.反射与Class类"></a>1.反射与Class类</h1><ul><li>Java本是静态语言，但反射提供了动态语言的特性，<strong>通过反射可以获得任意类的所有结构，并可以任意操作类内部的属性和方法</strong></li></ul><ul><li>类加载完毕后，<strong>堆空间中会出现唯一的Class对象</strong>，这个对象clazz包含了该类的所有结构</li><li>Class 对象是在加载类时由 Java 虚拟机以及通过调用<strong>类加载器</strong>中的defineClass 方法自动构造的</li><li>通过反射的方式获取对象效率远远不如直接new，当且仅当不能直接new对象的时候用反射创建对象，在主流框架中大量使用了反射<br><img src="https://img-blog.csdnimg.cn/2da4d89222d941138ef59e2298bb4e3b.png" alt="普通方法即直接new"></li></ul><h1 id="2-Class对象获取"><a href="#2-Class对象获取" class="headerlink" title="2.Class对象获取"></a>2.Class对象获取</h1><p>一个类的Class对象无论用什么方式获取多少次，都是唯一的</p><h2 id="new-目标类-getClass"><a href="#new-目标类-getClass" class="headerlink" title="new 目标类().getClass()"></a>new 目标类().getClass()</h2><ul><li>不建议这样使用，已经可以直接new了就不要再反射获取对象了</li><li>new Student()的同时也会在堆空间产生全局唯一的Student类对象</li></ul><pre><code>Student stu1 = new Student();//这一new 产生一个Student对象，一个Class对象。        Class stuClass = stu1.getClass();//获取Class对象        System.out.println(stuClass.getName());</code></pre><h2 id="目标类-class"><a href="#目标类-class" class="headerlink" title="目标类.class;"></a>目标类.class;</h2><p>这种方法也不推荐，需要额外在调用处导入目标类的包，依赖过强</p><pre><code>    //第二种方式获取Class对象    Class stuClass2 = Student.class;    </code></pre><h2 id="forName-方法——最常用"><a href="#forName-方法——最常用" class="headerlink" title="forName()方法——最常用"></a>forName()方法——最常用</h2><p>一般都第三种，一个字符串<strong>可以传入也可写在配置文件中等多种方法。</strong></p><pre><code>    //第三种方式获取Class对象    try &#123;        Class stuClass3 = Class.forName(&quot;com.fanshe.Student&quot;);//全类名路径    &#125; catch (ClassNotFoundException e) &#123;        e.printStackTrace();    &#125;</code></pre><h2 id="基本数据类型和包装类"><a href="#基本数据类型和包装类" class="headerlink" title="基本数据类型和包装类"></a>基本数据类型和包装类</h2><p>包装类.TYPE属性 相当于 基本数据类型.class属性</p><pre><code>    Class&lt;Integer&gt; c1 = int.class;    Class&lt;Integer&gt; c2 = Integer.TYPE;    System.out.println(c1==c2);//true</code></pre><p>源码<br>    @SuppressWarnings(“unchecked”)<br>    public static final Class<Integer>  TYPE = (Class<Integer>) Class.getPrimitiveClass(“int”);</p><h1 id="3-Class类常用方法"><a href="#3-Class类常用方法" class="headerlink" title="3.Class类常用方法"></a>3.Class类常用方法</h1><h2 id="3-1静态方法"><a href="#3-1静态方法" class="headerlink" title="3.1静态方法"></a>3.1静态方法</h2><h3 id="获取目标类的Class对象"><a href="#获取目标类的Class对象" class="headerlink" title="获取目标类的Class对象"></a>获取目标类的Class对象</h3><p><img src="https://img-blog.csdnimg.cn/8bfe66ffbeda44339ce388b2b1b37ac6.png"></p><h2 id="3-2非静态方法"><a href="#3-2非静态方法" class="headerlink" title="3.2非静态方法"></a>3.2非静态方法</h2><p>对于：Class c1 = Class.forName(“com.zjh.User”);</p><h3 id="获取目标类实例"><a href="#获取目标类实例" class="headerlink" title="获取目标类实例"></a>获取目标类实例</h3><pre><code>c1.newInstance()</code></pre><h3 id="获取目标类全类名路径"><a href="#获取目标类全类名路径" class="headerlink" title="获取目标类全类名路径"></a>获取目标类全类名路径</h3><pre><code>c1,getName()</code></pre><h3 id="获取父类的Class对象"><a href="#获取父类的Class对象" class="headerlink" title="获取父类的Class对象"></a>获取父类的Class对象</h3><pre><code> c1.getSuperClass().getSuperClass()....可以一直链路向上调用</code></pre><h3 id="获取类的方法Method对象，invoke激活"><a href="#获取类的方法Method对象，invoke激活" class="headerlink" title="获取类的方法Method对象，invoke激活"></a>获取类的方法Method对象，invoke激活</h3><p>不加Declared的getMethods()<strong>包括父类的方法</strong><br><img src="https://img-blog.csdnimg.cn/d180e2460a1a4be2acf80c2e395e458e.png"></p><p>先获取Method对象（无参可以不填or填null），然后invoke调用方法</p><pre><code>    Class c1 = Class.forName(&quot;filter.User&quot;);        Method tell = c1.getMethod(&quot;tell&quot;, String.class);    Object content = tell.invoke(new User(), &quot;说话内容&quot;);    System.out.println(content);//null无返回值</code></pre><h3 id="获取类的构造器"><a href="#获取类的构造器" class="headerlink" title="获取类的构造器"></a>获取类的构造器</h3><p><strong><code>没有形参的就是获取所有,注意是否为s结尾复数，形参列表是Class对象； 没有Declared的就是只获取public修饰的</code></strong></p><ul><li><strong>批量</strong>的方法：返回数组<br>   public Constructor[] **getConstructors()**：所有”<strong>公有的</strong>“构造方法<pre><code>      public Constructor[] **getDeclaredConstructors()**：获取**所有**的构造方法(包括私有、受保护、默认、公有)</code></pre></li><li><strong>单个</strong>的方法，并调用：<br>  public Constructor getConstructor(**Class… parameterTypes **):获取单个的”<strong>公有的</strong>“构造方法：<br>  public Constructor getDeclaredConstructor(<strong>Class… parameterTypes</strong>):获取”某个构造方法”可以是私有的，或受保护、默认、公有；</li></ul><p><code>调用时使用使用newInstance()</code></p><pre><code>    Class c1 = Class.forName(&quot;filter.User&quot;);    Constructor constructor = c1.getConstructor(String.class, int.class);    Object u = constructor.newInstance(&quot;牛逼&quot;, 12);    System.out.println(u);</code></pre><h3 id="获取类的属性"><a href="#获取类的属性" class="headerlink" title="获取类的属性"></a>获取类的属性</h3><p><strong><code>没有形参的就是获取所有,注意是否为s结尾复数，形参是String类型即指定获取某属性； 没有Declared的就是只获取public修饰的</code></strong></p><ul><li>批量的：<br>Field[] getFields():获取所有的”<strong>公有</strong>属性”,<strong>包括父类</strong><br>Field[] get<strong>Declared</strong>Fields():获取所有字段，包括：私有、受保护、默认、公有；</li><li>获取单个的：<br>public Field getField(<strong>String</strong> fieldName):获取某个”公有的”字段；<br>public Field getDeclaredField(<strong>String</strong> fieldName):获取某个字段(可以是私有的)</li></ul><p>————————————————————————————————————</p><p>如果使用getField(“name”)会由于<strong>私有属性</strong>抛java.lang.NoSuchFieldException: name</p><p>如果使用 Field name =c1.getDeclaredField(“name”);但是如果不  <strong><code>name.setAccessible(true);</code></strong> 就会抛异常<br>java.lang.IllegalAccessException</p><h3 id="获取类的加载器"><a href="#获取类的加载器" class="headerlink" title="获取类的加载器"></a>获取类的加载器</h3><p>类的加载器分为：</p><p>c1.getClassLoader()</p><h1 id="4-反射获取注解信息"><a href="#4-反射获取注解信息" class="headerlink" title="4.反射获取注解信息"></a>4.反射获取注解信息</h1><h2 id="4-1自定义注解"><a href="#4-1自定义注解" class="headerlink" title="4.1自定义注解"></a>4.1自定义注解</h2><pre><code>@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface MyValue &#123;    //给字段赋值    String value();&#125;@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface MyTable &#123;    //表名    String value();&#125;@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Inheritedpublic @interface MyController &#123;    //URL    String value();&#125;@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface MyColumn &#123;    //字段名绑定    String value();&#125;</code></pre><h2 id="4-2待绑定的Bean"><a href="#4-2待绑定的Bean" class="headerlink" title="4.2待绑定的Bean"></a>4.2待绑定的Bean</h2><pre><code>@MyTable(&quot;table_people&quot;)public class PeopleBean &#123;    @MyValue(&quot;zjh&quot;)    @MyColumn(&quot;xx_name&quot;)    private String name;    @MyValue(&quot;18&quot;)    @MyColumn(&quot;xx_age&quot;)    private int age;    @Override    public String toString() &#123;        return &quot;PeopleBean&#123;&quot; +                &quot;name=&#39;&quot; + name + &#39;\&#39;&#39; +                &quot;, age=&quot; + age +                &#39;&#125;&#39;;    &#125;&#125;</code></pre><h2 id="4-3测试"><a href="#4-3测试" class="headerlink" title="4.3测试"></a>4.3测试</h2><pre><code>@MyController(&quot;/com/baidu/www&quot;)public class MyTest &#123;    public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException &#123;        //1.获取当前URL        Class&lt;MyTest&gt; c1 = MyTest.class;        MyController anno1 = c1.getAnnotation(MyController.class);        String value1 = anno1.value();        System.out.println(&quot;当前URL是：&quot; + value1);        //2.反射获取PeopleBean，并用@value对其赋值        Class c2 = Class.forName(&quot;filter.PeopleBean&quot;);        PeopleBean people= (PeopleBean)c2.newInstance();        //3.PeopleBean直接获取的注解只有@MyTable        Annotation[] annotations = c2.getDeclaredAnnotations();        System.out.println(&quot;类级别的注解数：&quot;+annotations.length);//1        //4.获取类中所有不包括父类的属性        Field[] fields = c2.getDeclaredFields();        for (Field f : fields) &#123;            //@MyColumn绑定的字段信息            MyColumn column = f.getDeclaredAnnotation(MyColumn.class);            System.out.println(f.getName() + &quot;绑定的表字段是：&quot; + column.value());            //@MyValue赋值操作            MyValue Myvalue = f.getAnnotation(MyValue.class);            String toValue = Myvalue.value();            f.setAccessible(true);            //对@MyValue目标绑定数据类型进行判断并赋值            if(f.getType().getName().equals(&quot;int&quot;))&#123;//判断属性是否是int类型                f.set(people, Integer.parseInt(toValue));            &#125;else&#123;                f.set(people, toValue);            &#125;        &#125;        System.out.println(people);    &#125;&#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/e5c480a0846449ed9e23501be167923f.png"></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>HashMap中entrySet()详解</title>
      <link href="/zjh/2022/03/21/HashMap%E4%B8%ADentrySet-%E8%AF%A6%E8%A7%A3/"/>
      <url>/zjh/2022/03/21/HashMap%E4%B8%ADentrySet-%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<p>本文能解决的疑惑：</p><ol><li><strong>idea在debug时偷偷调用toString方法</strong>，在HashMap追源码时产生的疑惑</li><li><strong>HashMap的entrySet()和keySet()方法真的创建了一个存满数据的set对象吗</strong>？</li><li><strong>内部类：EntrySet类没有构造器，那它是怎么初始化的呢？</strong></li><li>为什么集合框架中一定要<strong>利用好迭代器iterator()来获取入口</strong>？</li><li>entrySet().size()获取的值是该set的实际大小吗？</li><li>……</li></ol><h1 id="entrySet-和keySet-详解"><a href="#entrySet-和keySet-详解" class="headerlink" title="entrySet()和keySet()详解"></a>entrySet()和keySet()详解</h1><ul><li>entrySet()和keySet()方法都是返回一个set对象，并且在debug时也能看到set的值和size；但是源码中<strong>并没有利用构造器</strong>对其初始化。</li><li>在此文中以entrySet()举例，来阐述entrySet和keySet的生命周期</li></ul><h2 id="测试代码示例，并提出问题"><a href="#测试代码示例，并提出问题" class="headerlink" title="测试代码示例，并提出问题"></a>测试代码示例，并提出问题</h2><pre><code>    HashMap hs = new HashMap();    hs.put(&quot;啊啊&quot;, &quot;2&quot;);    hs.put(&quot;2&quot;, &quot;2&quot;);    hs.put(&quot;3&quot;, &quot;2&quot;);    hs.put(&quot;4&quot;, &quot;2&quot;);    hs.put(&quot;5&quot;, &quot;2&quot;);    hs.put(&quot;6&quot;, &quot;2&quot;);    hs.put(&quot;7&quot;, &quot;2&quot;);    hs.put(&quot;8&quot;, &quot;2&quot;);    hs.put(&quot;9&quot;, &quot;2&quot;);    Set entrySet = hs.entrySet();//1.获取entrySet对象    System.out.println(entrySet );//2.结果：正确输出了上面put的内容    Object[] objects = entrySet .toArray();    System.out.println(objects[3]);//3.结果：正确打印了5=2    Iterator iterator = entrySet .iterator();//4.获取迭代器    while (iterator.hasNext())&#123;//5.迭代器遍历        Map.Entry next = (Map.Entry) iterator.next();        next.getKey();        next.getValue();    &#125;</code></pre><ul><li>如果在idea中使用debug对<code>Set entrySet = hs.entrySet()</code>打断点，你会发现即便是没有运行到第二步，<strong>debug信息栏中已然出现了该set全部的内容。</strong></li><li>跟着debug一直step into进行分析，发现并没有任何一个方法对entrySet对象进行过赋值，那么hashMap对象中的内容是如何进入到entrySet中的呢？</li></ul><h2 id="1-debug分析"><a href="#1-debug分析" class="headerlink" title="1 debug分析"></a>1 debug分析</h2><h3 id="new-EntrySet"><a href="#new-EntrySet" class="headerlink" title="new EntrySet()"></a>new EntrySet()</h3><ol><li>没有找到构造函数</li></ol><p><img src="https://img-blog.csdnimg.cn/08ff8cd5337849618e6dfc90c22b84a5.png"></p><ol start="2"><li>AbstractSet中只有一个空参且空函数体的方法</li></ol><p><img src="https://img-blog.csdnimg.cn/8cc53005bae44722845836798f466b1e.png"></p><h3 id="第一个结论：entrySet是空对象"><a href="#第一个结论：entrySet是空对象" class="headerlink" title="第一个结论：entrySet是空对象"></a>第一个结论：entrySet是空对象</h3><p>entrySet只是new出来了，但它是一个没有内容的空对象。</p><h2 id="2第二个问题：entrySet对象调用方法时为何有值？"><a href="#2第二个问题：entrySet对象调用方法时为何有值？" class="headerlink" title="2第二个问题：entrySet对象调用方法时为何有值？"></a>2第二个问题：entrySet对象调用方法时为何有值？</h2><p>既然    <code> Set entrySet = hs.entrySet()</code>出来的entrySet 对象是个空对象，那为何<code>System.out.println(entrySet );</code><br><code>Object[] objects = entrySet .toArray();</code><br><code>  Iterator iterator = entrySet .iterator()</code><br>对entrySet对象进行调用方法的时候却能正确的执行呢？</p><h2 id="2-源码分析"><a href="#2-源码分析" class="headerlink" title="2 源码分析"></a>2 源码分析</h2><h3 id="toString方法"><a href="#toString方法" class="headerlink" title="toString方法"></a>toString方法</h3><p><code>System.out.println(entrySet );</code>  显然调用的是toString方法；</p><ul><li>在2.5中的源码可知entrySet对象继承于<code>AbstractSet</code>类，间接实现了<code>AbstractCollection</code>接口</li><li><strong>重写的</strong>toString()方法调用了<code>this.iterator()</code>即EntrySet类的iterator()方法进行输出</li></ul><p><img src="https://img-blog.csdnimg.cn/62ee4cb2c23940579532b0b9816bba61.png"></p><h3 id="iterator方法"><a href="#iterator方法" class="headerlink" title="iterator方法"></a>iterator方法</h3><ol><li><p>我们发现HashMap中的内部类EntrySet中重写了iterator()方法，<strong>实际调用的是EntryIterator对象</strong><br><img src="https://img-blog.csdnimg.cn/e7a3d92938864dbfa739efcbe0412b7f.png"></p></li><li><p>EntryIterator类继承于HashIterator类 ：nextNode方法是HashIterator中的方法<br><img src="https://img-blog.csdnimg.cn/03f2e6ca1f0b4351bd1f8e8874207bb6.png" alt="EntryIterator"></p></li><li><p>跟进nextNode方法，框体内容是指针的变化的判断细节，不是本论题的重点</p></li></ol><p><img src="https://img-blog.csdnimg.cn/66322df3e3be43ac834ef9674557c2c1.png"><br>由此可知：</p><p>这个EntrySet类重写的iterator()方法可以使得指针<strong>正确得指向下一个节点</strong>..</p><h3 id="toArray方法"><a href="#toArray方法" class="headerlink" title="toArray方法"></a>toArray方法</h3><ul><li>测试代码中也正确输出了toArray()的结果，同样的，这个方法也是重写在其父类<code>AbstractCollection</code>中的</li><li>同理，其底层实现还是调用了iterator()，利用HashIterator类中的nextNode()方法对指针进行下移</li></ul><p><img src="https://img-blog.csdnimg.cn/21842f3c7f454b26aea052afb93d4961.png"></p><h3 id="size、clear方法"><a href="#size、clear方法" class="headerlink" title="size、clear方法"></a>size、clear方法</h3><p>这两个方法很简单，就是直接用的当前HashMap对象的属性和方法<br><img src="https://img-blog.csdnimg.cn/ddae87f117b94c039337ca30b8df092a.png"><br><strong>hashMap.entrySet().size()的大小并不是真正这个entrySet对象的大小，而是调用了size属性的fake size</strong></p><h2 id="3小总结"><a href="#3小总结" class="headerlink" title="3小总结"></a>3小总结</h2><ul><li>entrySet()和keySet()都是<strong>懒汉式</strong>，调用方法，<strong>new对象的时候并没有对其进行赋值</strong>,并且其size()方法也是一个虚假的size</li><li>而是在使用hashMap.entrySet().**toString()**、hashMap.entrySet(). <strong>toArray()</strong> 等方法的时候才<code>调用iterator()来获取迭代器</code></li><li>EntrySet类和KeySet类也都<strong>没有构造器能进行初始化</strong></li><li>不得不说HashMap的设计十分精巧，entrySet()表面上获取了一个set对象，实际上这个set对象是空的，<strong>几乎所有的方法都是先直接获取迭代器入口</strong>，<strong>节约内存的同时性能大幅提升</strong></li></ul><h2 id="补充：putVal-方法和entrySet-无关"><a href="#补充：putVal-方法和entrySet-无关" class="headerlink" title="补充：putVal()方法和entrySet()无关"></a>补充：putVal()方法和entrySet()无关</h2><p>在翻阅资料的时候看到很多人说是putVal()方法中调用了resize()来维护了entrySet(),在看完源码之后才会发现这种说法是没有根据的。</p><p>resize()放是扩容的方法，代码中也没有出现任何的跟EntrySet相关的逻辑</p><h2 id="4关于idea在debug时的问题"><a href="#4关于idea在debug时的问题" class="headerlink" title="4关于idea在debug时的问题"></a>4关于idea在debug时的问题</h2><p><a href="https://blog.csdn.net/lkforce/article/details/90479650">参考</a></p><ul><li>DEA在debug时，当debug到某个对象时，会调用对象的toString()方法，用来在debug界面显示对象信息。</li><li>IDEA调用toString()方法时，即使在toString()方法中设置了断点，该断点也不会被触发，也就是说，开发者多数情况下不会知道toString()方法被调用了。</li><li>多数情况下调用一下toString()方法没有什么问题，但是也有例外，<code>比如重写了toString()方法的类，随意的调用toString()方法会导致未知的问题</code>。<strong>本案例就是因为重写toString()方法而产生了问题</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HashMap</title>
      <link href="/zjh/2022/03/21/HashMap/"/>
      <url>/zjh/2022/03/21/HashMap/</url>
      
        <content type="html"><![CDATA[<p>参考链接</p><p><a href="https://www.bilibili.com/video/BV1FE411t7M7?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV1FE411t7M7?spm_id_from=333.999.0.0</a><br><a href="https://www.html.cn/qa/other/20583.html">https://www.html.cn/qa/other/20583.html</a><br><a href="https://blog.csdn.net/weixin_41105242/article/details/106972635">https://blog.csdn.net/weixin_41105242/article/details/106972635</a><br><a href="https://blog.csdn.net/fan2012huan/article/details/51087722">https://blog.csdn.net/fan2012huan/article/details/51087722</a><br><a href="https://segmentfault.com/q/1010000012304833">https://segmentfault.com/q/1010000012304833</a><br>………等等等等</p><ul><li>本文其中有一个邪门问题（entrySet和keySet方法的生命周期），作者花了十几个小时，查遍了国内外很多资料最后才总结的</li><li><strong>与其他面试题相比</strong>，本文能解决的疑惑（第3个大标题）：</li></ul><ol><li><strong>idea在debug时偷偷调用toString方法</strong>，在HashMap追源码时产生的疑惑</li><li><strong>HashMap的entrySet()和keySet()方法真的创建了一个存满数据的set对象吗</strong>？</li><li><strong>内部类：EntrySet类没有构造器，那它是怎么初始化的呢？</strong></li><li>为什么集合框架中一定要<strong>利用好迭代器iterator()来获取入口</strong>？</li><li>entrySet().size()获取的值是该set的实际大小吗？</li><li>……</li></ol><h1 id="1-数据结构"><a href="#1-数据结构" class="headerlink" title="1.数据结构"></a>1.数据结构</h1><ul><li>1.7中是：数组+单链表——头插法(多线程写可能死循环)</li></ul><p>1.8中是：数组+单链表——尾插法 + 红黑树</p><ul><li>数组默认初始大小16，负载因子默认0.75(泊松分布下的折中最佳值)<h2 id="JDK1-7：数组-单向链表"><a href="#JDK1-7：数组-单向链表" class="headerlink" title="JDK1.7：数组+单向链表"></a>JDK1.7：数组+单向链表</h2><h3 id="Q：为什么使用单向链表而不使用双向链表？"><a href="#Q：为什么使用单向链表而不使用双向链表？" class="headerlink" title="Q：为什么使用单向链表而不使用双向链表？"></a>Q：为什么使用单向链表而不使用双向链表？</h3>插入新数据or查询的时候需要<strong>遍历相同桶中的所有元素</strong>，来确保和相同hash值的所有元素调用equals方法进行比对</li></ul><h3 id="Q：头插法会出现什么问题？"><a href="#Q：头插法会出现什么问题？" class="headerlink" title="Q：头插法会出现什么问题？"></a>Q：头插法会出现什么问题？</h3><p><strong>并发下：同时扩容可能出现死循环：</strong></p><p><a href="https://blog.csdn.net/gongsenlin341/article/details/112582217">图解</a></p><h2 id="JDK1-8：数组-单向链表-红黑树"><a href="#JDK1-8：数组-单向链表-红黑树" class="headerlink" title="JDK1.8：数组+单向链表+红黑树"></a>JDK1.8：数组+单向链表+红黑树</h2><h3 id="Q：为什么选择红黑树"><a href="#Q：为什么选择红黑树" class="headerlink" title="Q：为什么选择红黑树"></a>Q：为什么选择红黑树</h3><ul><li>红黑树是一个绝对平衡的二叉树，插入、删除、查询的效果都比较平衡；</li><li>单向链表过长则会导致效率降低</li><li>而选择二叉树则可能在极端情况下成为链表；</li></ul><h3 id="Q：单链表什么时候转红黑树"><a href="#Q：单链表什么时候转红黑树" class="headerlink" title="Q：单链表什么时候转红黑树"></a>Q：单链表什么时候转红黑树</h3><ul><li><strong>当同时满足</strong>：链表长度&gt;=8   且    底层数组长度&gt;=64</li><li>底层数组长度不足64时，选择<strong>扩容</strong>来解决链表过长问题；</li></ul><h3 id="Q：JDK1-8使用尾插法"><a href="#Q：JDK1-8使用尾插法" class="headerlink" title="Q：JDK1.8使用尾插法"></a>Q：JDK1.8使用尾插法</h3><ul><li>防止了头插法在并发扩容场景下可能出现的死循环</li></ul><h3 id="Q：底层数组的元素存储的是值还是节点？"><a href="#Q：底层数组的元素存储的是值还是节点？" class="headerlink" title="Q：底层数组的元素存储的是值还是节点？"></a>Q：底层数组的元素存储的是值还是节点？</h3><p>底层数组本身上面存储的是Node implements Map.Entry节点，有一个<strong>next指针指向下链表or红黑树的root节点</strong></p><h1 id="2-源码解析"><a href="#2-源码解析" class="headerlink" title="2.源码解析"></a>2.源码解析</h1><h2 id="2-1-成员变量"><a href="#2-1-成员变量" class="headerlink" title="2.1 成员变量"></a>2.1 成员变量</h2><h3 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h3><p><img src="https://img-blog.csdnimg.cn/ca265c7f68b84bb78d094ff0ac5897eb.png"></p><ol><li>JDK7中使用的是Map.Entry存储键值对， JDK8中Node实际上只是Entry的一个套壳<br><img src="https://img-blog.csdnimg.cn/eea7d21b83f242d4acc93a294b4baa0b.png" alt="JDK8中的Node节点"></li></ol><ol start="2"><li>TreeNode就是红黑树的节点类</li></ol><h3 id="成员变量"><a href="#成员变量" class="headerlink" title="成员变量"></a>成员变量</h3><p>约定前面的数组结构的每一个格格称为<strong>桶</strong><br>约定桶后面存放的每一个数据称为<strong>bin</strong><br>bin这个术语来自于JDK 1.8的HashMap注释。</p><p><img src="https://img-blog.csdnimg.cn/53048b3d7eb7400cad0f7c4fb48eeaf6.png"><br>由图可知：</p><ol><li>实现了序列化机制</li><li>1&lt;&lt;&lt;4 位左移4，相当于2^4 = 16，默认底层数组容量是16</li><li>1&lt;&lt;&lt;30 位左移30，相当于2^30 ，即最大底层数组容量</li><li>默认加载因子：0.75，这个数是泊松分布下的折中最佳值：假设底层数组长度是默认值16，当桶数量 &gt;= 16*0.75 = 12时，则扩容</li><li>单链表最大长度=8 ， 超过8则扩容 or 转红黑树</li><li>当底层数组长&gt;=64时，才会选择生成红黑树，否则扩容</li><li>table即底层数组本身存储的是Node&lt;K,V&gt;节点，链表or红黑树的root节点只是被Node.next指向而已，他们本身不存储在table数组中</li><li>entrySet：获取所有元素的set集合（具体过程在后面有）</li><li>size：注意区分capacity（数组长度），**<code>size</code>是实际k-v对的个数<strong>；</strong><code>capacity</code>是数组长度；<code>threshold</code> = capacity * loadFactory是扩容临界域**</li><li>modCount：记录HashMap被修改的次数，Put、Clear等修改操作都会++modCount。并且各种操作都会判断modCount的值是否改变，以在并发场景下抛出异常。</li><li>threshold：扩容临界域，桶数量超过该值则扩容</li><li>loadFactor：负载因子(加载因子)：默认0.75，也可在构造函数中设置。0.75并不是统计学上的最佳，这跟不同的计算机也有关，而是JDK取了一个折中的值。</li></ol><h2 id="2-2-常用方法"><a href="#2-2-常用方法" class="headerlink" title="2.2 常用方法"></a>2.2 常用方法</h2><h3 id="put方法"><a href="#put方法" class="headerlink" title="put方法"></a>put方法</h3><p>put方法实际调用的是putVal：这个方法会<strong>计算hash值</strong>、**++modCount计数器<strong>、</strong>哈希碰撞的处理(链表or红黑树)<strong>、</strong>判断添加之后是否需要扩容**</p><p><img src="https://img-blog.csdnimg.cn/3917fbde500544c185547ae87abb3e55.png"></p><p>Q：<strong>这里为什么是<code>元素总数size</code> &gt; threshold 而不是 已使用的桶的数量 &gt; <code>threshold扩容边界值</code> 呢？</strong></p><h3 id="补：size、threshold、桶的使用个数"><a href="#补：size、threshold、桶的使用个数" class="headerlink" title="补：size、threshold、桶的使用个数"></a>补：size、threshold、桶的使用个数</h3><ul><li>首先，JDK源码中并没有给出<strong>桶的使用个数这个filed</strong>，只给出了threshold临界阈：例如initCapacity = 16  ，那么threshold = 12 。</li><li>size是所有元素的个数，查看JDK源码的put方法可知：<strong>只要size&gt;桶临界阈threshold，就会进行扩容resize()。</strong></li><li>因此可能存在一种<code>极端情况</code>：16个桶(capacity=16)，极端的哈希碰撞只使用了两个桶(一个桶7个元素，另一个桶6个元素)，<strong>但是size &gt; 12 ，扩容。</strong></li></ul><h3 id="hash值计算"><a href="#hash值计算" class="headerlink" title="hash值计算"></a>hash值计算</h3><p>我们在put方法中可以看到，调用了hash()方法，这个哈希方法首先计算出 key 的 hashCode 赋值给 h，然后与 h 无符号右移 16 位后的二进制进行按位异或得到最后的 hash 值<img src="https://img-blog.csdnimg.cn/4de59ef156ba4419b958f45db5289706.png" alt="hash()源码"></p><h3 id="补：为什么capacity必须是2-n"><a href="#补：为什么capacity必须是2-n" class="headerlink" title="补：为什么capacity必须是2^n"></a>补：为什么capacity必须是2^n</h3><ul><li>首先为了提高性能，JDK中大量使用了<code>位运算</code>，比如在计算hash值的时候，利用按位与hash&amp;(cap-1)，一个数如7（0111）的cap-1就是（0110）。那么最后一位数的按位与始终是0</li><li>而一个数如8（1000）的cap-1就是（0111），低位都是1，按位与不容易出现哈希碰撞</li><li>总之：<strong>2的n次幂 - 1 的二进制码<code>低位全部都是1</code>，于hash值<code>相与</code>时不会改变hash的低位值，因此减少了碰撞的概率</strong></li></ul><p><img src="https://img-blog.csdnimg.cn/a5a7b162aedd4b4c8ba269083074ad4b.png" alt="引用"></p><h3 id="补：JDK如何做到扩容时保持capacity-2-n？"><a href="#补：JDK如何做到扩容时保持capacity-2-n？" class="headerlink" title="补：JDK如何做到扩容时保持capacity=2^n？"></a>补：JDK如何做到扩容时保持capacity=2^n？</h3><p>底层也是用了位运算，效果就是：扩容后的是最接近的2^n<br><img src="https://img-blog.csdnimg.cn/772af8d5b2064ee8a4dfa338fba55fbb.png"></p><h3 id="扩容时调用的resize-方法"><a href="#扩容时调用的resize-方法" class="headerlink" title="扩容时调用的resize()方法"></a>扩容时调用的resize()方法</h3><ul><li>扩容是一个非常耗费资源的操作，并且在JDK7版本需要对所有元素进行hash值重新计算</li><li>JDK8引入了新的算法rehash（这不是一个JDK方法，这是一个算法），在rehash算法下，可以<strong>让一部分元素待在原索引处，另一部分元素 索引 += 新增的容量数</strong></li></ul><h3 id="remove删除"><a href="#remove删除" class="headerlink" title="remove删除"></a>remove删除</h3><ul><li>如果删除后该桶处的红黑树节点&lt;=8，则红黑树转为单链表</li><li>删除也是先算hash定位，然后遍历红黑树or单链表</li></ul><p>同理get()方法也是先算hash定位，后在桶中遍历</p><h2 id="2-3遍历的方法"><a href="#2-3遍历的方法" class="headerlink" title="2.3遍历的方法"></a>2.3遍历的方法</h2><p>一般情况下都是使用迭代器，迭代器的效率最高，<strong>阿里开发手册指出：第三种方法会遍历两次</strong></p><p><img src="https://img-blog.csdnimg.cn/479cc4d297a54082b9a15b9bf5996c10.png" alt="三种方法"></p><h2 id="2-4迭代器原理"><a href="#2-4迭代器原理" class="headerlink" title="2.4迭代器原理"></a>2.4迭代器原理</h2><p>可以自己写一个，然后跟着debug</p><pre><code>    Set set = hs.entrySet();//重点关注entrySet怎么来的    Iterator iterator = set.iterator();    while (iterator.hasNext())&#123;        Map.Entry next = (Map.Entry) iterator.next();        next.getKey();        next.getValue();    &#125;</code></pre><h3 id="iterator-next-方法"><a href="#iterator-next-方法" class="headerlink" title="iterator.next()方法"></a>iterator.next()方法</h3><ol><li>调用next()方法相当于调用Iterator接口中的nextNode()方法</li></ol><p><img src="https://img-blog.csdnimg.cn/e154e4ee1c714bf982fa0db3e1fe159d.png"></p><ol start="2"><li>在HashIterator类中查看nextNode()方法<br><img src="https://img-blog.csdnimg.cn/7c5b225f1a9f4f4f95e9fb0c620fe401.png" alt="1"><br><img src="https://img-blog.csdnimg.cn/d0bdaec1ce2d419984ccac8351df38c0.png" alt="2"></li></ol><h2 id="2-5-entrySet-、keySet-是如何获取Set的？"><a href="#2-5-entrySet-、keySet-是如何获取Set的？" class="headerlink" title="2.5 entrySet()、keySet()是如何获取Set的？"></a>2.5 entrySet()、keySet()是如何获取Set的？</h2><ul><li>总所周知HashMap的底层是数组+链表+红黑树</li><li>并且<strong>put方法中并没有同时构造一个entrySet、keySet</strong></li><li>那么hashMap.entrySet()为何就能直接获取entry键值对的Set集合的呢？</li></ul><p>我们以keySet()方法为例：</p><p>调用keySet()方法会 new一个keySet类对象</p><pre><code>public Set&lt;K&gt; keySet() &#123;    Set&lt;K&gt; ks = keySet;    if (ks == null) &#123;        ks = new KeySet();//1.调用keySet()方法时就new一个KeySet对象        keySet = ks;    &#125;    return ks;&#125;//2.但是KeySet类中并没有一个构造方法来使得keySet被赋值final class KeySet extends AbstractSet&lt;K&gt; &#123;//3.有的也只是重写了size()方法，返回的是当前hashMap的size    public final int size()                 &#123; return size; &#125;    public final void clear()               &#123; HashMap.this.clear(); &#125;    //4.并且初始化时也没有调用迭代器    public final Iterator&lt;K&gt; iterator()     &#123; return new KeyIterator(); &#125;    public final boolean contains(Object o) &#123; return containsKey(o); &#125;    public final boolean remove(Object key) &#123;        return removeNode(hash(key), key, null, false, true) != null;    &#125;    public final Spliterator&lt;K&gt; spliterator() &#123;        return new KeySpliterator&lt;&gt;(HashMap.this, 0, -1, 0, 0);    &#125;    //5.更没有调用forEach方法    public final void forEach(Consumer&lt;? super K&gt; action) &#123;        Node&lt;K,V&gt;[] tab;        if (action == null)            throw new NullPointerException();        if (size &gt; 0 &amp;&amp; (tab = table) != null) &#123;            int mc = modCount;            for (int i = 0; i &lt; tab.length; ++i) &#123;                for (Node&lt;K,V&gt; e = tab[i]; e != null; e = e.next)                    action.accept(e.key);            &#125;            if (modCount != mc)                throw new ConcurrentModificationException();        &#125;    &#125;&#125;</code></pre><p>然后我们去KeySet的父类，发现只有一个空参的空构造器，那么entrySet()和keySet()方法在调用的时候，到底是如何赋值的呢？<br><img src="https://img-blog.csdnimg.cn/e521350cff3a417482a83affd20fc406.png"></p><h1 id="3-entrySet-和keySet-详解"><a href="#3-entrySet-和keySet-详解" class="headerlink" title="3.entrySet()和keySet()详解"></a>3.entrySet()和keySet()详解</h1><ul><li>前面已经提到，entrySet()和keySet()方法都是返回一个set对象，并且在debug时也能看到set的值和size；但是源码中<strong>并没有利用构造器</strong>对其初始化。</li><li>在此文中以entrySet()举例，来阐述entrySet和keySet的生命周期</li></ul><h2 id="3-1测试代码示例，并提出问题"><a href="#3-1测试代码示例，并提出问题" class="headerlink" title="3.1测试代码示例，并提出问题"></a>3.1测试代码示例，并提出问题</h2><pre><code>    HashMap hs = new HashMap();    hs.put(&quot;啊啊&quot;, &quot;2&quot;);    hs.put(&quot;2&quot;, &quot;2&quot;);    hs.put(&quot;3&quot;, &quot;2&quot;);    hs.put(&quot;4&quot;, &quot;2&quot;);    hs.put(&quot;5&quot;, &quot;2&quot;);    hs.put(&quot;6&quot;, &quot;2&quot;);    hs.put(&quot;7&quot;, &quot;2&quot;);    hs.put(&quot;8&quot;, &quot;2&quot;);    hs.put(&quot;9&quot;, &quot;2&quot;);    Set entrySet = hs.entrySet();//1.获取entrySet对象    System.out.println(entrySet );//2.结果：正确输出了上面put的内容    Object[] objects = entrySet .toArray();    System.out.println(objects[3]);//3.结果：正确打印了5=2    Iterator iterator = entrySet .iterator();//4.获取迭代器    while (iterator.hasNext())&#123;//5.迭代器遍历        Map.Entry next = (Map.Entry) iterator.next();        next.getKey();        next.getValue();    &#125;</code></pre><ul><li>如果在idea中使用debug对<code>Set entrySet = hs.entrySet()</code>打断点，你会发现即便是没有运行到第二步，<strong>debug信息栏中已然出现了该set全部的内容。</strong></li><li>跟着debug一直step into进行分析，发现并没有任何一个方法对entrySet对象进行过赋值，那么hashMap对象中的内容是如何进入到entrySet中的呢？</li></ul><h2 id="3-1-debug分析"><a href="#3-1-debug分析" class="headerlink" title="3.1 debug分析"></a>3.1 debug分析</h2><h3 id="new-EntrySet"><a href="#new-EntrySet" class="headerlink" title="new EntrySet()"></a>new EntrySet()</h3><ol><li>没有找到构造函数</li></ol><p><img src="https://img-blog.csdnimg.cn/08ff8cd5337849618e6dfc90c22b84a5.png"></p><ol start="2"><li>AbstractSet中只有一个空参且空函数体的方法</li></ol><p><img src="https://img-blog.csdnimg.cn/8cc53005bae44722845836798f466b1e.png"></p><h3 id="第一个结论：entrySet是空对象"><a href="#第一个结论：entrySet是空对象" class="headerlink" title="第一个结论：entrySet是空对象"></a>第一个结论：entrySet是空对象</h3><p>entrySet只是new出来了，但它是一个没有内容的空对象。</p><h2 id="3-2第二个问题：entrySet对象调用方法时为何有值？"><a href="#3-2第二个问题：entrySet对象调用方法时为何有值？" class="headerlink" title="3.2第二个问题：entrySet对象调用方法时为何有值？"></a>3.2第二个问题：entrySet对象调用方法时为何有值？</h2><p>既然    <code> Set entrySet = hs.entrySet()</code>出来的entrySet 对象是个空对象，那为何<code>System.out.println(entrySet );</code><br><code>Object[] objects = entrySet .toArray();</code><br><code>  Iterator iterator = entrySet .iterator()</code><br>对entrySet对象进行调用方法的时候却能正确的执行呢？</p><h2 id="3-2-源码分析"><a href="#3-2-源码分析" class="headerlink" title="3.2 源码分析"></a>3.2 源码分析</h2><h3 id="toString方法"><a href="#toString方法" class="headerlink" title="toString方法"></a>toString方法</h3><p><code>System.out.println(entrySet );</code>  显然调用的是toString方法；</p><ul><li>在2.5中的源码可知entrySet对象继承于<code>AbstractSet</code>类，间接实现了<code>AbstractCollection</code>接口</li><li><strong>重写的</strong>toString()方法调用了<code>this.iterator()</code>即EntrySet类的iterator()方法进行输出</li></ul><p><img src="https://img-blog.csdnimg.cn/62ee4cb2c23940579532b0b9816bba61.png"></p><h3 id="iterator方法"><a href="#iterator方法" class="headerlink" title="iterator方法"></a>iterator方法</h3><ol><li><p>我们发现HashMap中的内部类EntrySet中重写了iterator()方法，<strong>实际调用的是EntryIterator对象</strong><br><img src="https://img-blog.csdnimg.cn/e7a3d92938864dbfa739efcbe0412b7f.png"></p></li><li><p>EntryIterator类继承于HashIterator类 ：nextNode方法是HashIterator中的方法<br><img src="https://img-blog.csdnimg.cn/03f2e6ca1f0b4351bd1f8e8874207bb6.png" alt="EntryIterator"></p></li><li><p>跟进nextNode方法，框体内容是指针的变化的判断细节，不是本论题的重点</p></li></ol><p><img src="https://img-blog.csdnimg.cn/66322df3e3be43ac834ef9674557c2c1.png"><br>由此可知：</p><p>这个EntrySet类重写的iterator()方法可以使得指针<strong>正确得指向下一个节点</strong>..</p><h3 id="toArray方法"><a href="#toArray方法" class="headerlink" title="toArray方法"></a>toArray方法</h3><ul><li>测试代码中也正确输出了toArray()的结果，同样的，这个方法也是重写在其父类<code>AbstractCollection</code>中的</li><li>同理，其底层实现还是调用了iterator()，利用HashIterator类中的nextNode()方法对指针进行下移</li></ul><p><img src="https://img-blog.csdnimg.cn/21842f3c7f454b26aea052afb93d4961.png"></p><h3 id="size、clear方法"><a href="#size、clear方法" class="headerlink" title="size、clear方法"></a>size、clear方法</h3><p>这两个方法很简单，就是直接用的当前HashMap对象的属性和方法<br><img src="https://img-blog.csdnimg.cn/ddae87f117b94c039337ca30b8df092a.png"><br><strong>hashMap.entrySet().size()的大小并不是真正这个entrySet对象的大小，而是调用了size属性的fake size</strong></p><h2 id="3-3小总结"><a href="#3-3小总结" class="headerlink" title="3.3小总结"></a>3.3小总结</h2><ul><li>entrySet()和keySet()都是<strong>懒汉式</strong>，调用方法，<strong>new对象的时候并没有对其进行赋值</strong></li><li>而是在使用hashMap.entrySet().**toString()**、hashMap.entrySet(). <strong>toArray()</strong> 等方法的时候才<code>调用iterator()来获取迭代器</code></li><li>EntrySet类和KeySet类也都<strong>没有构造器能进行初始化</strong></li><li>不得不说HashMap的设计十分精巧，entrySet()表面上获取了一个set对象，实际上这个set对象是空的，<strong>几乎所有的方法都是先直接获取迭代器入口</strong>，<strong>性能大幅提升</strong></li></ul><h2 id="3-4关于idea在debug时的问题"><a href="#3-4关于idea在debug时的问题" class="headerlink" title="3.4关于idea在debug时的问题"></a>3.4关于idea在debug时的问题</h2><p><a href="https://blog.csdn.net/lkforce/article/details/90479650">参考</a></p><ul><li>DEA在debug时，当debug到某个对象时，会调用对象的toString()方法，用来在debug界面显示对象信息。</li><li>IDEA调用toString()方法时，即使在toString()方法中设置了断点，该断点也不会被触发，也就是说，开发者多数情况下不会知道toString()方法被调用了。</li><li>多数情况下调用一下toString()方法没有什么问题，但是也有例外，<code>比如重写了toString()方法的类，随意的调用toString()方法会导致未知的问题</code>。<strong>本案例就是因为重写toString()方法而产生了问题</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 源码 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HashMap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mysql事务和存储引擎</title>
      <link href="/zjh/2022/03/07/Mysql%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/"/>
      <url>/zjh/2022/03/07/Mysql%E4%BA%8B%E5%8A%A1%E5%92%8C%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/</url>
      
        <content type="html"><![CDATA[<h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p><a href="https://www.jianshu.com/p/9b5eb43236cc">参考</a><br><a href="https://www.cnblogs.com/qlqwjy/p/8547999.html">参考</a></p><h2 id="事务控制"><a href="#事务控制" class="headerlink" title="事务控制"></a>事务控制</h2><p>方式一：set autocommit = 0</p><p>方式二：START TRANSACTION 或 BEGIN</p><p>都是手动提交commit，手动回滚rollback</p><h2 id="Springboot中事务控制"><a href="#Springboot中事务控制" class="headerlink" title="Springboot中事务控制"></a>Springboot中事务控制</h2><h3 id="Transactional注解："><a href="#Transactional注解：" class="headerlink" title="@Transactional注解："></a>@Transactional注解：</h3><p>在Spring Boot中推荐使用@Transactional注解来申明事务。</p><ul><li>首先需要导入JDBC依赖</li><li>在<strong>Service层</strong>中添加@Transactional注解</li><li>@Transactional注解<strong>既可以标注在类上也可以标注在方法上</strong></li></ul><h3 id="业务场景举例："><a href="#业务场景举例：" class="headerlink" title="业务场景举例："></a>业务场景举例：</h3><p>经典的银行转账问题，Dao层两个@update，一个增一个减，Service层中不光注入了转账的Dao，还注入了积分相关的Dao，这一系列操作是一个事务，所以需要在Service层or其下对应的方法使用注解@Transactional</p><h3 id="注解属性"><a href="#注解属性" class="headerlink" title="注解属性"></a>注解属性</h3><p><a href="https://blog.csdn.net/wkl305268748/article/details/77619367?spm=1001.2014.3001.5506">常用配置参考</a></p><ul><li>rollbackFor：触发回滚的异常类型设定</li><li>isolation：事务的隔离级别设定</li><li>timeout：超时回滚<br><img src="https://img-blog.csdnimg.cn/fadee28af9584631b86082be4046fd9a.png"></li></ul><p>举例：<br><img src="https://img-blog.csdnimg.cn/a0f3bbb6296b4e78851a6faf049c4788.png"></p><h3 id="Transactional失效"><a href="#Transactional失效" class="headerlink" title="@Transactional失效"></a>@Transactional失效</h3><p><a href="https://zhuanlan.zhihu.com/p/114461128">失效参考案例</a><br>最常见的失效是：<strong>在事务内部把异常给捕获了</strong>，举个例子</p><p><img src="https://img-blog.csdnimg.cn/57b35a827c5e4ea489fc87ea18af55d8.png">应该在最外层（控制层）进行异常捕获，保证事务的开启只有一条语句</p><h2 id="事务四大特性"><a href="#事务四大特性" class="headerlink" title="事务四大特性"></a>事务四大特性</h2><p><img src="https://img-blog.csdnimg.cn/62d285c60c0f4d4885ed8575657a0f9d.png"></p><h2 id="并发事务问题"><a href="#并发事务问题" class="headerlink" title="并发事务问题"></a>并发事务问题</h2><ul><li>赃读：一个事务读到另外一个事务<strong>还没有提交</strong>的数据</li><li>不可重复读：一个事务<strong>先后</strong>读取同一条记录，但两次读取的数据不同，称之为不可重复读</li><li>幻读：（<strong>读时没有，插时有</strong>）一个事务按照条件查询数据时，没有对应的数据行，但是在插入数据时，又发现这行数据已经存在，好像出现了 “幻影”。</li></ul><h2 id="事务的4个隔离级别"><a href="#事务的4个隔离级别" class="headerlink" title="事务的4个隔离级别"></a>事务的4个隔离级别</h2><p>事务隔离级别越高，数据越安全，但是性能越低</p><p><img src="https://img-blog.csdnimg.cn/bfa54d09e1ed476f8514fdfc13522988.png"></p><h1 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h1><ul><li>存储数据，建立索引，增删改查</li><li>基于表，而非基于库</li><li>Mysql默认引擎是InnoDB</li></ul><p>mysiam使用的常见被nosql：mongodb替代<br>memory也是一样被nosql：redis取代</p><p><img src="https://img-blog.csdnimg.cn/ebc4baf0cebf45c18b826440bcf5809f.png"></p><h2 id="查看设置引擎"><a href="#查看设置引擎" class="headerlink" title="查看设置引擎"></a>查看设置引擎</h2><p>查看：SHOW ENGINES<br>设置：CREATE TABLE xxx（）ENGIENS = MyISAM</p><h2 id="默认：InnoDB"><a href="#默认：InnoDB" class="headerlink" title="默认：InnoDB"></a>默认：InnoDB</h2><ul><li>可靠性(行锁+事务+外键)，高性能(B+树)</li><li>支持事务，DML操作遵循ACID模型</li><li>行级锁，<strong>提高并发访问性能</strong>    </li><li>支持外键，保证数据完整性和正确性</li></ul><h2 id="早期：MyISAM"><a href="#早期：MyISAM" class="headerlink" title="早期：MyISAM"></a>早期：MyISAM</h2><p>面试题：</p><p><img src="https://img-blog.csdnimg.cn/1a0de812895e4c64b62fc4fa410bc886.png"><br>足迹，评论，点赞这种非核心数据 可以用myisam，偶尔丢点数据也没事</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Mysql(InnoDB)索引原理及的使用</title>
      <link href="/zjh/2022/03/07/Mysql-InnoDB-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%8F%8A%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/zjh/2022/03/07/Mysql-InnoDB-%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E5%8F%8A%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="索引概述"><a href="#索引概述" class="headerlink" title="索引概述"></a>索引概述</h1><ul><li>正常的业务SELECT居多，而INSERT UPDATE DELETE偏少，所以使用索引， 用空间换时间；查询变快，增删改变慢。</li><li>可以选择给单个字段加索引，也可以联合几个字段加索引</li><li>主键和外键默认都有索引，没有主键会自动生成rowid<h1 id="索引结构"><a href="#索引结构" class="headerlink" title="索引结构"></a>索引结构</h1>索引是存储引擎实现的，InnoDB的索引结构是B+树，<strong>大部分的引擎也都支持B+树索引</strong><br><img src="https://img-blog.csdnimg.cn/c678a3d3200c4c51bb94f79b353513bb.png"></li></ul><h2 id="B-树索引的优点"><a href="#B-树索引的优点" class="headerlink" title="B+树索引的优点"></a>B+树索引的优点</h2><p><img src="https://img-blog.csdnimg.cn/467a09b2cd70414dba064625da2053e5.png"></p><ul><li><strong>层级少</strong>，2200W的数据只有3层</li><li>叶子节点存数据+指针(<strong>利于排序</strong>)</li><li>支持<strong>范围查询</strong>    </li><li>支持<strong>排序(区间指针)</strong></li><li>索引全部出现在最下层，即便是他们作为了上层分支</li></ul><h2 id="InnoDB到底支持Hash索引吗？"><a href="#InnoDB到底支持Hash索引吗？" class="headerlink" title="InnoDB到底支持Hash索引吗？"></a>InnoDB到底支持Hash索引吗？</h2><p>InnoDB在特定条件下会<strong>自适应Hash索引，用户不能手动创建</strong>，可以理解为“索引的索引”，可以加快索引查询速度</p><p>关于这个问题，参考<a href="https://wenku.baidu.com/view/912836ffb5360b4c2e3f5727a5e9856a571226ef.html">https://wenku.baidu.com/view/912836ffb5360b4c2e3f5727a5e9856a571226ef.html</a></p><p>相比B+树的优缺点：</p><ul><li>不支持范围查询，但指定查询效率更高(一般只需一次检索)</li><li>哈希冲突问题使用链表解决</li><li><strong>无法排序</strong>，哈希值计算结果没有顺序关系</li></ul><p><a href="https://www.cnblogs.com/igoodful/p/9361500.html">参考</a></p><h1 id="索引4种分类"><a href="#索引4种分类" class="headerlink" title="索引4种分类"></a>索引4种分类</h1><p><img src="https://img-blog.csdnimg.cn/251aa1aa0c344c15a3fdc3d56e499f10.png"></p><h2 id="聚集索引and二级索引"><a href="#聚集索引and二级索引" class="headerlink" title="聚集索引and二级索引"></a>聚集索引and二级索引</h2><p>聚集索引：唯一；索引处叶子节点包括<strong>行数据</strong><br>二级索引：多个：索引处叶子节点包括<strong>数据+关联的聚集索引</strong></p><h3 id="聚类索引"><a href="#聚类索引" class="headerlink" title="聚类索引"></a>聚类索引</h3><ul><li><strong>主键</strong>就是聚类索引</li><li>没有主键就是<strong>UNIQUE</strong>作为聚类索引</li><li>都没有则InnoDB<strong>自动生成rowid</strong>作为隐藏的聚类索引</li></ul><h3 id="二级索引及回表查询"><a href="#二级索引及回表查询" class="headerlink" title="二级索引及回表查询"></a>二级索引及回表查询</h3><ul><li>每个叶子节点都包含<strong>对应行的聚类索引</strong></li><li><strong>回表查询</strong>：例如当SELECT * FROM时，这种先到二级索引中查找数据，找到主键值，然后再到聚集索引中根据主键值，获取数据的方式</li></ul><h1 id="索引语法"><a href="#索引语法" class="headerlink" title="索引语法"></a>索引语法</h1><p><a href="https://blog.csdn.net/qq_34698708/article/details/102529272?ops_request_misc=&request_id=&biz_id=102&utm_term=mysql%E5%88%9B%E5%BB%BA%E7%B4%A2%E5%BC%95%E8%AF%AD%E6%B3%95&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-102529272.nonecase&spm=1018.2226.3001.4187">详细参考</a><br><img src="https://img-blog.csdnimg.cn/911a861364f3410c9527643a8754ad60.png"></p><h2 id="主键和外键"><a href="#主键和外键" class="headerlink" title="主键和外键"></a>主键和外键</h2><p>主键：ALTER TABLE nxbusers ADD PRIMARY KEY ( id );<br><img src="https://img-blog.csdnimg.cn/9e729dd490024ece8da2f08eb1ae5079.png"><br>外键：ALTER TABLE nxbinfolike ADD FOREIGN KEY ( infoid ) REFERENCES nxbpushinfo ( infoid );</p><p>也可以在设计表的时候直接添加。关于是否添加外键，可以参考<br><a href="https://www.cnblogs.com/jxl00125/p/12622969.html">https://www.cnblogs.com/jxl00125/p/12622969.html</a><br><a href="https://blog.csdn.net/bisal/article/details/50934304">https://blog.csdn.net/bisal/article/details/50934304</a></p><h2 id="查看索引"><a href="#查看索引" class="headerlink" title="查看索引"></a>查看索引</h2><p><strong>SHOW INDEX FROM</strong> nxbcomments<br>一般建立的索引都是普通类型，至于索引方法还可以选择Hash，但不建议<br><img src="https://img-blog.csdnimg.cn/a544a78407cf48cbb802c94efa04bfee.png"></p><h2 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h2><h3 id="默认：普通索引"><a href="#默认：普通索引" class="headerlink" title="默认：普通索引"></a>默认：普通索引</h3><p><strong>CREATE INDEX</strong> idx_comment_infoid <strong>ON</strong> nxbcomments <strong>(</strong> infoid <strong>)</strong></p><h3 id="全文索引or唯一索引"><a href="#全文索引or唯一索引" class="headerlink" title="全文索引or唯一索引"></a>全文索引or唯一索引</h3><p>同理可以把FULLTEXT更换为UNIQUE<br>CREATE <strong>FULLTEXT</strong> INDEX idx_comment_infoid ON nxbcomments ( infoid );</p><p><img src="https://img-blog.csdnimg.cn/53e1a75bbcf5412fbe5118b890cc0c3f.png"></p><h3 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h3><p>注意索引命名方式，<strong>括号内顺序就是索引建立的顺序，关乎索引失效问题</strong><br>CREATE INDEX idx_pushinfo_topic_location ON nxbpushinfo ( topic, location );</p><p>这样一来就建立了“话题”和“定位”的索引，在查询的时候可以只查询话题（索引失效的应用）</p><p>在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引，而非单列索引。</p><h2 id="删除索引"><a href="#删除索引" class="headerlink" title="删除索引"></a>删除索引</h2><p>DROP INDEX idx_comment_infoid ON nxbcomments;<br>或者</p><p>ALTER TABLE nxbcomments DROP INDEX idx_comment_infoid;</p><h1 id="索引设计原则"><a href="#索引设计原则" class="headerlink" title="索引设计原则"></a>索引设计原则</h1><p>1). 针对于<strong>数据量较大</strong>，且查询比较频繁的表建立索引。<br>2). 针对于常作为<strong>查询条件（where）、排序（order by）、分组（group by）</strong>操作的字段建立索引。<br>3). 尽量选择区分度高的列作为索引，<strong>尽量建立唯一索引，区分度越高，使用索引的效率越高。</strong><br>4). 如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。<br>5). <strong>尽量使用联合索引</strong>，减少单列索引，查询时，<strong>联合索引很多时候可以覆盖索引，节省存储空间</strong>，避免回表，提高查询效率。<br>6). <strong>要控制索引的数量</strong>，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，<strong>会影响增删改的效率</strong><br>7). <strong>如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它</strong>。当优化器知道每列是否包含NULL值时，它可以更好地确定哪个索引最有效地用于查询。</p><h1 id="联合索引失效"><a href="#联合索引失效" class="headerlink" title="联合索引失效"></a>联合索引失效</h1><ul><li>索引失效会带来一些问题，同时也可以巧妙应用</li><li>索引的触发是通过where的，<strong>没有where则不触发索引</strong></li><li>where的条件的顺序没有影响，有影响的是<strong>定义索引时的顺序</strong></li><li><strong>总结</strong>：跳过了定义时的中间索引(后面的失效)；&lt;&gt;（后面的失效）；进行了运算（后面的失效）；字符串不加引号（后面的失效）；前缀%模糊查询（后面的失效）；or连接条件有的没索引(<strong>全失效</strong>)；查询已排序好的数据的边缘<h2 id="最左前缀法则"><a href="#最左前缀法则" class="headerlink" title="最左前缀法则"></a>最左前缀法则</h2>创建索引（topic , location , tag）即该索引在底层的建立顺序是从<strong>左到右</strong></li><li>如果where条件中出现了topic = “” 则触发索引机制</li><li>如果where条件中只写了topic = “” 和 tag = “” 而<strong>跳过了中间的location，则索引只对topic生效</strong></li><li>如果where tag = “” and loacation = “” and topic = “”这种顺序也是可以的，<strong>只要是出现了topic就能触发索引</strong></li></ul><p>我们可以利用该特性实现《只定义一个联合索引，达到多方式筛选的目的》</p><h2 id="范围查询"><a href="#范围查询" class="headerlink" title="范围查询"></a>范围查询</h2><p>联合索引中，出现范围查询(&gt;,&lt;)，范围查询<strong>右侧的列索引失效**。<br>当范围查询使用&gt;= 或 &lt;= 时，走联合索引了，所有的字段都是走索引<br>的。<br>**所以，在业务允许的情况下，尽可能的使用类似于 &gt;= 或 &lt;= 这类的范围查询，而避免使用 &gt; 或 &lt;</strong></p><h2 id="索引列运算"><a href="#索引列运算" class="headerlink" title="索引列运算"></a>索引列运算</h2><p>例如explain select * from tb_user where <strong>substring(phone,10,2) = ‘15’;</strong><br>会导致索引失效</p><p><img src="https://img-blog.csdnimg.cn/4f0a1723a4a94b0da4ca9415fccf7e2e.png"></p><h2 id="字符串不加引号"><a href="#字符串不加引号" class="headerlink" title="字符串不加引号"></a>字符串不加引号</h2><p>字符串类型的数据如果不加引号，对查询结果没有影响，但是不会触发索引</p><p>不触发：SELECT * FROM nxbpushinfo WHERE infoid = 1643877357315 ;</p><p>触发：SELECT * FROM nxbpushinfo WHERE infoid = ‘1643877357315’ ;</p><h2 id="头部模糊查询"><a href="#头部模糊查询" class="headerlink" title="头部模糊查询"></a>头部模糊查询</h2><p>尾模糊不失效，头模糊失效<br><img src="https://img-blog.csdnimg.cn/783740dede13460f8112d8de20b68e35.png"></p><h2 id="or连接条件"><a href="#or连接条件" class="headerlink" title="or连接条件"></a>or连接条件</h2><p><strong>or连接的条件必须都有索引，不然都会失效；开发中可以使用UNION进行优化</strong></p><p>where topic = “” or location = “”如果topic字段有索引（单独索引or联合索引）但是location没有索引，那么topic的索引也失效</p><h2 id="数据分布影响"><a href="#数据分布影响" class="headerlink" title="数据分布影响"></a>数据分布影响</h2><p>如果MySQL评估使用索引比全表更慢，则不使用索引。<br>例如：已经按排序字段数据，查询倒数第10到正数第一的所有数据，不走索引<br>例如：一个表中绝大多数都是null，那么WHERE 有索引的字段 is not null也不走索引</p><h1 id="EXPLAIN"><a href="#EXPLAIN" class="headerlink" title="EXPLAIN"></a>EXPLAIN</h1><p> 直接在select语句之前加上关键字 explain / desc<br>EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件 ;</p><p>可以查询索引的使用情况</p><h1 id="SQL提示"><a href="#SQL提示" class="headerlink" title="SQL提示"></a>SQL提示</h1><p>SQL提示，是优化数据库的一个重要手段，可以指定查询<strong>走联合索引or指定索引</strong></p><h2 id="use-index建议"><a href="#use-index建议" class="headerlink" title="use index建议"></a>use index建议</h2><p>建议MySQL使用哪一个索引完成此次查询（仅仅是建议，mysql内部还会再次进行评估）</p><p> select * from 表 index(指定索引) where 条件；</p><h2 id="ignore-index忽略"><a href="#ignore-index忽略" class="headerlink" title="ignore index忽略"></a>ignore index忽略</h2><p>忽略指定的索引。<br>如果有其他包含的索引，则走其他索引。没有则不走索引</p><h2 id="force-index强制"><a href="#force-index强制" class="headerlink" title="force index强制"></a>force index强制</h2><p>放的位置也和use index 一样，强制使用索引，不听mysql评估</p><h1 id="索引覆盖-避免回表"><a href="#索引覆盖-避免回表" class="headerlink" title="索引覆盖(避免回表)"></a>索引覆盖(避免回表)</h1><p>概念：where中出现的字段都有索引，select的字段尽量是这些索引的字段，而非其他字段</p><p><strong>如果超出这个范围，就需要拿到主键id，再去扫描聚集索引，再获取额外的数据（回表查询）</strong></p><h1 id="前缀索引"><a href="#前缀索引" class="headerlink" title="前缀索引"></a>前缀索引</h1><p>当字段类型为字符串（varchar，text，longtext等）时，有时候需要索引很长的字符串，这会让索引变得很大，查询时，浪费大量的磁盘IO， 影响查询效率。<strong>此时可以只将字符串的一部分前缀，建立索引</strong>，这样可以大大节约索引空间，从而提高索引效率。</p><p>例如：对江苏南京，四川绵阳这种location字段的省份建立索引(不考虑黑龙江是三个字)</p><p>create index idx_location_province on nxbpushinfo(location(2))</p><p>例如：手机号码的前缀决定了地域，也可以添加前缀索引</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>类自身嵌套(二叉树删除)栈堆分析</title>
      <link href="/zjh/2022/03/07/%E7%B1%BB%E8%87%AA%E8%BA%AB%E5%B5%8C%E5%A5%97-%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%A0%E9%99%A4-%E6%A0%88%E5%A0%86%E5%88%86%E6%9E%90/"/>
      <url>/zjh/2022/03/07/%E7%B1%BB%E8%87%AA%E8%BA%AB%E5%B5%8C%E5%A5%97-%E4%BA%8C%E5%8F%89%E6%A0%91%E5%88%A0%E9%99%A4-%E6%A0%88%E5%A0%86%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="类自嵌堆栈分析"><a href="#类自嵌堆栈分析" class="headerlink" title="类自嵌堆栈分析"></a>类自嵌堆栈分析</h1><pre><code>//节点类，构造器等方法省略    class MyNode &#123;        Key key;        Value value;        MyNode left;        MyNode right;&#125;</code></pre><h2 id="自身嵌套不创建栈空间"><a href="#自身嵌套不创建栈空间" class="headerlink" title="自身嵌套不创建栈空间"></a>自身嵌套不创建栈空间</h2><pre><code>@Test    public void test1()&#123;        MyNode node1 = new MyNode();//第一个节点    node1.left = new MyNode();    node1.left.left = new MyNode();    node1.left.left.left = new MyNode();    node1.left.left.left.left = new MyNode();    node1.left.left.left.left.left = new MyNode();    //栈地址：node2 ≠ node1.left    //栈值(堆地址)：node2 = node1.left    MyNode node2 = node1.left;    node2.left.left.left.left = null;//尾节点置空，修改堆的值，相当于node1.left.left.left.left.left=null;    //原node1之下的树：    System.out.println(node1.left.left.left.left);//tree.BinaryTree$MyNode@2d3fcdbd;但该节点的4个属性都为null    System.out.println(node1.left.left.left.left.left);//null&#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/b19e546980ea41b7901bd9a23976beca.png"></p><p><img src="https://img-blog.csdnimg.cn/9039c0f58be8492189820eae8e716a47.png"><br><strong>因此对node2.left.left…的属性进行修改是会影响到node1.left.left…的</strong></p><h1 id="删除方法"><a href="#删除方法" class="headerlink" title="删除方法"></a>删除方法</h1><p>一个简陋版的删除方法，有一些小bug，但大题思路是这样</p><ul><li>开辟栈空间，用temp中间变量来进入树的内部，因为修改的是堆对象，所以这个新开辟的temp也能达到并修改</li><li>当删除的节点左右分支都存在时，右子树的最小节点将作为替换节点</li></ul><p><img src="https://img-blog.csdnimg.cn/b59481d64bea4f94bf00c048ea4c21d0.png" alt="在这里插入图片描述"></p><pre><code>public MyNode deleteFrom(MyNode x , Key key)&#123;    if(x==null)&#123;        return null;    &#125;    int cmp = key.compareTo(x.key);//递归    if(cmp&lt;0)&#123;        x.left = deleteFrom(x, key);    &#125;else if(cmp&gt;0)&#123;        x.right = deleteFrom(x,key);    &#125;else&#123;//当前节点就是需要删除的节点        //如果两边都有节点，那么要找出right子树的最小节点temp替代当前节点        if(x.right==null)&#123;            return x.left;        &#125;else if(x.left==null)&#123;            return x.right;        &#125;else&#123;            //1,找到右子树最小节点temp,并在原树中删除            MyNode temp = x.right;//开辟栈temp                      MyNode destTemp = null;//开辟栈destTemp            while(temp.left != null)&#123;                temp = temp.left;                if(temp.left.left == null)&#123;//temp.left就是该换位的节点，                    //1.1 destTemp拿到最终节点的地址值                    destTemp = temp.left;  //栈中destTemp拿到对象                    //1.2                    temp.left = null;     //堆中对象的left属性置空，但堆对象存在                    break;                &#125;            &#125;                        temp = destTemp; //栈中temp拿到了右子树最小节点的地址            //2,temp指向x.left和x.right            temp.left = x.left;            temp.right = x.right;            //3,temp替换x            x = temp;            &#125;            n--;        &#125;    return x;&#125;</code></pre><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><ul><li>匿名对象也不创建栈，只创建堆对象，即便是匿名对象被引用了，例如:<br>Thread t1 = new Thread(new MyRunable());</li><li>不显式声明的对象都没有栈</li><li>jvm栈中的内存在类结构确定时就知道了，随着方法结束或者线程消亡，内存自然而然被回收了，<strong>因此尽量不使用递归，递归的方法不结束会连续创建很多个栈空间，可能爆栈；而循环每循环一次都会入栈出栈</strong></li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据结构算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java堆排序的过程到设计</title>
      <link href="/zjh/2022/03/07/Java%E5%A0%86%E6%8E%92%E5%BA%8F%E7%9A%84%E8%BF%87%E7%A8%8B%E5%88%B0%E8%AE%BE%E8%AE%A1/"/>
      <url>/zjh/2022/03/07/Java%E5%A0%86%E6%8E%92%E5%BA%8F%E7%9A%84%E8%BF%87%E7%A8%8B%E5%88%B0%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><ul><li>堆的原理是顺序二叉树，但底层实现是数组</li><li>arr[i]是父节点，那么arr[2<em>i+1]是其左子节点，arr[2</em>i+2]是其右子节点</li><li>arr[i]的父节点是arr[ (i-1)/2 ]</li><li>arr[0]是根节点，并频繁用于和尾节点交换<br><img src="https://img-blog.csdn.net/20180908013007479?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2MTg2Njkw/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70#pic_center" alt="过程动图"></li></ul><p><a href="https://blog.csdn.net/u010452388/article/details/81283998?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164646575616781685311492%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=164646575616781685311492&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-81283998.pc_search_result_control_group&utm_term=%E5%A0%86%E6%8E%92%E5%BA%8F&spm=1018.2226.3001.4187">参考1</a></p><p><a href="https://blog.csdn.net/qq_36186690/article/details/82505569?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164647017516780271519582%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=164647017516780271519582&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-82505569.pc_search_result_control_group&utm_term=%E5%A0%86%E6%8E%92%E5%BA%8Fjava&spm=1018.2226.3001.4187">参考2</a></p><ol><li>调用heapMaker方法，把arr变成大顶堆的顺序（会判断每个元素）</li><li>此时已有大顶堆，把根节点（大顶）和末尾交换并固定，size-1</li><li>再从新的根节点（之前的小节点）调用<strong>下沉算法</strong>sink，再把arr变为大顶堆的顺序（这次只操作部分元素）</li><li>循环，直至size = 1</li></ol><h1 id="API设计"><a href="#API设计" class="headerlink" title="API设计"></a>API设计</h1><h2 id="heapMaker构造大顶堆"><a href="#heapMaker构造大顶堆" class="headerlink" title="heapMaker构造大顶堆"></a>heapMaker构造大顶堆</h2><p>将无序数组构造成一个大根堆（升序用大根堆，降序就用小根堆）</p><pre><code>//创建堆：从arr[0]开始，每添加一个元素都和其父元素进行对比public static void heapMaker(int[] arr) &#123;    for (int i = 0; i &lt; arr.length; i++) &#123;        int currentIndex = i;        int fatherIndex = (i - 1) / 2;        //因为此逻辑并未判断左右子节点之间的大小关系，所以在sink方法中需要进行判断        while (arr[currentIndex] &gt; arr[fatherIndex]) &#123;            //1.交换            swap(arr, currentIndex, fatherIndex);            //2.子索引变父索引，继续向上判断            currentIndex = fatherIndex;            fatherIndex = (fatherIndex - 1) / 2;        &#125;    &#125;&#125;</code></pre><h2 id="交换固定"><a href="#交换固定" class="headerlink" title="交换固定"></a>交换固定</h2><pre><code>//交换public static void swap(int[] arr, int i, int j) &#123;    int temp = arr[i];    arr[i] = arr[j];    arr[j] = temp;&#125;</code></pre><h2 id="下沉算法：修正大顶堆"><a href="#下沉算法：修正大顶堆" class="headerlink" title="下沉算法：修正大顶堆"></a>下沉算法：修正大顶堆</h2><pre><code>//大顶堆的修正(下沉算法)public static void sink(int[] arr, int index, int size) &#123;//size:最大范围    //1.左右子节点大小对比，    int left = index * 2 + 1;    int right = index * 2 + 2;    int maxValueIndex = 0;//父、左、右的最大值对应的索引    //2.right&lt;size即可保证指针不越界    while (left &lt; size) &#123;        //2.1找出最大值的索引        if (right &lt; size &amp;&amp; arr[right] &gt; arr[left]) &#123;            maxValueIndex = right;        &#125; else &#123;            maxValueIndex = left;        &#125;        if (arr[index] &gt; arr[maxValueIndex]) &#123;            maxValueIndex = index;        &#125;        //2.2判断是否大顶堆        if (index == maxValueIndex) &#123;            break;        &#125;        //2.3交换arr中的值        swap(arr, index, maxValueIndex);        //2.4下一轮        index = maxValueIndex;//一定是左or右        left = index * 2 + 1;        right = index * 2 + 2;    &#125;&#125;</code></pre><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><pre><code>public static void main(String[] args) &#123;    int[] arr = new int[]&#123;1, 2, 4, 5, 1, 2, 4, 3, 2, 54, 23452, 543, 12, 4&#125;;    System.out.println(&quot;最初&quot;);    System.out.println(Arrays.toString(arr));    System.out.println(&quot;生成大顶堆&quot;);    heapMaker(arr);//生成大顶堆    System.out.println(Arrays.toString(arr));    System.out.println(&quot;循环固定，排序后&quot;);    int size = arr.length;    while (size &gt; 1) &#123;        //1,固定最大值        swap(arr, 0, size - 1);        size--;        //2,下沉：修正大顶堆        sink(arr, 0, size);    &#125;    System.out.println(Arrays.toString(arr));&#125;&#125;</code></pre><p><img src="https://img-blog.csdnimg.cn/9ff6ff7f01284cafbc5222d7a9dc7481.png"></p><h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1><pre><code>public class heapSort &#123;public static void main(String[] args) &#123;    int[] arr = new int[]&#123;1, 2, 4, 5, 1, 2, 4, 3, 2, 54, 23452, 543, 12, 4&#125;;    System.out.println(&quot;最初&quot;);    System.out.println(Arrays.toString(arr));    System.out.println(&quot;生成大顶堆&quot;);    heapMaker(arr);//生成大顶堆    System.out.println(Arrays.toString(arr));    System.out.println(&quot;循环固定，排序后&quot;);    int size = arr.length;    while (size &gt; 1) &#123;        //1,固定最大值        swap(arr, 0, size - 1);        size--;        //2,下沉：修正大顶堆        sink(arr, 0, size);    &#125;    System.out.println(Arrays.toString(arr));&#125;//交换public static void swap(int[] arr, int i, int j) &#123;    int temp = arr[i];    arr[i] = arr[j];    arr[j] = temp;&#125;//创建堆：从arr[0]开始，每添加一个元素都和其父元素进行对比public static void heapMaker(int[] arr) &#123;    for (int i = 0; i &lt; arr.length; i++) &#123;        int currentIndex = i;        int fatherIndex = (i - 1) / 2;        //因为此逻辑并未判断左右子节点之间的大小关系，所以在sink方法中需要进行判断        while (arr[currentIndex] &gt; arr[fatherIndex]) &#123;            //1.交换            swap(arr, currentIndex, fatherIndex);            //2.子索引变父索引，继续向上判断            currentIndex = fatherIndex;            fatherIndex = (fatherIndex - 1) / 2;        &#125;    &#125;&#125;//大顶堆的修正(下沉算法)public static void sink(int[] arr, int index, int size) &#123;//size:最大范围    //1.左右子节点大小对比，    int left = index * 2 + 1;    int right = index * 2 + 2;    int maxValueIndex = 0;//父、左、右的最大值对应的索引    //2.right&lt;size即可保证指针不越界    while (left &lt; size) &#123;        //2.1找出最大值的索引        if (right &lt; size &amp;&amp; arr[right] &gt; arr[left]) &#123;            maxValueIndex = right;        &#125; else &#123;            maxValueIndex = left;        &#125;        if (arr[index] &gt; arr[maxValueIndex]) &#123;            maxValueIndex = index;        &#125;        //2.2判断是否大顶堆        if (index == maxValueIndex) &#123;            break;        &#125;        //2.3交换arr中的值        swap(arr, index, maxValueIndex);        //2.4下一轮        index = maxValueIndex;//一定是左or右        left = index * 2 + 1;        right = index * 2 + 2;    &#125;&#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>LinkedList源码中为何大量出现final</title>
      <link href="/zjh/2022/02/21/LinkedList%E6%BA%90%E7%A0%81%E4%B8%AD%E4%B8%BA%E4%BD%95%E5%A4%A7%E9%87%8F%E5%87%BA%E7%8E%B0final/"/>
      <url>/zjh/2022/02/21/LinkedList%E6%BA%90%E7%A0%81%E4%B8%AD%E4%B8%BA%E4%BD%95%E5%A4%A7%E9%87%8F%E5%87%BA%E7%8E%B0final/</url>
      
        <content type="html"><![CDATA[<h1 id="源码中出现final的地方"><a href="#源码中出现final的地方" class="headerlink" title="源码中出现final的地方"></a>源码中出现final的地方</h1><ul><li>所有的link有关的方法（增删操作）add remove</li><li>需要保存中间变量的节点（prev和next指针需要修改的节点）</li><li>像clear get这种不涉及“更改指针指向”的方法不需要对中间变量定义final</li></ul><p><img src="https://img-blog.csdnimg.cn/8205fb2b21234a24a8f79d42bc9ca406.png" alt="linkFirst"><br><img src="https://img-blog.csdnimg.cn/e59b57429ad34923b07be9a51fda4c53.png" alt="unlink"></p><h1 id="final的作用"><a href="#final的作用" class="headerlink" title="final的作用"></a>final的作用</h1><p><a href="https://www.cnblogs.com/chhyan-dream/p/10685878.html">final关键字的作用</a><br><img src="https://img-blog.csdnimg.cn/1b4bfe04d9a54f7ba8de7ee622f9b5a7.png"></p><p>LinkedList中Node是一个对象，因此适用于第二条<strong>引用数据类型</strong>，举个例子：</p><h2 id="有无final修饰的浅拷贝"><a href="#有无final修饰的浅拷贝" class="headerlink" title="有无final修饰的浅拷贝"></a>有无final修饰的浅拷贝</h2><pre><code>People p1 = new People(18,&quot;张三&quot;);People p2 = p1;</code></pre><ol><li><p>当：p1 = null;或者p1 = new People(20,”李四”);<br>实际上是栈中的p1存储的地址改变，但堆空间中之前 new People(18,”张三”);的对象仍然存在。因此p2不受影响</p></li><li><p>当：p1.setAge(21); 此时操作的是堆空间中的唯一对象，p2会受到影响</p></li></ol><p>在源码中：</p><pre><code>    final E element = x.item;    final Node&lt;E&gt; next = x.next;    final Node&lt;E&gt; prev = x.prev;</code></pre><p>使得element  next    prev三个属性<strong>栈空间保存的地址不可再被重定向</strong>，但可以修改值，例如：next.prev = prev和prev.next=next <strong>可以对栈所指向的堆成员变量进行修改</strong></p><h1 id="使用final初始化的优点"><a href="#使用final初始化的优点" class="headerlink" title="使用final初始化的优点"></a>使用final初始化的优点</h1><p>参考链接：</p><p><a href="https://www.cnblogs.com/noteless/p/10416678.html">https://www.cnblogs.com/noteless/p/10416678.html</a><br><a href="https://www.cnblogs.com/noteless/p/10410368.html">https://www.cnblogs.com/noteless/p/10410368.html</a><br><a href="https://www.cnblogs.com/mianlaoshu/articles/3648403.html">https://www.cnblogs.com/mianlaoshu/articles/3648403.html</a><br><a href="https://www.cnblogs.com/maxiaopao/p/9212903.html">https://www.cnblogs.com/maxiaopao/p/9212903.html</a><br><a href="https://zhuanlan.zhihu.com/p/88775601">https://zhuanlan.zhihu.com/p/88775601</a><br><a href="https://www.zhihu.com/question/21762917/answer/19239387">https://www.zhihu.com/question/21762917/answer/19239387</a><br>第四条链接中讲final的优点很详细<br>第五条讲到了重排序<br>第六条是JVM对方法中的final变量性能调优</p><h2 id="安全性分析"><a href="#安全性分析" class="headerlink" title="安全性分析"></a>安全性分析</h2><ul><li>LinkedList本身是不安全，但这并不影响，因为每次事务初始化的都不是同一个Node对象，如果多线程并发并同时add，那么即便是源码定义了final，也可能会出现错误，因此LinkedList在并发场景下需要自行同步</li><li><strong>但多线程并发对于方法中局部变量是不存在冲突的</strong></li><li><strong>排除安全性的可能</strong></li></ul><h2 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h2><ul><li><strong>在能够通过编译的前提下，无论局部变量声明时带不带final关键字修饰，对其访问的效率都一样。</strong></li><li>既然一样，那性能上没影响了。排除</li></ul><h2 id="规范"><a href="#规范" class="headerlink" title="规范"></a>规范</h2><p>参考阿里巴巴的开发手册<br><img src="https://img-blog.csdnimg.cn/6039ed0d6c4c41f0b0dccf8451657ef2.png"><br>不允许修改的局部变量声明为final更多的是一种规范，在实质作用上加与不加没有区别，但他就是个规范。<strong>排除任何可能对这个变量进行修改的可能性</strong></p><p>本问题花了我14个小时，查阅了无数资料，问了无数的人，最后能总结出来的答案就是：规范<br>hhhh浪费了我一天的宝贵时间</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul><li>方法内部初始化的final变量是局部变量</li><li>没有多线程冲突问题</li><li>局部静态基本数据变量定义final才有JVM优化，而引用类型则没有</li><li>final可以避免误操作可能带来的问题，因此对所有不会修改的局部变量都用final定义</li><li>LikedList仍然是线程不安全的，需要手动上锁</li></ul>]]></content>
      
      
      <categories>
          
          <category> 源码 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>LinkedList中clear和unlink方法为什么要多次置空</title>
      <link href="/zjh/2022/02/20/LinkedList%E4%B8%ADclear%E5%92%8Cunlink%E6%96%B9%E6%B3%95%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%A4%9A%E6%AC%A1%E7%BD%AE%E7%A9%BA/"/>
      <url>/zjh/2022/02/20/LinkedList%E4%B8%ADclear%E5%92%8Cunlink%E6%96%B9%E6%B3%95%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%A4%9A%E6%AC%A1%E7%BD%AE%E7%A9%BA/</url>
      
        <content type="html"><![CDATA[<p>今天在看LinkedList源码的时候发现clear和unlink源码都对Node的前后和itme进行了<strong>分别置空</strong>，我之前的想法是直接把所有的Node本身直接置空，x.prev=null和x.next=null，直接x = null也可以使得所有节点为空啊</p><p>但在参考了很多资料后发现，如果单纯的x=null而不x.prev=null和x.next=null，可能不会正常触发GC，事情远远没有那么简单……</p><p>阅读本文需要有JVM垃圾回收机制的知识储备</p><p>参考资料：<br><a href="https://www.iteye.com/problems/71569">https://www.iteye.com/problems/71569</a><br><a href="https://www.bilibili.com/video/BV1AE411E7uj?p=1">https://www.bilibili.com/video/BV1AE411E7uj?p=1</a><br><a href="https://www.bilibili.com/video/BV1yE411Z7AP?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV1yE411Z7AP?spm_id_from=333.999.0.0</a><br><a href="https://www.cnblogs.com/chenpt/p/9803298.html">https://www.cnblogs.com/chenpt/p/9803298.html</a><br><a href="https://www.iteye.com/problems/71569">https://www.iteye.com/problems/71569</a><br><a href="https://codingdict.com/questions/113892">https://codingdict.com/questions/113892</a><br><a href="https://www.cnblogs.com/dmzna/archive/2020/05/18/12913458.html">https://www.cnblogs.com/dmzna/archive/2020/05/18/12913458.html</a><br><a href="https://www.cnblogs.com/shouyaya/p/13524476.html">https://www.cnblogs.com/shouyaya/p/13524476.html</a><br><a href="https://blog.csdn.net/mccand1234/article/details/52078645">https://blog.csdn.net/mccand1234/article/details/52078645</a><br><a href="https://blog.csdn.net/qq_41701956/article/details/81664921">https://blog.csdn.net/qq_41701956/article/details/81664921</a><br><a href="https://blog.csdn.net/yubujian_l/article/details/80804708">https://blog.csdn.net/yubujian_l/article/details/80804708</a></p><h1 id="例如clear的源码"><a href="#例如clear的源码" class="headerlink" title="例如clear的源码"></a>例如clear的源码</h1><p><img src="https://img-blog.csdnimg.cn/2569150ae8b14450b59c58678e2c33d1.png"><br>x.next = null，即表示下一个节点对象=null，为什么还要分成3步写来把属性=null呢？为什么不仅仅是把首尾节点=null让链表找不到入口呢？</p><h1 id="注释翻译："><a href="#注释翻译：" class="headerlink" title="注释翻译："></a>注释翻译：</h1><ul><li><pre><code>is sure to free memory even if there is a reachable Iterator 即便是有迭代器指针此时正在访问中间的节点，也会置空。</code></pre></li><li>helps a generational GC if the discarded nodes inhabit more than one generation有多个节点时，这样做有助于GC垃圾回收</li></ul><h2 id="注解解读："><a href="#注解解读：" class="headerlink" title="注解解读："></a>注解解读：</h2><h3 id="第一个"><a href="#第一个" class="headerlink" title="第一个"></a>第一个</h3><p>如果仅仅是把首尾置空，中间的链表虽然找不到首尾入口，但若此时：</p><ul><li>有迭代器正好访问到中间，取到了中间的node对象</li><li>中间的某个node已被<strong>强引用</strong></li></ul><h3 id="第二个"><a href="#第二个" class="headerlink" title="第二个"></a>第二个</h3><p>倘若JDK版本在8以上，可以忽略这一条，但老版本的gc机制，所用的垃圾收集器可能使用的算法是<strong>引用计数器算法</strong>，该算法不能解决相互引用情况下的垃圾回收</p><p>例如：没有迭代器访问，中间节点对象也没有被强引用，但是他们之间是互相调用的，引用计数器算法不能回收这样的对象，即便是他们没有入口</p><p>而在JDK的流行高版本中一般不使用引用计数器算法，而使用可达性分析算法，当他们都没有被强引用时，便没有了GC Roots根对象，因此会被垃圾回收，但引用计数器算法也并未被淘汰，在著名的单进程高并发缓存Redis中依然采用这种算法来进行内存回收</p><p>综上：第二个注释“<strong>help GC</strong>”所表达的含义是防止因为JDK版本低，垃圾回收算法所导致的“无法回收循环引用”的情况</p><p>同样 对于remove方法调用了unlink，注解也说了help GC<br><img src="https://img-blog.csdnimg.cn/b8137bccbd6943c69eaa21c3a5343348.png"></p>]]></content>
      
      
      <categories>
          
          <category> 源码 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>gc垃圾回收机制</title>
      <link href="/zjh/2022/02/20/gc%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/"/>
      <url>/zjh/2022/02/20/gc%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>参考链接：<br><a href="https://www.bilibili.com/video/BV1AE411E7uj?p=1">https://www.bilibili.com/video/BV1AE411E7uj?p=1</a><br><a href="https://www.bilibili.com/video/BV1yE411Z7AP?spm_id_from=333.999.0.0">https://www.bilibili.com/video/BV1yE411Z7AP?spm_id_from=333.999.0.0</a><br><a href="https://www.cnblogs.com/chenpt/p/9803298.html">https://www.cnblogs.com/chenpt/p/9803298.html</a><br><a href="https://www.iteye.com/problems/71569">https://www.iteye.com/problems/71569</a><br><a href="https://codingdict.com/questions/113892">https://codingdict.com/questions/113892</a><br><a href="https://www.cnblogs.com/dmzna/archive/2020/05/18/12913458.html">https://www.cnblogs.com/dmzna/archive/2020/05/18/12913458.html</a><br><a href="https://www.cnblogs.com/shouyaya/p/13524476.html">https://www.cnblogs.com/shouyaya/p/13524476.html</a><br><a href="https://blog.csdn.net/mccand1234/article/details/52078645">https://blog.csdn.net/mccand1234/article/details/52078645</a><br><a href="https://blog.csdn.net/qq_41701956/article/details/81664921">https://blog.csdn.net/qq_41701956/article/details/81664921</a><br><a href="https://blog.csdn.net/yubujian_l/article/details/80804708">https://blog.csdn.net/yubujian_l/article/details/80804708</a></p><h1 id="补-运行时数据区"><a href="#补-运行时数据区" class="headerlink" title="补:运行时数据区"></a>补:运行时数据区</h1><p><img src="https://img-blog.csdnimg.cn/82bc155c3ade45cca26dbad5798bd46c.png"></p><h2 id="补-程序计数器"><a href="#补-程序计数器" class="headerlink" title="补:程序计数器"></a>补:程序计数器</h2><p>为了<strong>保证程序（在操作系统中理解为进程）能够连续地执行下去</strong>，处理器必须具有某些手段来确定下一条指令的地址。而程序计数器正是起到这种作用，所以通常又称为指令计数器。在程序开始执行前，必须将它的起始地址，即程序的第一条指令所在的内存单元地址送入程序计数器，因此程序计数器的内容即是从内存提取的一条指令的地址。当执行指令时，处理器将自动修改PC的内容，即每执行一条指令PC增加一个量，这个量等于指令所含的字节数，以便使其保持的总是将要执行的下一条指令的地址。由于大多数指令都是按顺序来执行的，所以修改的过程通常只是简单的对PC加1。<br>但是，当遇到转移指令如JMP（跳转、外语全称：JUMP）指令时，后继指令的地址（即PC的内容）必须从指令寄存器中的地址字段取得。在这种情况下，下一条从内存取出的指令将由转移指令来规定，而不像通常一样按顺序来取得。因此程序计数器的结构应当是具有寄存信息和计数两种功能的结构。<br><strong>这一部分不会发生内存泄漏</strong>，程序计数器指令可以标记<strong>if for 多线程</strong>等“<strong>运行到哪里”</strong>  通常又称之为‘指令计数器’</p><h2 id="补-JVM堆空间（gc堆）"><a href="#补-JVM堆空间（gc堆）" class="headerlink" title="补:JVM堆空间（gc堆）"></a>补:JVM堆空间（gc堆）</h2><ul><li>存放: 对象实例 and  数组</li><li>每次new操作都是在堆中开辟空间，不一定是连续的空间，</li><li>堆空间的分配常用分代策略（新生代 老年代 永久代（现：元空间））</li></ul><h1 id="补-垃圾回收的流程"><a href="#补-垃圾回收的流程" class="headerlink" title="补:垃圾回收的流程"></a>补:垃圾回收的流程</h1><p>以分代机制+回收算法+G1垃圾收集器为例：</p><ul><li><strong>G1垃圾收集器</strong>决定了：垃圾回收的cpu资源调度方式是并发兼顾延迟和吞吐量，分堆；能结合多种算法策略，是一个监视者的角色。</li><li>回收算法决定了：xx对象在本轮回收中是否被回收，如强引用则不回收，其他引用回收策略不同</li><li>分代机制决定了：什么时候调用垃圾回收，如新生代区的Eden满后调用Minor GC</li><li>过程：不停的new，因为引用方式不同and对象大小不同，会导致不同的对象分在了元空间(相当于JDK8之前的永久代)、新生代(Eden满后Minor GC)、老年代(System.gc()或老年代区满后Full GC)<br>————因为垃圾回收器的区别，如G1会动态监控并标记GC Roots，调用回收算法<br>————进行可达性分析，决定对象的去留<br>————调用Full GC来进行垃圾回收，释放内存</li></ul><h1 id="JVM如何判定一个对象是否应该被回收"><a href="#JVM如何判定一个对象是否应该被回收" class="headerlink" title="JVM如何判定一个对象是否应该被回收?"></a>JVM如何判定一个对象是否应该被回收?</h1><h2 id="1-引用计数器算法×"><a href="#1-引用计数器算法×" class="headerlink" title="1.引用计数器算法×"></a>1.引用计数器算法×</h2><p>方法内容：<br>对象被引用一次，计数器+1；失效一次，计数器-1，计数器归零后失效</p><p><strong>不能解决互相引用</strong>情况下的垃圾回收问题，例如：LinkedList源码中clear方法和unLinked方法需要多步操作<strong>来消除循环引用</strong></p><h2 id="2-可达性分析算法√"><a href="#2-可达性分析算法√" class="headerlink" title="2.可达性分析算法√"></a>2.可达性分析算法√</h2><p>在Java C＃中的主流算法<br>算法思想：<br>通过一些列成为“GC Roots”的<strong>根对象</strong>作为起始点，如果一条引用链的起始点不是GC Roots，那么就会被垃圾回收（<strong>不是强引用就会被垃圾回收，只是时间问题</strong>）<br>GC Roots包括：</p><ol><li>虚拟机栈中引用的对象</li><li>方法区静态属性引用的对象</li><li>方法区常量引用的对象</li><li>本地方法引用的对象（底层是c或操作系统语言）<br><img src="https://img-blog.csdnimg.cn/dc4ad3fb230748bf8f14980cbcbf1449.png" alt="打圈的会被回收"><h3 id="GC-Roots"><a href="#GC-Roots" class="headerlink" title="GC Roots"></a>GC Roots</h3>这其实是一个相对的概念，在调用Minor GC的时候，老年代就是根对象<br>像上面的那4种是“即使Full GC”也不会回收的，就是绝对的根对象</li></ol><h2 id="补充：引用的四种方式："><a href="#补充：引用的四种方式：" class="headerlink" title="补充：引用的四种方式："></a>补充：引用的四种方式：</h2><p><a href="https://blog.csdn.net/linzhiqiang0316/article/details/88591907?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-0.pc_relevant_default&spm=1001.2101.3001.4242.1&utm_relevant_index=2">参考链接</a></p><h3 id="强引用"><a href="#强引用" class="headerlink" title="强引用"></a>强引用</h3><p>Object obj = new Object();强引用在，垃圾收集器就一直不会被回收该对象，JVM宁愿抛出OutOfMemory错误也不会回收这种对象。如果想中断强引用和某个对象之间的关联，可以显示地将引用赋值为null，这样一来的话，JVM在合适的时间就会回收该对象。</p><h3 id="软引用SoftReference"><a href="#软引用SoftReference" class="headerlink" title="软引用SoftReference"></a>软引用SoftReference</h3><p>SoftReference aSoftRef=new SoftReference(obj);如果一个对象具有软引用，内存空间足够，垃圾回收器就不会回收它；软引用可用来实现内存敏感的高速缓存，<strong>一旦垃圾线程回收该Java对象之 后，get()方法将返回null</strong></p><p><img src="https://img-blog.csdnimg.cn/5c02dfba92cc4a4ca626b50c48ea0369.png"></p><h3 id="弱引用WeakReference"><a href="#弱引用WeakReference" class="headerlink" title="弱引用WeakReference"></a>弱引用WeakReference</h3><p>创建方法和WeakReference 相同，但比SoftReference更弱，<strong>仅仅能生存到下次垃圾回收之前</strong>，无论内存是否足够 都会回收</p><pre><code>    People people=new People(&quot;zjh&quot;,21);      WeakReference&lt;People&gt;reference=new WeakReference&lt;People&gt;(people);    System.out.println(reference.get());  //zjh 21    System.gc();      System.out.println(reference.get()); //null</code></pre><h3 id="虚引用PhantomReference"><a href="#虚引用PhantomReference" class="headerlink" title="虚引用PhantomReference"></a>虚引用PhantomReference</h3><p>最弱的引用关系，虚引用主要用来<strong>跟踪</strong>对象被垃圾回收的活动，在回收之前通知系统，但<strong>不影响对象的生命周期</strong>。</p><h1 id="JVM垃圾回收算法有哪些？"><a href="#JVM垃圾回收算法有哪些？" class="headerlink" title="JVM垃圾回收算法有哪些？"></a>JVM垃圾回收算法有哪些？</h1><ul><li>以下三种方法，在实际的虚拟机中是组合使用，去其糟粕，取其精华</li><li>垃圾回收算法 和 回收机制不同</li></ul><h2 id="标记清除算法"><a href="#标记清除算法" class="headerlink" title="标记清除算法"></a>标记清除算法</h2><p>标记不连续，可用内存被分割，在申请连续大空间时可能没有可用的内存，资源浪费大<br><img src="https://img-blog.csdnimg.cn/592240b2bc514b7ea211e3fa194d9f16.png"></p><h2 id="标记整理算法"><a href="#标记整理算法" class="headerlink" title="标记整理算法"></a>标记整理算法</h2><p>标记的同时把可用对象整理在一起</p><p><img src="https://img-blog.csdnimg.cn/53fe5484d0554b6db22d524888041867.png"></p><h2 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h2><p>局限性很大，内存利用率很差，先复制可用存活对象复制到一块区域</p><p><img src="https://img-blog.csdnimg.cn/87e917f8d1b8489e8fcc834e22e1a41a.png">右边这块的内存都是不能使用的</p><p><a href="https://www.cnblogs.com/dmzna/archive/2020/05/18/12913458.html">参考链接</a></p><h1 id="JVM垃圾回收机制"><a href="#JVM垃圾回收机制" class="headerlink" title="JVM垃圾回收机制"></a>JVM垃圾回收机制</h1><ul><li>回收机制≠回收算法</li><li>常用的是<strong>分代回收策略</strong></li><li>一般是只要<strong>空间不足就触发</strong>垃圾回收机制<h2 id="代的划分"><a href="#代的划分" class="headerlink" title="代的划分"></a>代的划分</h2></li></ul><p><img src="https://img-blog.csdnimg.cn/3c26182da16a4119a79f012073d0e2d1.png"></p><p><a href="https://blog.csdn.net/mccand1234/article/details/52078645">参考链接1</a><br><a href="https://www.cnblogs.com/jichi/p/12580906.html">参考链接2</a></p><p>商用Java内存分配和回收的机制概括的说，就是：<strong>分代分配，分代回收</strong>。</p><ul><li>对象将根据<strong>存活的时间</strong>被分为：<br>年轻代（Young Generation）：<strong>回收频率快</strong><br>年老代（Old Generation）：<strong>回收频率慢</strong><br>永久代（Permanent Generation，也就是方法区，JDK1.8之后删除了永久代）</li><li>不同代有不同的算法，不同的处理机制</li><li>内存担保机制：新生代到老年代</li></ul><h3 id="新生代的三个分区8-1-1"><a href="#新生代的三个分区8-1-1" class="headerlink" title="新生代的三个分区8:1:1"></a>新生代的三个分区8:1:1</h3><p>Eden伊甸园:From幸存区:To幸存区=8：1：1<br>From是上一次幸存的对象<br>To是本次幸存的对象</p><ul><li>new一个对象，默认采用伊甸园的空间，<strong>大对象则直接到老年代</strong></li><li>一直new直到伊甸园空间放不够了就触发<strong>新生代垃圾回收Minor GC</strong></li><li>直到连老年代都快满了，触发<strong>老年代垃圾回收Full GC</strong></li></ul><h3 id="Minor-GC"><a href="#Minor-GC" class="headerlink" title="Minor GC"></a>Minor GC</h3><ul><li><strong>触发</strong>了Minor GC之后就调用<strong>垃圾回收算法</strong>（标记清除、标记整理、复制算法）</li><li>例如调用了标记算法，就把标记存活的对象复制到幸存区To中，<strong>寿命计数器+1</strong>；而被标记回收的伊甸园对象则被回收</li><li>伊甸园再次空闲，直到下次满的时候<strong>触发第二次Minor GC</strong></li><li>寿命计数器&gt;15(4bit)时(可能因为新生代空间严重不足而提前晋升)，对象从新生代传入老年代，此后不会被Minor GC回收</li><li><strong>会触发STW，但耗时短</strong><h3 id="Full-GC"><a href="#Full-GC" class="headerlink" title="Full GC"></a>Full GC</h3></li><li>新生代老年代<strong>同时进行垃圾回收</strong></li><li><strong>会触发STW，且耗时长</strong></li><li>调用System.gc()</li></ul><h2 id="STW"><a href="#STW" class="headerlink" title="STW"></a>STW</h2><ul><li>stop thr world 当触发STW时，其他的所有线程都停止，直到垃圾回收完成</li><li>因此回收效率高，但会有停顿时间，适合在Client端使用，不适合在Sever端使用</li><li>Minor GC 和 Full GC都会触发STW</li></ul><h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><p>JVM中的垃圾收集器主要包括7种，即Serial，Serial Old，ParNew，Parallel Scavenge，Parallel Old以及CMS，G1收集器。<br><img src="https://img-blog.csdnimg.cn/3107e1c7f6c44dc59dd32dba530ca563.png"></p><h2 id="G1——Garbage-one"><a href="#G1——Garbage-one" class="headerlink" title="G1——Garbage one"></a>G1——Garbage one</h2><ul><li><strong>取代CMS</strong>垃圾回收器</li><li>出自JDK7，JDK9之后成为<strong>默认</strong>的垃圾回收器</li><li><strong>并发</strong></li><li><strong>同时注重吞吐量和响应时间</strong></li><li>适合于超大内存场景，<strong>会将堆均匀分区以便并发</strong>，每个区都有独立的年轻代、老年代堆区域</li><li>CMS和G1都是<strong>Full GC</strong>(老年代垃圾回收机制)<br><img src="https://img-blog.csdnimg.cn/4038af9659a6445fb1f3391d9633622b.png"></li></ul><h2 id="串行"><a href="#串行" class="headerlink" title="串行"></a>串行</h2><ul><li>单线程</li><li>堆内存小，适合个人电脑</li></ul><h2 id="吞吐量优先"><a href="#吞吐量优先" class="headerlink" title="吞吐量优先"></a>吞吐量优先</h2><ul><li>多线程</li><li>堆内存大，需要多核CPU支持（真并发），适合服务器</li><li>一次大量回收，<strong>单位时间STW时间尽可能短</strong>，总时间更短</li></ul><h2 id="响应时间有限"><a href="#响应时间有限" class="headerlink" title="响应时间有限"></a>响应时间有限</h2><ul><li>多线程</li><li>堆内存大，需要多核CPU支持（真并发），适合服务器</li><li>单次少量回收，<strong>单次STW时间尽可能短</strong>，每次影响更小</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>随机森林——泰坦尼克号获救预测</title>
      <link href="/zjh/2022/01/11/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E2%80%94%E2%80%94%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E8%8E%B7%E6%95%91%E9%A2%84%E6%B5%8B/"/>
      <url>/zjh/2022/01/11/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E2%80%94%E2%80%94%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E8%8E%B7%E6%95%91%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h1><p>定义问题——&gt;数据收集——&gt;数据清洗——&gt;分析——&gt;建模——&gt;验证——&gt;优化</p><p>该问题下前两步已经完成，本文从数据清洗开始</p><h1 id="数据集的特征解读"><a href="#数据集的特征解读" class="headerlink" title="数据集的特征解读"></a>数据集的特征解读</h1><table><thead><tr><th align="center">英</th><th align="center">中</th><th align="center">分析</th></tr></thead><tbody><tr><td align="center">PassengeID</td><td align="center">乘客ID</td><td align="center">乘客ID不影响Survive与否，但可标识身份</td></tr><tr><td align="center">Pclass</td><td align="center">船舱等级</td><td align="center">高等船舱靠近甲板，更容易Survive</td></tr><tr><td align="center">Name</td><td align="center">姓名</td><td align="center">标记</td></tr><tr><td align="center">Sex</td><td align="center">性别</td><td align="center">男女生理差别，对Survive有影响</td></tr><tr><td align="center">Age</td><td align="center">年龄</td><td align="center">同上</td></tr><tr><td align="center">SibSp</td><td align="center">兄弟配偶数</td><td align="center">有无同行兄弟or配偶，同行会影响决策</td></tr><tr><td align="center">Parch</td><td align="center">父母孩子数</td><td align="center">有无同行父母or孩子，从而影响Survive</td></tr><tr><td align="center">Ticket</td><td align="center">船票信息</td><td align="center">/</td></tr><tr><td align="center">Fare</td><td align="center">票价</td><td align="center">票价跟Pclass也是正相关</td></tr><tr><td align="center">Cabin</td><td align="center">船舱信息</td><td align="center">/</td></tr><tr><td align="center">Embarked</td><td align="center">港口</td><td align="center">/</td></tr><tr><td align="center">Survived</td><td align="center">存活与否</td><td align="center">/</td></tr></tbody></table><p>以上信息中</p><ul><li>有些特征对分析没什么意义，建模时可以不扔进算法</li><li>有些特征之间互相有关联，可以多特征线性合并</li><li>部分数据需要清洗</li><li>Train集中的Survived变量要放入模型训练</li><li>Test集中的Survived变量作为验证标准</li></ul><h1 id="库和数据导入，简单分析"><a href="#库和数据导入，简单分析" class="headerlink" title="库和数据导入，简单分析"></a>库和数据导入，简单分析</h1><pre><code>import pandas as pdimport numpy as npimport timeimport sklearnfrom sklearn import ensemble#集成学习，包括了随机森林，SVM等集成学习算法from sklearn import feature_selection#特征值选择，分类回归都需要的特征值如F和Pfrom sklearn import model_selection#模型选择，包括了交叉验证，网格搜索等from sklearn import metrics#包括了多个计算模型评估的算法from sklearn.preprocessing import LabelEncoder#将Label标准化，如：字符串——&gt;数字，以便代入模型##绘图import matplotlib as mplimport matplotlib.pyplot as pltimport seaborn as sns#一个封装好的matplotlib，底层是matplotlib，使用更方便#mpl.style_use(&quot;ggplot&quot;)#设置matplotlib的绘图风格，可有可无data_train = pd.read_csv(&quot;train.csv&quot;)data_test  = pd.read_csv(&quot;test.csv&quot;)#显示数据集信息print(data_train.info())print(data_test.head(10))</code></pre><h2 id="完整显示数据集统计信息（完整描述）set-option"><a href="#完整显示数据集统计信息（完整描述）set-option" class="headerlink" title="完整显示数据集统计信息（完整描述）set_option"></a>完整显示数据集统计信息（完整描述）set_option</h2><pre><code>pd.set_option(&#39;display.max_columns&#39;,11)#train集中有11列属性，设置最大列数为11print(data_train.describe())</code></pre><ul><li>同样的，pd.set_option(‘display.max_columns’,10)也可以让原本显示不全的head()显示全</li></ul><p><img src="https://img-blog.csdnimg.cn/img_convert/5cef01f2bb72055365b892b39b01cdfb.png" alt="info和head输出结果"></p><pre><code>count:有效值个数（非空值）unique:特征值的种类数top：出现最多的特征freq: top出现的次数mean：均值std : 标准差min ：最小值25%：四分之一位50%：中位数75%：四分之三位max：最大值</code></pre><p><img src="https://img-blog.csdnimg.cn/img_convert/aadde03b94c0c0ced9033806d8fa540f.png" alt="describe输出结果"></p><ul><li><strong>一共有891行数据，但Age、Cabin属性明显缺失，此案例下的缺失值暂时用中位数代替</strong></li></ul><h1 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h1><p>数据清洗是数据分析中耗时最长最麻烦的阶段</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><pre><code>#列名小写,方便后续data_test.columns = data_test.columns.str.lower()data_train.columns = data_train.columns.str.lower()data_train.info()#查看属性小写后的info#合并Train和Test以便统一数据清洗data_sum = [data_train , data_test]#但由于这个sum是一个list，会缺少很多原本train和test能用的属性or方法，如columns#注意：此处的合并不是直接合并数据集，而是创建一个list，实现一键操作#一定是先分别lower再合并成sum</code></pre><p>   <strong>要想调用方法，需要使用for循环</strong></p><h3 id="查看survived的统计直方图"><a href="#查看survived的统计直方图" class="headerlink" title="查看survived的统计直方图"></a>查看survived的统计直方图</h3><pre><code>#查看属性统计量seaborn下的countplot，绘制图像sns.countplot(x = data_train[&#39;survived&#39;] )#sns.coutplot(x = &quot;survived&quot; , data = data_train)#两种表达方式plt.show()#olt.show()是生成图的操作，必不可少</code></pre><h2 id="补全缺失值fillna"><a href="#补全缺失值fillna" class="headerlink" title="补全缺失值fillna"></a>补全缺失值fillna</h2><pre><code>#分别查看train和test集中为null值的汇总print(data_train.isnull().sum())print(&#39;\n&#39;)print(data_test.isnull().sum())</code></pre><ul><li><strong>age embarked的缺失值占比比较少，可以替换值</strong></li><li><strong>cabin的缺失值占比很高，建模时直接把cabin属性全扔掉</strong></li></ul><p><img src="https://img-blog.csdnimg.cn/img_convert/6608f6f8d8f17032998fd2e2801c213b.png" alt="左：null汇总  右：contplot直方图"></p><h3 id="利用for循环对样本集一键纠正"><a href="#利用for循环对样本集一键纠正" class="headerlink" title="利用for循环对样本集一键纠正"></a>利用for循环对样本集一键纠正</h3><pre><code>for dataset in data_sum:    dataset[&#39;age&#39;].fillna(dataset[&#39;age&#39;].median() , inplace=True)    dataset[&#39;fare&#39;].fillna(dataset[&#39;fare&#39;].median() , inplace=True)    ###因为age、fare都是数字类型，因此可以调用median中位数    ###而像属性值位字符串的特征则不能调用median    dataset[&#39;embarked&#39;].fillna(dataset[&#39;embarked&#39;].mode()[0] , inplace=True)    #mode返回的是 众数，因为即便是字符串，也可以调用</code></pre><ul><li><p>注意：mode和median的用法场景区别</p></li><li><p>注意fillna的使用格式</p></li><li><p>inplace=True表示更改原数据集，而不是返回一个新的数据集</p></li><li><p>mode是pandas下的一个方法，返回按索引号排序的众数，<strong>mode()[索引号]的索引号很重要，如果省略则不填充</strong></p><h2 id="删除无用字段-特征-drop"><a href="#删除无用字段-特征-drop" class="headerlink" title="删除无用字段(特征)drop"></a>删除无用字段(特征)drop</h2><p>  drop_columns = [‘cabin’,’passengerid’,’ticket’]#创建一个list<br>  #分析认为：cabin缺失值太多，需要删除<br>  #passengerid无关survive，删除<br>  #ticket都是编号，删除</p><p>  data_train.drop(drop_columns,axis=1,inplace=True)<br>  data_test.drop(drop_columns,axis=1,inplace=True)<br>  #drop参数的意义(行or列 , axis=0删行 axis=1删列 ， inplace=True直接更改调用者数据集本身)</p></li><li><p>注意：drop的参数含义</p></li><li><p>可以构建for循环 + drop_columns一次操作</p></li></ul><h2 id="纠正异常值"><a href="#纠正异常值" class="headerlink" title="纠正异常值"></a>纠正异常值</h2><h3 id="利用for循环的样本集一键纠正"><a href="#利用for循环的样本集一键纠正" class="headerlink" title="利用for循环的样本集一键纠正"></a>利用for循环的样本集一键纠正</h3><p>因为这个案例中信息来源准确，可以认为没有异常值，故在此案例中不做处理</p><h2 id="构建新特征"><a href="#构建新特征" class="headerlink" title="构建新特征"></a>构建新特征</h2><ul><li>连续值用cut或者qcut来划分</li><li>离散值直接划分，合并数量少的值<h3 id="同行规模"><a href="#同行规模" class="headerlink" title="同行规模"></a>同行规模</h3><pre><code>  #同行规模 = 配偶 + 兄弟姐妹 + 1(自己)  dataset[&#39;together_size&#39;] =  dataset[&#39;sibsp&#39;] + dataset[&#39;parch&#39;] + 1</code></pre></li></ul><h3 id="是否单身"><a href="#是否单身" class="headerlink" title="是否单身"></a>是否单身</h3><pre><code>    #是否单身：单身可以不顾别人，会影响survive    dataset[&#39;isSingle&#39;] = 0    dataset[&#39;isSingle&#39;].loc[dataset[&#39;together_size&#39;] &gt; 1] = 1</code></pre><h3 id="票价分段：cut"><a href="#票价分段：cut" class="headerlink" title="票价分段：cut"></a>票价分段：cut</h3><pre><code>    #票价分段fare_bin:票价的离散值太多，应该划分为几个集    #数据集中票价0~512，并且绝大多数都是便宜票，所以用cut等宽划分    dataset[&#39;fare_bin&#39;] = pd.cut(dataset[&#39;fare&#39;] , 4)</code></pre><h3 id="年龄分段：qcut"><a href="#年龄分段：qcut" class="headerlink" title="年龄分段：qcut"></a>年龄分段：qcut</h3><pre><code>    #年龄分段age_bin    dataset[&#39;age_bin&#39;] = pd.qcut(dataset[&#39;age&#39;] , 4)</code></pre><h3 id="身份分类：合少为1"><a href="#身份分类：合少为1" class="headerlink" title="身份分类：合少为1"></a>身份分类：合少为1</h3><pre><code>    #身份 status:因为英国人的名字会加入跟身份有关的职业，身份也会影响获救概率    dataset[&#39;status&#39;] = dataset[&#39;name&#39;].str.split(&#39;, &#39; , expand = True)[1].str.split(&#39;.&#39; , expand = True)[0]    ###参数含义：str是返回字符串，expand要为True值    ###按引号中的符号进行split拆分，[0]表示取前半段，[1]表示取后半段    print(dataset[&#39;status&#39;].value_counts())#查看统计</code></pre><p><img src="https://img-blog.csdnimg.cn/6a4e973ba6174e63a9514db8712abbc3.png" alt="可以把少的分为一类other"></p><pre><code>   #把少的分为一类other    othersSum = dataset[&#39;status&#39;].value_counts() &lt; 10    #other对象 = 小于10的    dataset[&#39;status&#39;] = dataset[&#39;status&#39;].apply(lambda x : &#39;ohter&#39; if othersSum[x] else x)    #更新后的status属性 = 之前的status.aooly(lambda x : &#39;新的名字&#39; if other对象[x] else x)    print(dataset[&#39;status&#39;].value_counts())</code></pre><p><img src="https://img-blog.csdnimg.cn/2629dc2066e64987b95896a87db5dd6c.png" alt="少的被分到了other组"></p><h2 id="新特征分析：评估新特征划分的好坏"><a href="#新特征分析：评估新特征划分的好坏" class="headerlink" title="新特征分析：评估新特征划分的好坏"></a>新特征分析：评估新特征划分的好坏</h2><p>以不同的特征分类计算各属性值的均值，以标签survived的均值为参考，不同特征值的标签均值差别越大越好</p><pre><code>#简单分析上述构建特征是否有效:groupby根据属性值分组print(data_train[&#39;survived&#39;].groupby(data_train[&#39;status&#39;]).mean())#查看按这样构建的特征status的不同值survived对应的均值print(data_train[&#39;survived&#39;].groupby(data_train[&#39;age_bin&#39;]).mean())print(data_train[&#39;survived&#39;].groupby(data_train[&#39;fare_bin&#39;]).mean())print(data_train[&#39;survived&#39;].groupby(data_train[&#39;isSingle&#39;]).mean())print(data_train[&#39;survived&#39;].groupby(data_train[&#39;together_size&#39;]).mean())</code></pre><p><img src="https://img-blog.csdnimg.cn/7fb4dcd3150d4be886223a0af1715d6d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_19,color_FFFFFF,t_70,g_se,x_16" alt="新特征分析">于是对age_bin进行修改，最终尝试结果是qcut改cut，区分度提升最明显</p><h1 id="格式替换-构建新字段，"><a href="#格式替换-构建新字段，" class="headerlink" title="格式替换,构建新字段，"></a>格式替换,构建新字段，</h1><p>1，基于scikit-learn中的LabelEncoder()<br>把属性值为字符串的特征转化为“特征_code”，字符串——&gt;数字，以便放入模型中跑<br><strong>机器学习模型只能处理int和float的数据</strong></p><pre><code>#实例化label = LabelEncoder()#字符串——&gt;数字for dataset in data_sum:    # （1）新字段：sex_code    dataset[&#39;sex_code&#39;] = label.fit_transform(dataset[&#39;sex&#39;])    # （2）新字段：embarked_code    dataset[&#39;embarked_code&#39;] = label.fit_transform(dataset[&#39;embarked&#39;])    # （3）新字段：status_code    dataset[&#39;status_code&#39;] = label.fit_transform(dataset[&#39;status&#39;])    # （4）新字段：age_bin_code    dataset[&#39;age_bin_code&#39;] = label.fit_transform(dataset[&#39;age_bin&#39;])    # （5）新字段：fare_bin_code    dataset[&#39;fare_bin_code&#39;] = label.fit_transform(dataset[&#39;fare_bin&#39;])print(data_train.columns.to_list)    </code></pre><p><img src="https://img-blog.csdnimg.cn/e20dfbee4e5b4bb7992cfb15aaeae6ac.png" alt="新的列名"><br><img src="https://img-blog.csdnimg.cn/cda97a956c634886b678242a3a315ec8.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_20,color_FFFFFF,t_70,g_se,x_16"><br>2，通过Pandas中的get_dummies() 进行编码</p><h1 id="建模"><a href="#建模" class="headerlink" title="建模"></a>建模</h1><h2 id="标签、特征选择"><a href="#标签、特征选择" class="headerlink" title="标签、特征选择"></a>标签、特征选择</h2><h3 id="标签选择"><a href="#标签选择" class="headerlink" title="标签选择"></a>标签选择</h3><pre><code>target = [&#39;survived&#39;]    </code></pre><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><pre><code>data_feature_one = [&#39;sex&#39;, &#39;pclass&#39;, &#39;embarked&#39;, &#39;status&#39;, &#39;sibsp&#39;, &#39;parch&#39;, &#39;age&#39;, &#39;fare&#39;, &#39;together_size&#39;,                    &#39;isSingle&#39;]</code></pre><h3 id="通过Pandas中的get-dummies-进行编码"><a href="#通过Pandas中的get-dummies-进行编码" class="headerlink" title="通过Pandas中的get_dummies() 进行编码"></a>通过Pandas中的get_dummies() 进行编码</h3><p>这是一个暴力转码（字符串——&gt;数字代号）的方法，十分简单，且更好用</p><pre><code>data_one_dummy = pd.get_dummies(data_train[data_feature_one])#把data_feature_one中需要转码的如：status、embarked转为数字代号data_one_dummy_list = data_one_dummy.columns.tolist()#转list，以便放入网格搜索的形参中去跑</code></pre><h2 id="把train集拆分为训练集和测试"><a href="#把train集拆分为训练集和测试" class="headerlink" title="把train集拆分为训练集和测试"></a>把train集拆分为训练集和测试</h2><pre><code>X_train_one, X_test_one, y_train_one, y_test_one = model_selection.train_test_split(data_one_dummy[data_one_dummy_list],#转码后的list格式的train[feature]                                                                    data_train[target],#标签                                                                    random_state = 0)#随机种子print(X_train_one.shape)print(X_test_one.shape)#shape查看分割的大小，也可以通过size参数自己设置分割比例,数据量很大时通常使用2 8分，train_size=0.8print(y_train_one.shape)print(y_test_one.shape)#大X表示：特征  小y表示：标签</code></pre><p><img src="https://img-blog.csdnimg.cn/f70f693e524f4c75bfdb6ccfe37883b4.png" alt="左：数据量(行)  右：特征数(列)"></p><h2 id="网格搜索：寻找最优"><a href="#网格搜索：寻找最优" class="headerlink" title="网格搜索：寻找最优"></a>网格搜索：寻找最优</h2><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><pre><code>from sklearn.model_selection import GridSearchCV   #网格搜索from sklearn.ensemble import RandomForestClassifier #随机森林分类器rfc = RandomForestClassifier(max_features=&#39;auto&#39; , random_state= 0 , n_jobs=-1 )#实例化一个RandomForestClassifier对象#简单选取所有特征 ， 随机种子=0  ， 利用所有线程#这里实例化RandomForestClassifier时可以不用写入太多参数，参数可以放进网格里面自己跑出最优的</code></pre><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><pre><code>param_gird = &#123;#需要最优化的参数对象    &#39;criterion&#39; : [&#39;gini&#39;, &#39;entropy&#39;],#标准选择    &#39;min_samples_leaf&#39; : [ 1,3,5, 10],#最小子叶数    &#39;min_samples_split&#39; : [10, 12, 16,20,24],#最小样本数    &#39;n_estimators&#39; : [20,35,50,100]#决策树的个数选择&#125;gscv = GridSearchCV(#网格搜索交叉验证对象                estimator=rfc,#rf带入网格算                param_grid=param_gird,#需要最优化的参数带入                scoring= &#39;accuracy&#39;, #得分评判————准确度                cv=3,#交叉验证次数                n_jobs=-1)#-1 利用CPU所有线程gs = gscv.fit(X_train_one , y_train_one.values.ravel())#自动训练，两个参数都是train集#.values.ravel()是为了防止warning#自动训练的所有结果返回在gs中，这个print(gs.best_score_)#最高分数print(gs.best_params_)#最佳组合</code></pre><p><img src="https://img-blog.csdnimg.cn/7b7e4e2ba989488b8e4d553f025731fc.png"></p><h3 id="网格搜索调参"><a href="#网格搜索调参" class="headerlink" title="网格搜索调参"></a>网格搜索调参</h3><ul><li>如果某特征的最优值是在罗列的数的中间，那么认为比较优秀</li><li>如果在边上，就需要往那个方向调参重新跑</li><li>同时有多个参数需要调时，先调差距最大的</li><li>即使是位于中间的参数也可以细分调整</li><li>类似高中生物实验探究题《寻找最佳浓度》的思想</li></ul><h2 id="用最优参数训练随机森林"><a href="#用最优参数训练随机森林" class="headerlink" title="用最优参数训练随机森林"></a>用最优参数训练随机森林</h2><pre><code>#实例化RandomForestClassifier对象rfc2 = RandomForestClassifier(criterion=&#39;entropy&#39;,                             min_samples_leaf=5,                             min_samples_split=16,                             n_estimators=35,                             n_jobs=-1,                             random_state=1)#训练rfc2.fit(X_train_one, y_train_one.values.ravel())</code></pre><p>此时训练完成，等待后续用<strong>split分割出来的测试集test来测试</strong></p><h3 id="根据特征的重要性排序"><a href="#根据特征的重要性排序" class="headerlink" title="根据特征的重要性排序"></a>根据特征的重要性排序</h3><pre><code>print(pd.concat((pd.DataFrame(X_train_one.iloc[:, 1:].columns, columns=[&#39;Variable&#39;]),           pd.DataFrame(rfc2.feature_importances_, columns=[&#39;importance&#39;])),           axis=1).sort_values(by=&#39;importance&#39;, ascending=False))</code></pre><p><img src="https://img-blog.csdnimg.cn/1583b73b3f2845c2b203ded785146e72.png"></p><ul><li><strong>重要性</strong>：重要性是特征在模型中的决定能力，而不是越高就代表标签越接近1</li></ul><h2 id="在test上预测：是split分割出来的test"><a href="#在test上预测：是split分割出来的test" class="headerlink" title="在test上预测：是split分割出来的test"></a>在test上预测：是split分割出来的test</h2><pre><code>predict_test = rfc2.predict(X_test_one)#test集中的特征数据Xpred_df = pd.DataFrame(predict_test, columns=[&#39;survived&#39;])#预测结果表print(pred_df)#test集的验证结果print(&#39;随机森林 AUC...&#39;)fpr_test, tpr_test, th_test = metrics.roc_curve(predict_test, y_test_one)# 构造 roc 曲线print(&#39;AUC = %.4f&#39; %metrics.auc(fpr_test, tpr_test))#参考意义最大的就是AUCprint(&#39;随机森林精确度...&#39;)print(metrics.classification_report(predict_test, y_test_one))#精准度表格</code></pre><p><img src="https://img-blog.csdnimg.cn/04fabbe4baed47c68ad12214800bf1d0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_19,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="验证：不是split分割出来的test，而是test-csv"><a href="#验证：不是split分割出来的test，而是test-csv" class="headerlink" title="验证：不是split分割出来的test，而是test.csv"></a>验证：不是split分割出来的test，而是test.csv</h2><pre><code>data_val_dummy = pd.get_dummies(data_test[data_feature_one])#转码data_val_dummy_list = data_val_dummy.columns.tolist()print(data_val_dummy_list)#查看转码后的列名，拿着这些列名预测pred_val = rfc2.predict(data_val_dummy[[#根据上一条语句的结果，copy了列名                                        &#39;pclass&#39;, &#39;sibsp&#39;, &#39;parch&#39;, &#39;age&#39;,                                        &#39;fare&#39;, &#39;together_size&#39;, &#39;isSingle&#39;,                                        &#39;sex_female&#39;, &#39;sex_male&#39;, &#39;embarked_C&#39;,                                        &#39;embarked_Q&#39;, &#39;embarked_S&#39;, &#39;status_Master&#39;,                                        &#39;status_Miss&#39;, &#39;status_Mr&#39;, &#39;status_Mrs&#39;,                                        &#39;status_ohter&#39;]])pred_val_df = pd.DataFrame(pred_val, columns=[&#39;survived&#39;])print(pred_val_df.head(10))#展示前10个数据</code></pre><p><img src="https://img-blog.csdnimg.cn/348435ac3b974dfd827f256ee10998f0.png"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>决策树/随机森林——用户流失预测的案例</title>
      <link href="/zjh/2022/01/01/%E5%86%B3%E7%AD%96%E6%A0%91-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E2%80%94%E2%80%94%E7%94%A8%E6%88%B7%E6%B5%81%E5%A4%B1%E9%A2%84%E6%B5%8B%E7%9A%84%E6%A1%88%E4%BE%8B/"/>
      <url>/zjh/2022/01/01/%E5%86%B3%E7%AD%96%E6%A0%91-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E2%80%94%E2%80%94%E7%94%A8%E6%88%B7%E6%B5%81%E5%A4%B1%E9%A2%84%E6%B5%8B%E7%9A%84%E6%A1%88%E4%BE%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><p><strong>摘要</strong>：<br><br>从决策树的定义，优缺点等宏观角度入题，逐步从数学原理过渡到代码实现，最后总结</p><p><strong>关键词</strong>:<br><br>决策树、信息熵、基尼系数、ID3、CART</p><h2 id="决策树是什么"><a href="#决策树是什么" class="headerlink" title="决策树是什么"></a>决策树是什么</h2><blockquote><p>一个根节点，若干个内部节点和叶节点<br><br> 非参数学习算法<br><br> 天然的分类器<br></p></blockquote><h2 id="决策树的目标"><a href="#决策树的目标" class="headerlink" title="决策树的目标"></a>决策树的目标</h2><p>解决<strong>分类</strong>和<strong>回归</strong>问题</p><h2 id="决策树的优点"><a href="#决策树的优点" class="headerlink" title="决策树的优点"></a>决策树的优点</h2><blockquote><ul><li>决策树易于理解和实现，人们在在学习过程中不需要使用者了解很多的背景知识，这同时是它的能够直接体现数据的特点，只要通过解释后都有能力去理解决策树所表达的意义。</li><li>对于决策树，数据的准备往往是简单或者是不必要的，而且能够同时处理数据型和常规型属性，在相对短的时间内能够对大型数据源做出可行且效果良好的结果。</li><li>准确性高: 挖掘出来的分类规则准确性高, 便于理解, 决策树可以清晰的显示哪些字段比较重要, 即可以生成可以理解的规则.</li><li>适合处理有缺失属性的样本，对缺失值不敏感</li></ul></blockquote><h2 id="决策树的缺点"><a href="#决策树的缺点" class="headerlink" title="决策树的缺点"></a>决策树的缺点</h2><blockquote><ul><li>容易发生过拟合（剪枝 随机森林）</li><li>分类过程中每一步都依据单一特征，忽视了特征之间的关联性，在处理特征关联性强的数据时表现不好</li><li>对于样本不均衡的数据集表现不好，欠拟合。在特征选择时ID3算法偏好于选取可取值数目较多的属性,C4.5算法偏向选取可取值数目较少的属性（实际中是在算法中采用启发式原则，先从候选属性中选出信息增益高于平均水平的属性，再从中选择增益率最高的属性）</li></ul></blockquote><h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>根据<strong>信息熵</strong>(entropy) or <strong>基尼系数</strong>(gini)的大小决定下一个节点怎么分枝，最后生成决策树，而<strong>随机森林</strong>就是多个决策树的组合</p><h2 id="信息熵entropy"><a href="#信息熵entropy" class="headerlink" title="信息熵entropy"></a>信息熵entropy</h2><p><a href="https://www.zhihu.com/search?q=yjango%E4%BF%A1%E6%81%AF%E7%86%B5&utm_content=search_suggestion&type=content">超链接：Yjango:什么是信息熵？</a></p><p><em>熵在信息论中代表随机变量的不确定性的度量</em></p><p>熵越小，数据不确定性越低<br>熵越大，数据不确定性越高</p><p>信息熵<br>H=$-\displaystyle \sum^{k}_{i = 1}{Pi}$${log_2{(Pi)}}$</p><h2 id="基尼系数"><a href="#基尼系数" class="headerlink" title="基尼系数"></a>基尼系数</h2><ul><li>基尼值<br>G = 1 $-\displaystyle \sum^{k}_{i = 1}{Pi^2}$</li></ul><p>以基尼指数为指标时，应该选择Gini指数最<strong>小</strong>的</p><p>CART决策树使用“基尼指数”来选择划分属性</p><ul><li>  基尼指数<br>G_index = $-\displaystyle \sum^{V}_{v = 1}{\frac{|D^v|}{|D|}Gini(D^v)}$</li></ul><p><strong>基尼指数到0时，即到叶节点，不能再往下划分</strong></p><h2 id="AUC-ROC-tpr-fpr"><a href="#AUC-ROC-tpr-fpr" class="headerlink" title="AUC ROC tpr fpr"></a>AUC ROC tpr fpr</h2><ul><li>tpr：Recall，召回率，即当前被分到正样本类别中，真实的正样本占所有正样本的比例，即召回率（召回了多少正样本比例）</li><li>fpr：Precision，正例率，即当前划分到正样本类别中，被正确分类的比例（即正式正样本所占比例），就是我们一般理解意义上所关心的正样本的分类准确率；</li><li>ROC：tpr和fpr决定的曲线</li><li>AUC：ROC曲线下包围的面积，最大值为1，越大拟合性能越好</li></ul><h2 id="过拟合的原因及如何防止"><a href="#过拟合的原因及如何防止" class="headerlink" title="过拟合的原因及如何防止"></a>过拟合的原因及如何防止</h2><p>对于过拟合现象产生的原因，有以下几个方面，</p><blockquote><ul><li>第一：在决策树构建的过程中，对决策树的生长没有进行合理的限制（<strong>剪枝</strong>）；</li><li>第二：在建模过程中使用了<strong>较多的输出变量</strong>，变量较多也容易产生过拟合；</li><li>第三：样本中有一些<strong>噪声数据</strong>，噪声数据对决策树的构建的干扰很多，没有对噪声数据进行有效的剔除。</li></ul></blockquote><p>对于过拟合现象的预防措施，有以下一些方法，</p><blockquote><ul><li>第一：选择合理的参数进行<strong>剪枝</strong>，可以分为预剪枝后剪枝，我们一般用后剪枝的方法来做；</li><li>第二：<strong>K-folds交叉验证</strong>，将训练集分为K份，然后进行K次的交叉验证，每次使用K-1份作为训练样本数据集，另外的一份作为测试集合（作者说反了，应该是份作为测试集，其余k-1份作为训练集）；</li><li>第三：减少特征，计算每一个特征和相应变量的<strong>相关性</strong>，常见的为皮尔逊相关系数，将相关性较小的变量剔除，当然还有一些其他的方法来进行特征筛选，比如基于决策树的特征筛选，通过正则化的方式来进行特征选取等。</li></ul></blockquote><h2 id="预剪枝：生成决策树的过程中剪枝"><a href="#预剪枝：生成决策树的过程中剪枝" class="headerlink" title="预剪枝：生成决策树的过程中剪枝"></a>预剪枝：生成决策树的过程中剪枝</h2><pre><code>基于“贪心”本质，能剪则剪。</code></pre><p>如果某个分支的存在并没有提高准确率，or降低了准确率，则剪掉</p><blockquote><p>降低了过拟合风险；<br><br>显著减少了决策树训练时间；<br><br>但带来了欠拟合的风险</p></blockquote><h2 id="后剪枝：生成决策树之后剪枝"><a href="#后剪枝：生成决策树之后剪枝" class="headerlink" title="后剪枝：生成决策树之后剪枝"></a>后剪枝：生成决策树之后剪枝</h2><pre><code>能不剪，则不剪，剪前后若准确率相等，则保留</code></pre><blockquote><p>同样的训练模型，后剪枝的决策树保留了更多的分支<br><br>后剪枝的欠拟合风险很小<br><br>泛化性能往往优于预剪枝(分的更细，在面对陌生数据时判断更准确)<br><br>训练时间长的多(生成决策树之后需要自底向上逐一考察，计算开销大)<br></p></blockquote><pre><code>“在有噪声的情况下，剪枝操作甚至能将泛化性能提高25%”</code></pre><h2 id="连续值：可取连续值的属性"><a href="#连续值：可取连续值的属性" class="headerlink" title="连续值：可取连续值的属性"></a>连续值：可取连续值的属性</h2><p>例如：脐部{凹陷，平坦，稍凹}这种是离散值；而密度，xx含量等很多属性值都是连续的</p><p>因此在划分分支的时候，需要有一个间断点</p><p>间断点的划分方法：二分法，例如有17个排序后的点集，两两之间算中位数，一共算16次，生成16个t值，组成一个t的集合T，用T中的划分点代入Gain算法，计算Gain(D，该属性，t为划分点)，取Gain最大值，对应的t即为最终确定的划分点<br>划分完t之后，如果子分支还需用到更细的判断， 可以使用t的子集：例如：一个节点判断“密度&lt;=0.381”那么后续的子节点可以使用任何”密度&lt;0.381”范围的判断依据</p><h2 id="缺失值：某些数据的其中某个数据缺失，若全部弃用则会很浪费"><a href="#缺失值：某些数据的其中某个数据缺失，若全部弃用则会很浪费" class="headerlink" title="缺失值：某些数据的其中某个数据缺失，若全部弃用则会很浪费"></a>缺失值：某些数据的其中某个数据缺失，若全部弃用则会很浪费</h2><p>属性a缺失值处理方法：</p><p>西瓜书上p88：跳过该属性a的判断，直接判断下一节点的所有可能性，但需要加上训练集中的比例权重</p><pre><code>(离散值)：众数填充、相关性最高的列(属性b总是与属性a的取值几乎一一对应)填充(连续值)：中位数、相关性最高的列(同上)做线性回归估计</code></pre><h2 id="多变量决策树：用线性关系替代多个变量"><a href="#多变量决策树：用线性关系替代多个变量" class="headerlink" title="多变量决策树：用线性关系替代多个变量"></a>多变量决策树：用线性关系替代多个变量</h2><p>有些属性之间有一定的线性关系，例如：密度和含糖量之间存在着线性关系，那么就把密度和含糖量分别乘上各自的权重系数，用他俩组成的一个式子&lt;=t 或 &gt;=t 作为分界点来判断</p><pre><code>多变量决策树算法：贪心寻找每个属性的最优权值，线性分类器的最小二乘法</code></pre><h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><p>擅长于解决数据不平衡的分类</p><h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="1，导包"><a href="#1，导包" class="headerlink" title="1，导包"></a>1，导包</h3><pre><code>import pandas as pdimport numpy as np</code></pre><h3 id="2，读取、初步查看分析数据"><a href="#2，读取、初步查看分析数据" class="headerlink" title="2，读取、初步查看分析数据"></a>2，读取、初步查看分析数据</h3><pre><code>df = pd.read_csv(&#39;broadband.csv&#39;)df.rename(str.lower, axis=&#39;columns&#39;, inplace=True)#列名全换小写，方便看print(df.head())#空参则显示前5行数据# broadband 即可：0-离开(否)，1-留存(是)df.info() #输出行列信息（总体数据特征）print(df.sample()) # 随机查看一个样本数据# 查看因变量 broadband 分布情况，看是否存在不平衡from collections import Counterprint(&#39;Broadband: &#39;, Counter(df[&#39;broadband&#39;]))     #输出结果是Broadband:  Counter(&#123;0: 131, 1: 49&#125;)，数据并不平衡</code></pre><p><img src="https://img-blog.csdnimg.cn/6a2b7fea48b04223b402fb145f80d793.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_20,color_FFFFFF,t_70,g_se,x_16" alt="前5行信息and随机查看样本数据"></p><p><img src="https://img-blog.csdnimg.cn/30820d3df1b24efb98664f1347d2109d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_19,color_FFFFFF,t_70,g_se,x_16" alt="info输出信息"></p><h3 id="3，划分训练集-测试集"><a href="#3，划分训练集-测试集" class="headerlink" title="3，划分训练集 测试集"></a>3，划分训练集 测试集</h3><p>由于步骤2中info()发现数据集的第一列是用户ID，最后一列是判断标准Broadband，故这两列都不用做数据分析</p><pre><code>y = df[&#39;broadband&#39;] # y就是标签(结果)X = df.iloc[:, 1:-1] # 客户 id 没有用，故丢弃 cust_id；标签y也要去掉，故1：-1#左边冒号左右端为空，表示所有行数据全部都取到X中from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)#40%划分为test集，# 这里的random_state就是为了保证程序每次运行都分割一样的训练集和测试集。# 否则，同样的算法模型在不同的训练集和测试集上的效果不一样。# 因此具体取值多少无所谓，但对结果有影响</code></pre><h3 id="4，决策树建模"><a href="#4，决策树建模" class="headerlink" title="4，决策树建模"></a>4，决策树建模</h3><h4 id="网格搜索："><a href="#网格搜索：" class="headerlink" title="网格搜索："></a>网格搜索：</h4><p>因为决策树算法是非参数学习算法，需要自行调参，利用网格搜索则可以自动调参，择优选取<br><br>把自己认为好的参数都扔进去，让网格搜索自己跑</p><pre><code>import sklearn.tree as tree# 1. 直接使用交叉网格搜索来优化决策树模型，边训练边优化from sklearn.model_selection import GridSearchCV# 2. 网格搜索参数，选择最优参数,该param_grid作为评价指标用于下面的训练模型param_grid = &#123;&#39;criterion&#39;: [&#39;entropy&#39;, &#39;gini&#39;], # 树的深度评估指标,信息熵or基尼            &#39;max_depth&#39;: [2, 3, 4, 5, 6, 7, 8], # 可选树的深度            &#39;min_samples_split&#39;: [4, 8, 12, 16, 20, 24, 28]&#125; # 可选最小拆分的叶子样本数</code></pre><h4 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h4><pre><code># 3. 定义一棵树对象clf = tree.DecisionTreeClassifier()  # 4. 传入模型，网格搜索的参数，评估指标，cv交叉验证的次数clfcv = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=&#39;roc_auc&#39;,cv=4) # roc曲线和auc面积值作为评价标准（一般都用auc直接比较面积）# cv=？表示交叉验证的次数# 5. 训练模型clfcv.fit(X_train, y_train)# 6. 使用模型来对测试集进行预测test_result = clfcv.predict(X_test)</code></pre><h4 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h4><pre><code># 7. 模型评估import sklearn.metrics as metricsprint(&quot;决策树 AUC:&quot;)fpr_test, tpr_test, th_test = metrics.roc_curve(y_test, test_result)#主要是为了得到fpr，tpr，代入AUC计算公式print(&#39;AUC = %.4f&#39; %metrics.auc(fpr_test, tpr_test))#输出AUC的值print(&quot;决策树准确度:&quot;)print(metrics.classification_report(y_test,test_result))#输出准确度表格，参考价值不是很大，一般还是以AUC为准# 9. 求网格搜索后的最优参数print(clfcv.best_params_)#输出最优参数组合，但这个最优并非完全最优，可能还需要在开始的地方再重新调参，可能#算出的最后参数结果还不同#假设“最小样本设置&#123;4，5，6，7，8&#125;”，而最优结果是4 或 8，处于边缘，#就需要往边缘调参#因为该样本结果是：#&#123;&#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 3, &#39;min_samples_split&#39;: 12&#125;#都不是设置的边缘只，所以可以认为这些参数还不错，暂时不调参</code></pre><p><img src="https://img-blog.csdnimg.cn/16e8639fe87447e1b9f205219401708c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_20,color_FFFFFF,t_70,g_se,x_16" alt="决策树AUC" title="决策树AUC"></p><h3 id="5，决策树生成"><a href="#5，决策树生成" class="headerlink" title="5，决策树生成"></a>5，决策树生成</h3><h4 id="选择最优参数重新训练"><a href="#选择最优参数重新训练" class="headerlink" title="选择最优参数重新训练"></a>选择最优参数重新训练</h4><pre><code># 将最优参数代入到模型中，重新训练、预测#&#123;&#39;criterion&#39;: &#39;entropy&#39;, &#39;max_depth&#39;: 3, &#39;min_samples_split&#39;: 12&#125;clf2 = tree.DecisionTreeClassifier(criterion=&#39;entropy&#39;, max_depth=3, min_samples_split=12)clf2.fit(X_train, y_train)test_res2 = clf2.predict(X_test)</code></pre><h4 id="绘制决策树，在同目录下生成pdf"><a href="#绘制决策树，在同目录下生成pdf" class="headerlink" title="绘制决策树，在同目录下生成pdf"></a>绘制决策树，在同目录下生成pdf</h4><pre><code>#  绘制图形 pip3 install graphvizimport graphvizdot_data = tree.export_graphviz(clf2, out_file=None)graph = graphviz.Source(dot_data)graph.render(&#39;决策树&#39;)#生成文件名为决策树的pdf图片</code></pre><p><img src="https://img-blog.csdnimg.cn/bac26eaf8ba04751a8308ddf86301246.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_20,color_FFFFFF,t_70,g_se,x_16" alt="决策树生成" title="决策树生成"></p><h2 id="随机森林-1"><a href="#随机森林-1" class="headerlink" title="随机森林"></a>随机森林</h2><p>由于上述决策树生成的AUC值还不到0.7，认为拟合效果不够好，因此尝试使用随机森林算法</p><h3 id="1-网格搜索"><a href="#1-网格搜索" class="headerlink" title="1,网格搜索"></a>1,网格搜索</h3><pre><code>param_grid = &#123;    &#39;criterion&#39;:[&#39;entropy&#39;,&#39;gini&#39;],# 衡量标准    &#39;max_depth&#39;:[5, 6, 7, 8],    # 每棵决策树的深度    &#39;n_estimators&#39;:[11,13,15],  # 决策树个数 - 随机森林特有参数    &#39;max_features&#39;:[0.3,0.4,0.5], # 每棵决策树使用的变量占比 - 随机森林特有参数    &#39;min_samples_split&#39;:[4,8,12,16]  # 叶子的最小拆分样本量&#125;</code></pre><h3 id="2-集成学习：随机森林训练"><a href="#2-集成学习：随机森林训练" class="headerlink" title="2,集成学习：随机森林训练"></a>2,集成学习：随机森林训练</h3><pre><code>import sklearn.ensemble as ensemble # ensemble learning: 集成学习rfc = ensemble.RandomForestClassifier()rfc_cv = GridSearchCV(estimator=rfc, param_grid=param_grid,                    scoring=&#39;roc_auc&#39;, cv=4)rfc_cv.fit(X_train, y_train)</code></pre><h3 id="3-使用随机森林对结果预测，并求AUC（一般都高于决策树）"><a href="#3-使用随机森林对结果预测，并求AUC（一般都高于决策树）" class="headerlink" title="3,使用随机森林对结果预测，并求AUC（一般都高于决策树）"></a>3,使用随机森林对结果预测，并求AUC（一般都高于决策树）</h3><pre><code>predict_test = rfc_cv.predict(X_test)#训练，预测结束之后，方可查看最佳参数配置print(rfc_cv.best_params_)#输出AUC和精度表格print(&#39;随机森林 AUC...&#39;)fpr_test, tpr_test, th_test = metrics.roc_curve(predict_test, y_test) # 构造 roc 曲线print(&#39;AUC = %.4f&#39; %metrics.auc(fpr_test, tpr_test))print(&#39;随机森林精确度...&#39;)print(metrics.classification_report(predict_test, y_test))</code></pre><p><img src="https://img-blog.csdnimg.cn/f0a64f28f5004c82bc2914efde97415c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_20,color_FFFFFF,t_70,g_se,x_16" alt="随机森林AUC结果"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>调参的思想类似于高中生物实验探究题中的 <strong>“寻找最佳浓度”</strong></p><p>衡量决策树 or 随机森林 <strong>模型好坏的标准一般用AUC的值来判断</strong></p><p><strong>非参数学习一般都用网格搜索</strong><br><br>例如在进行网格搜索时，有很多参数，哪怕最优结果表明只需要调整一个参数，调整之后其他最优结果可能也会改变（牵一发动全身）<br><em>当然，如果电脑性能足够好，可以直接放很多参数去跑，省去了大量的调参花费的精力</em></p><p><strong>网格搜索的参数范围一开始要间隔比较大才好</strong></p><p>其他参数相同时，同一个 random_state=？保证了算出来的结果相同</p><h1 id="附："><a href="#附：" class="headerlink" title="附："></a>附：</h1><h2 id="树模型的参数"><a href="#树模型的参数" class="headerlink" title="树模型的参数"></a>树模型的参数</h2><pre><code># # -  1.criterion  gini  or  entropy# # -  2.splitter  best or random 前者是在所有特征中找最好的切分点 后者是在部分特征中（数据量大的时候）# # -  3.max_features  None（所有），log2，sqrt，N  特征小于50的时候一般使用所有的# # -  4.max_depth  数据少或者特征少的时候可以不管这个值，如果模型样本量多，特征也多的情况下，可以尝试限制下# # -  5.min_samples_split  如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。# # -  6.min_samples_leaf  这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝，如果样本量不大，不需要管这个值，大些如10W可是尝试下5# # -  7.min_weight_fraction_leaf 这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。# # -  8.max_leaf_nodes 通过限制最大叶子节点数，可以防止过拟合，默认是&quot;None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制具体的值可以通过交叉验证得到。# # -  9.class_weight 指定样本各类别的的权重，主要是为了防止训练集某些类别的样本过多导致训练的决策树过于偏向这些类别。这里可以自己指定各个样本的权重如果使用“balanced”，则算法会自己计算权重，样本量少的类别所对应的样本权重会高。# # - 10.min_impurity_split 这个值限制了决策树的增长，如果某节点的不纯度(基尼系数，信息增益，均方差，绝对差)小于这个阈值则该节点不再生成子节点。即为叶子节点 。# - n_estimators:要建立树的个数</code></pre>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>IDEA常用快捷键</title>
      <link href="/zjh/2021/12/25/IDEA%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
      <url>/zjh/2021/12/25/IDEA%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
      
        <content type="html"><![CDATA[<p>摘自： <a href="https://blog.csdn.net/cold___play/article/details/100178346?ops_request_misc=&request_id=&biz_id=102&utm_term=idea%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-100178346.nonecase&spm=1018.2226.3001.4187" title="来自：CSDN"> IDEA常用命令 ,侵删</a></p><h3 id="1-自动代码"><a href="#1-自动代码" class="headerlink" title="1. 自动代码"></a>1. 自动代码</h3><p>常用的有fori/sout/psvm+Tab即可生成循环、System.out、main方法等boilerplate样板代码 。<br>例如要输入for(User user : users)只需输入user.for+Tab。</p><p>再比如，要输入Date birthday = user.getBirthday();只需输入user.getBirthday().var+Tab即可。代码标签输入完成后，按Tab，生成代码。</p><table><thead><tr><th align="center">快捷键</th><th align="center">指令</th></tr></thead><tbody><tr><td align="center">Ctrl+Alt+O</td><td align="center">优化导入的类和包</td></tr><tr><td align="center">Alt+Insert</td><td align="center">生成代码(如get,set方法,构造函数等) 或者右键（Generate）</td></tr><tr><td align="center">Ctrl+Alt+T</td><td align="center">生成try catch 或者 Alt+enter</td></tr><tr><td align="center">CTRL+ALT+T</td><td align="center">把选中的代码放在 TRY{} IF{} ELSE{} 里</td></tr><tr><td align="center">Ctrl + O</td><td align="center">重写方法</td></tr><tr><td align="center">Ctrl + I</td><td align="center">实现方法</td></tr><tr><td align="center">Ctr+shift+U</td><td align="center">大小写转化</td></tr><tr><td align="center">ALT+回车</td><td align="center">导入包,自动修正</td></tr><tr><td align="center">ALT+/</td><td align="center">代码提示</td></tr><tr><td align="center">CTRL+J</td><td align="center">自动代码</td></tr><tr><td align="center">Ctrl+Shift+J</td><td align="center">整合两行为一行</td></tr><tr><td align="center">CTRL+空格</td><td align="center">代码提示</td></tr><tr><td align="center">CTRL+SHIFT+SPACE</td><td align="center">自动补全代码</td></tr><tr><td align="center">CTRL+ALT+L</td><td align="center">格式化代码</td></tr><tr><td align="center">CTRL+ALT+I</td><td align="center">自动缩进</td></tr><tr><td align="center">CTRL+ALT+O</td><td align="center">优化导入的类和包</td></tr><tr><td align="center">ALT+INSERT</td><td align="center">生成代码(如GET,SET方法,构造函数等)</td></tr><tr><td align="center">CTRL+E</td><td align="center">最近更改的代码</td></tr><tr><td align="center">CTRL+ALT+SPACE</td><td align="center">类名或接口名提示</td></tr><tr><td align="center">CTRL+P</td><td align="center">方法参数提示</td></tr><tr><td align="center">CTRL+Q</td><td align="center">可以看到当前方法的声明</td></tr><tr><td align="center">Shift+F6</td><td align="center">重构-重命名 (包、类、方法、变量、甚至注释等)</td></tr><tr><td align="center">Ctrl+Alt+V</td><td align="center">提取变量</td></tr></tbody></table><h3 id="2-查询快捷键"><a href="#2-查询快捷键" class="headerlink" title="2. 查询快捷键"></a>2. 查询快捷键</h3><table><thead><tr><th align="center">快捷键</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">Ctrl＋Shift＋Backspace</td><td align="center">可以跳转到上次编辑的地</td></tr><tr><td align="center">CTRL+ALT+ left/right</td><td align="center">前后导航编辑过的地方</td></tr><tr><td align="center">ALT+7</td><td align="center">靠左窗口显示当前文件的结构</td></tr><tr><td align="center">Ctrl+F12</td><td align="center">浮动显示当前文件的结构</td></tr><tr><td align="center">ALT+F7</td><td align="center">找到你的函数或者变量或者类的所有引用到的地方</td></tr><tr><td align="center">CTRL+ALT+F7</td><td align="center">找到你的函数或者变量或者类的所有引用到的地方</td></tr><tr><td align="center">Ctrl+Shift+Alt+N</td><td align="center">查找类中的方法或变量</td></tr><tr><td align="center">双击SHIFT</td><td align="center">在项目的所有目录查找文件</td></tr><tr><td align="center">Ctrl+N</td><td align="center">查找类</td></tr><tr><td align="center">Ctrl+Shift+N</td><td align="center">查找文件</td></tr><tr><td align="center">CTRL+G</td><td align="center">定位行</td></tr><tr><td align="center">CTRL+F</td><td align="center">在当前窗口查找文本</td></tr><tr><td align="center">CTRL+SHIFT+F</td><td align="center">在指定窗口查找文本</td></tr><tr><td align="center">CTRL+R</td><td align="center">在当前窗口替换文本</td></tr><tr><td align="center">CTRL+SHIFT+R</td><td align="center">在指定窗口替换文本</td></tr><tr><td align="center">ALT+SHIFT+C</td><td align="center">查找修改的文件</td></tr><tr><td align="center">CTRL+E</td><td align="center">最近打开的文件</td></tr><tr><td align="center">F3</td><td align="center">向下查找关键字出现位置</td></tr><tr><td align="center">SHIFT+F3</td><td align="center">向上一个关键字出现位置</td></tr><tr><td align="center">选中文本，按Alt+F3</td><td align="center">高亮相同文本，F3逐个往下查找相同文本</td></tr><tr><td align="center">F4</td><td align="center">查找变量来源</td></tr><tr><td align="center">CTRL+SHIFT+O</td><td align="center">弹出显示查找内容</td></tr><tr><td align="center">Ctrl+W</td><td align="center">选中代码，连续按会有其他效果</td></tr><tr><td align="center">F2 或Shift+F2</td><td align="center">高亮错误或警告快速定位</td></tr><tr><td align="center">Ctrl+Up/Down</td><td align="center">光标跳转到第一行或最后一行下</td></tr><tr><td align="center">Ctrl+B</td><td align="center">快速打开光标处的类或方法</td></tr><tr><td align="center">CTRL+ALT+B</td><td align="center">找所有的子类</td></tr><tr><td align="center">CTRL+SHIFT+B</td><td align="center">找变量的类</td></tr><tr><td align="center">Ctrl+Shift+上下键</td><td align="center">上下移动代码</td></tr><tr><td align="center">Ctrl+Alt+ left/right</td><td align="center">返回至上次浏览的位置</td></tr><tr><td align="center">Ctrl+X</td><td align="center">删除行</td></tr><tr><td align="center">Ctrl+D</td><td align="center">复制行</td></tr><tr><td align="center">Ctrl+/ 或 Ctrl+Shift+/</td><td align="center">注释（// 或者/…/ ）</td></tr><tr><td align="center">Ctrl+H</td><td align="center">显示类结构图</td></tr><tr><td align="center">Ctrl+Q</td><td align="center">显示注释文档</td></tr><tr><td align="center">Alt+F1</td><td align="center">查找代码所在位置</td></tr><tr><td align="center">Alt+1</td><td align="center">快速打开或隐藏工程面板</td></tr><tr><td align="center">Alt+ left/right</td><td align="center">切换代码视图</td></tr><tr><td align="center">ALT+ ↑/↓</td><td align="center">在方法间快速移动定位</td></tr><tr><td align="center">CTRL+ALT+ left/right</td><td align="center">前后导航编辑过的地方</td></tr><tr><td align="center">Ctrl＋Shift＋Backspace</td><td align="center">可以跳转到上次编辑的地</td></tr><tr><td align="center">Alt+6</td><td align="center">查找TODO</td></tr></tbody></table><h3 id="3-其它快捷键"><a href="#3-其它快捷键" class="headerlink" title="3. 其它快捷键"></a>3. 其它快捷键</h3><table><thead><tr><th align="center">快捷键</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">SHIFT+ENTER</td><td align="center">另起一行</td></tr><tr><td align="center">CTRL+Z</td><td align="center">倒退(撤销)</td></tr><tr><td align="center">CTRL+SHIFT+Z</td><td align="center">向前(取消撤销)</td></tr><tr><td align="center">CTRL+ALT+F12</td><td align="center">资源管理器打开文件夹</td></tr><tr><td align="center">ALT+F1</td><td align="center">查找文件所在目录位置</td></tr><tr><td align="center">SHIFT+ALT+INSERT</td><td align="center">竖编辑模式</td></tr><tr><td align="center">CTRL+F4</td><td align="center">关闭当前窗口</td></tr><tr><td align="center">Ctrl+Alt+V</td><td align="center">可以引入变量。例如：new String(); 自动导入变量定义</td></tr><tr><td align="center">Ctrl+~</td><td align="center">快速切换方案（界面外观、代码风格、快捷键映射等菜单）</td></tr></tbody></table><h3 id="4-svn快捷键"><a href="#4-svn快捷键" class="headerlink" title="4. svn快捷键"></a>4. svn快捷键</h3><table><thead><tr><th align="center">快捷键</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">ctrl+k</td><td align="center">提交代码到SVN</td></tr><tr><td align="center">ctrl+t</td><td align="center">更新代码</td></tr></tbody></table><h3 id="5-调试快捷键"><a href="#5-调试快捷键" class="headerlink" title="5. 调试快捷键"></a>5. 调试快捷键</h3><p>其实常用的 就是F8 F7 F9 最值得一提的 就是Drop Frame 可以让运行过的代码从头再来</p><table><thead><tr><th align="center">快捷键</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">alt+F8</td><td align="center">debug时选中查看值</td></tr><tr><td align="center">Alt+Shift+F9</td><td align="center">选择 Debug</td></tr><tr><td align="center">Alt+Shift+F10</td><td align="center">选择 Run</td></tr><tr><td align="center">Ctrl+Shift+F9</td><td align="center">编译</td></tr><tr><td align="center">Ctrl+Shift+F8</td><td align="center">查看断点</td></tr><tr><td align="center">F7</td><td align="center">步入</td></tr><tr><td align="center">Shift+F7</td><td align="center">智能步入</td></tr><tr><td align="center">Alt+Shift+F7</td><td align="center">强制步入</td></tr><tr><td align="center">F8</td><td align="center">步过</td></tr><tr><td align="center">Shift+F8</td><td align="center">步出</td></tr><tr><td align="center">Alt+Shift+F8</td><td align="center">强制步过</td></tr><tr><td align="center">Alt+F9</td><td align="center">运行至光标处</td></tr><tr><td align="center">Ctrl+Alt+F9</td><td align="center">强制运行至光标处</td></tr><tr><td align="center">F9</td><td align="center">恢复程序</td></tr><tr><td align="center">Alt+F10</td><td align="center">定位到断点</td></tr></tbody></table><h3 id="6-重构"><a href="#6-重构" class="headerlink" title="6. 重构"></a>6. 重构</h3><table><thead><tr><th align="center">快捷键</th><th align="center">描述</th></tr></thead><tbody><tr><td align="center">Ctrl+Alt+Shift+T</td><td align="center">弹出重构菜单</td></tr><tr><td align="center">Shift+F6</td><td align="center">重命名</td></tr><tr><td align="center">F6</td><td align="center">移动</td></tr><tr><td align="center">F5</td><td align="center">复制</td></tr><tr><td align="center">Alt+Delete</td><td align="center">安全删除</td></tr><tr><td align="center">Ctrl+Alt+N</td><td align="center">内联</td></tr></tbody></table><h1 id="十大IntelliJ-IDEA快捷键"><a href="#十大IntelliJ-IDEA快捷键" class="headerlink" title="十大IntelliJ IDEA快捷键"></a>十大IntelliJ IDEA快捷键</h1><p>Intellij IDEA中有很多快捷键让人爱不释手，stackoverflow上也有一些有趣的讨论。每个人都有自己的最爱，想排出个理想的榜单还真是困难。<br>以前也整理过Intellij的快捷键，这次就按照我日常开发时的使用频率，简单分类列一下我最喜欢的十大快捷-神-键吧。</p><h3 id="智能提示："><a href="#智能提示：" class="headerlink" title="智能提示："></a>智能提示：</h3><p>Intellij首当其冲的当然就是Intelligence智能！基本的代码提示用Ctrl+Space，还有更智能地按类型信息提示Ctrl+Shift+Space，但因为Intellij总是随着我们敲击而自动提示，所以很多时候都不会手动敲这两个快捷键(除非提示框消失了)。用F2/ Shift+F2移动到有错误的代码，Alt+Enter快速修复(即Eclipse中的Quick Fix功能)。当智能提示为我们自动补全方法名时，我们通常要自己补上行尾的反括号和分号，当括号嵌套很多层时会很麻烦，这时我们只需敲Ctrl+Shift+Enter就能自动补全末尾的字符。而且不只是括号，例如敲完if/for时也可以自动补上{}花括号。<br>最后要说一点，Intellij能够智能感知Spring、Hibernate等主流框架的配置文件和类，以静制动，在看似“静态”的外表下，智能地扫描理解你的项目是如何构造和配置的。</p><h3 id="重构："><a href="#重构：" class="headerlink" title="重构："></a>重构：</h3><p>Intellij重构是另一完爆Eclipse的功能，其智能程度令人瞠目结舌，比如提取变量时自动检查到所有匹配同时提取成一个变量等。尤其看过《重构-改善既有代码设计》之后，有了Intellij的配合简直是令人大呼过瘾！也正是强大的智能和重构功能，使Intellij下的TDD开发非常顺畅。<br>切入正题，先说一个无敌的重构功能大汇总快捷键Ctrl+Shift+Alt+T，叫做Refactor This。按法有点复杂，但也符合Intellij的风格，很多快捷键都要双手完成，而不像Eclipse不少最有用的快捷键可以潇洒地单手完成(不知道算不算Eclipse的一大优点)，但各位用过Emacs的话就会觉得也没什么了(非Emacs黑)。此外，还有些最常用的重构技巧，因为太常用了，若每次都在Refactor This菜单里选的话效率有些低。比如Shift+F6直接就是改名，Ctrl+Alt+V则是提取变量。</p><h3 id="代码生成："><a href="#代码生成：" class="headerlink" title="代码生成："></a>代码生成：</h3><p>这一点类似Eclipse，虽不是独到之处，但因为日常使用频率极高，所以还是罗列在榜单前面。常用的有fori/sout/psvm+Tab即可生成循环、System.out、main方法等boilerplate样板代码，用Ctrl+J可以查看所有模板。后面“辅助”一节中将会讲到Alt+Insert，在编辑窗口中点击可以生成构造函数、toString、getter/setter、重写父类方法等。这两个技巧实在太常用了，几乎每天都要生成一堆main、System.out和getter/setter。<br>另外，Intellij IDEA 13中加入了后缀自动补全功能(Postfix Completion)，比模板生成更加灵活和强大。例如要输入for(User user : users)只需输入user.for+Tab。再比如，要输入Date birthday = user.getBirthday();只需输入user.getBirthday().var+Tab即可。</p><h3 id="编辑："><a href="#编辑：" class="headerlink" title="编辑："></a>编辑：</h3><p>编辑中不得不说的一大神键就是能够自动按语法选中代码的Ctrl+W以及反向的Ctrl+Shift+W了。此外，Ctrl+Left/Right移动光标到前/后单词，Ctrl+[/]移动到前/后代码块，这些类Vim风格的光标移动也是一大亮点。以上Ctrl+Left/Right/[]加上Shift的话就能选中跳跃范围内的代码。Alt+Forward/Backward移动到前/后方法。还有些非常普通的像Ctrl+Y删除行、Ctrl+D复制行、Ctrl+&lt;/&gt;折叠代码就不多说了。<br>关于光标移动再多扩展一点，除了Intellij本身已提供的功能外，我们还可以安装ideaVim或者emacsIDEAs享受到Vim的快速移动和Emacs的AceJump功能(超爽！)。另外，Intellij的书签功能也是不错的，用Ctrl+Shift+Num定义1-10书签(再次按这组快捷键则是删除书签)，然后通过Ctrl+Num跳转。这避免了多次使用前/下一编辑位置Ctrl+Left/Right来回跳转的麻烦，而且此快捷键默认与Windows热键冲突(默认多了Alt，与Windows改变显示器显示方向冲突，一不小心显示器就变成倒着显式的了，冏啊)。</p><h3 id="查找打开："><a href="#查找打开：" class="headerlink" title="查找打开："></a>查找打开：</h3><p>类似Eclipse，Intellij的Ctrl+N/Ctrl+Shift+N可以打开类或资源，但Intellij更加智能一些，我们输入的任何字符都将看作模糊匹配，省却了Eclipse中还有输入*的麻烦。最新版本的IDEA还加入了Search Everywhere功能，只需按Shift+Shift即可在一个弹出框中搜索任何东西，包括类、资源、配置项、方法等等。<br>类的继承关系则可用Ctrl+H打开类层次窗口，在继承层次上跳转则用Ctrl+B/Ctrl+Alt+B分别对应父类或父方法定义和子类或子方法实现，查看当前类的所有方法用Ctrl+F12。<br>要找类或方法的使用也很简单，Alt+F7。要查找文本的出现位置就用Ctrl+F/Ctrl+Shift+F在当前窗口或全工程中查找，再配合F3/Shift+F3前后移动到下一匹配处。<br>Intellij更加智能的又一佐证是在任意菜单或显示窗口，都可以直接输入你要找的单词，Intellij就会自动为你过滤。</p><h3 id="其他辅助："><a href="#其他辅助：" class="headerlink" title="其他辅助："></a>其他辅助：</h3><p>以上这些神键配上一些辅助快捷键，即可让你的双手90%以上的时间摆脱鼠标，专注于键盘仿佛在进行钢琴表演。这些不起眼却是至关重要的最后一块拼图有：</p><ul><li>命令：Ctrl+Shift+A可以查找所有Intellij的命令，并且每个命令后面还有其快捷键。所以它不仅是一大神键，也是查找学习快捷键的工具。</li><li>新建：Alt+Insert可以新建类、方法等任何东西。</li><li>格式化代码：格式化import列表Ctrl+Alt+O，格式化代码Ctrl+Alt+L。</li><li>切换窗口：Alt+Num，常用的有1-项目结构，3-搜索结果，4/5-运行调试。Ctrl+Tab切换标签页，Ctrl+E/Ctrl+Shift+E打开最近打开过的或编辑过的文件。</li><li>单元测试：Ctrl+Alt+T创建单元测试用例。</li><li>运行：Alt+Shift+F10运行程序，Shift+F9启动调试，Ctrl+F2停止。</li><li>调试：F7/F8/F9分别对应Step into，Step over，Continue。</li></ul><p>此外还有些我自定义的，例如水平分屏Ctrl+|等，和一些神奇的小功能Ctrl+Shift+V粘贴很早以前拷贝过的，Alt+Shift+Insert进入到列模式进行按列选中。</p><ul><li>Top #10切来切去：Ctrl+Tab</li><li>Top #9选你所想：Ctrl+W</li><li>Top #8代码生成：Template/Postfix +Tab</li><li>Top #7发号施令：Ctrl+Shift+A</li><li>Top #6无处藏身：Shift+Shift</li><li>Top #5自动完成：Ctrl+Shift+Enter</li><li>Top #4创造万物：Alt+Insert</li><li>Top #1智能补全：Ctrl+Shift+Space</li><li>Top #1自我修复：Alt+Enter</li><li>Top #1重构一切：Ctrl+Shift+Alt+T</li></ul><p>CTRL+ALT+ left/right 前后导航编辑过的地方。<br>Ctrl＋Shift＋Backspace可以跳转到上次编辑的地。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>回形针数字矩阵Java实现</title>
      <link href="/zjh/2021/12/25/%E5%9B%9E%E5%BD%A2%E9%92%88%E6%95%B0%E5%AD%97%E7%9F%A9%E9%98%B5Java%E5%AE%9E%E7%8E%B0/"/>
      <url>/zjh/2021/12/25/%E5%9B%9E%E5%BD%A2%E9%92%88%E6%95%B0%E5%AD%97%E7%9F%A9%E9%98%B5Java%E5%AE%9E%E7%8E%B0/</url>
      
        <content type="html"><![CDATA[<p><img src="https://img-blog.csdnimg.cn/20210726004539592.png"><br>我们发现这个回形数矩阵的逻辑是：→↓←↑四个为一个循环，故考虑框架为：一个外层for里面嵌套4个内层for</p><p>每个内层for的起点终点都随着外层的变化而变化</p><pre><code>import java.util.Scanner;public class Test1 &#123;    public static void main(String[] args) &#123;        Scanner scan = new Scanner(System.in);        System.out.println(&quot;输入一个数，返回回形数矩阵&quot;);        int i = scan.nextInt();        // 键盘输入一个数        int[][] arr = new int[i][i];        int m = 1;//用于赋值        /*思考循环数的逻辑顺序，→↓←↑四个为一个循环，故考虑框架为一个外层for里面套4个内层for*/        /*每一个循环的→↓←↑内层for循环，其起点和终点都不断改变，所以起点终点必须表现出来这个联系，绝不能为常数*/        for (int j = 0; j &lt; i; j++) &#123;             for (int k = j; k &lt; i - j; k++) &#123;//k=j和k&lt;i-j都在不断的改变                        arr[j][k] = m;                m++;            &#125;             for (int l = j + 1; l &lt; i - j; l++) &#123;                arr[l][i - j - 1] = m;                m++;            &#125;            for (int p = i - j - 2; p &gt; j - 1; p--) &#123;                arr[i - j - 1][p] = m;                m++;            &#125;            for (int q = i - j - 2; q &gt; j; q--) &#123;                arr[q][j] = m;                m++;            &#125;        &#125;        // 输出矩阵        for (int a = 0; a &lt; arr.length; a++) &#123;            for (int b = 0; b &lt; arr[a].length; b++) &#123;                System.out.print(arr[a][b] + &quot;\t&quot;);             &#125;            System.out.println();        &#125;    &#125;&#125;</code></pre>]]></content>
      
      
      <categories>
          
          <category> 数据结构算法 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java四种next用法</title>
      <link href="/zjh/2021/12/25/Java%E5%9B%9B%E7%A7%8Dnext%E7%94%A8%E6%B3%95/"/>
      <url>/zjh/2021/12/25/Java%E5%9B%9B%E7%A7%8Dnext%E7%94%A8%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在查阅了大量网上相关资料都没有一个完整的解释，并且我查的几篇高赞回答都是错误的时候，我决定用一整天的时间来精细写下这篇文章，希望对你有帮助。</p><pre><code>大多数人对hasNext的印象停留在“判断是否有下一个值”上，而该方法还是一个阻塞式的方法</code></pre><h1 id="hasNext和hasNextLine的区别"><a href="#hasNext和hasNextLine的区别" class="headerlink" title="hasNext和hasNextLine的区别"></a>hasNext和hasNextLine的区别</h1><p>二者都是用于判断“有无键盘输入”的，有则返回true，没有则阻塞！一定记住是阻塞而不是返回false，很多人都说是返回false，但你查源码会发现是不会返回false的，他会让你一直阻塞在判断阶段，二者只是在细节上有不同</p><pre><code>hasNext()方法会判断接下来是否有非空字符.如果有,则返回true，没有则阻塞。例如一直敲回车相当于一直判断为空字符，但是不会返回false，而是一直阻塞在判断阶段，直到你输入了非空字符hasNextLine() 方法会根据行匹配模式去判断接下来是否有一行(包括空行),如果有,则返回true。这个没什么特别的，只要是你敲了回车那都是true并且不会阻塞</code></pre><p>例如像这种if语句是永远不可能执行到内部方法体的</p><pre><code>if(scan.hasNext()==false)&#123;    System.out.println(&quot;hasNext和hasNextLine不会返回false&quot;);&#125;</code></pre><p> 再举一个例子加深理解：</p><pre><code>Scanner scan = new Scanner(System.in);System.out.println(scan.hasNextLine());System.out.println(scan.hasNext());</code></pre><p> 运行该代码，一直不停敲回车键，第一次回车会直接输出true，而后面一直敲都会阻塞在hasNext语句上，运行如下图</p><p><img src="https://img-blog.csdnimg.cn/20211001130739982.png"></p><p>首先，在看用法和解释之前，有以下几个点必须时刻牢记</p><blockquote><p>next方法不能录入空格，在特定情况下会把空格当作回车，nextLine方法可以识录入空格<br>hasNext和hasNextLine的返回值都是boolean类型，但只有可能返回true，不可能返回false，并且都默认以回车键为结束（hasNext可以设置为任意符号为结束键，不在本文研究范围之内）<br>hasNext、next不能直接识别裸回车，而hasNextLine和nextLine都可以直接识别裸回车。换句话讲：对于不输入符号而直接裸敲一个回车的操作，只有后两个能识别<br>hasNext、hasNextLine在返回一个boolean类型结果true的同时，会在堆空间中开辟一块专门用于存放刚刚输入的字符串，用于下次next或者nextLine：即下次next或者nextLine不需要再从键盘输入，相当于系统自动把刚刚输入的字符串再原封不动的输入了一遍。同时这个存储寿命＝调用对象的寿命<br>对于hasNext来说，每次敲击回车都相当于在堆空间中开辟一行，敲几次回车就会直接给后续next、nextLine方法赋值几次<br>hasNext是线程阻塞的，对于hasNext来说，如果一直不输入字符，反而一直敲回车的话，整个线程会卡在这个输入的地方，直到有字符输入</p></blockquote><p>在知道 hasNext的方法用于判断和存储，next的方法用于输入之后，来做如下预备工作</p><blockquote><p>因为hasNext、hasNextLine与next、nextLine有2X2种组合方式，所以我们用4段代码做4次实验就可以大体上了解他们的特性</p></blockquote><p>以下4段代码希望看客们能亲自复制粘贴了试一试，以便更深理解</p><h2 id="hasNext-和-next组合"><a href="#hasNext-和-next组合" class="headerlink" title="hasNext 和 next组合"></a>hasNext 和 next组合</h2><pre><code>Scanner scan = new Scanner(System.in);System.out.println(&quot;请输入字符串，并多混入空格回车尝试不同结果&quot;);if(scan.hasNext() ) &#123;    System.out.println(&quot;第一次&quot;+scan.next());    System.out.println(&quot;第二次&quot;+scan.next());    System.out.println(&quot;第三次&quot;+scan.next());&#125;</code></pre><p>尝试输入：空格aaa空格bbb空格ccc回车<br><img src="https://img-blog.csdnimg.cn/20211001131608748.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_18,color_FFFFFF,t_70,g_se,x_16"><br>解释：<br><img src="https://img-blog.csdnimg.cn/20211001125303907.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_15,color_FFFFFF,t_70,g_se,x_16"></p><h2 id="hasNext-和-NextLine组合"><a href="#hasNext-和-NextLine组合" class="headerlink" title="hasNext 和 NextLine组合"></a>hasNext 和 NextLine组合</h2><pre><code>Scanner scan = new Scanner(System.in);System.out.println(&quot;请输入字符串，并多混入空格回车尝试不同结果&quot;);if(scan.hasNext() ) &#123;    System.out.println(&quot;第一次&quot;+scan.nextLine());    System.out.println(&quot;第二次&quot;+scan.nextLine());    System.out.println(&quot;第三次&quot;+scan.nextLine());&#125;</code></pre><p>解释：光标仍然闪烁，证明堆空间中的  aaa bbb ccc只赋值给了第一个，这也验证了nextLine可以录入空格。此时线程正在等待用户输入第二个nextLine<br>hasNextLine 和 next组合</p><pre><code>Scanner scan = new Scanner(System.in);System.out.println(&quot;请输入字符串，并多混入空格回车尝试不同结果&quot;);if(scan.hasNextLine() ) &#123;    System.out.println(&quot;第一次&quot;+scan.next());    System.out.println(&quot;第二次&quot;+scan.next());    System.out.println(&quot;第三次&quot;+scan.next());&#125;</code></pre><h2 id="hasNextLine-和-nextLine组合"><a href="#hasNextLine-和-nextLine组合" class="headerlink" title="hasNextLine 和 nextLine组合"></a>hasNextLine 和 nextLine组合</h2><pre><code>Scanner scan = new Scanner(System.in);System.out.println(&quot;请输入字符串，并多混入空格回车尝试不同结果&quot;);if(scan.hasNextLine() ) &#123;    System.out.println(&quot;第一次&quot;+scan.nextLine());    System.out.println(&quot;第二次&quot;+scan.nextLine());    System.out.println(&quot;第三次&quot;+scan.nextLine());&#125;</code></pre><p>发现规律了吗<br><img src="https://img-blog.csdnimg.cn/20211001132037981.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_18,color_FFFFFF,t_70,g_se,x_16"></p><p><strong>如果直接连续敲回车，那么hasNextLine会判断为true，同时进入if语句执行，并且输入了三个空行也会输出三个空行</strong></p><p>验证hasNext、hasNextLine对输入代码的存储寿命</p><p>hasNextLine在if语句内，我们将验证语句next放在if语句之外，输入aaa bbb ccc ddd测试</p><pre><code>Scanner scan = new Scanner(System.in);System.out.println(&quot;请输入字符串，并多混入空格回车尝试不同结果&quot;);if(scan.hasNextLine() ) &#123;    System.out.println(&quot;第一次&quot;+scan.next());    System.out.println(&quot;第二次&quot;+scan.next());    System.out.println(&quot;第三次&quot;+scan.next());&#125;        System.out.println(&quot;验证存储寿命是否＝scan对象寿命&quot;+scan.next());</code></pre><p> <img src="https://img-blog.csdnimg.cn/20211001132824820.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_17,color_FFFFFF,t_70,g_se,x_16"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>hasNext、hasNextLine不可能返回false，只有true和阻塞两种结果</p><p>hasNext、hasNextLine会判断有无输入，并且hasNext一直敲回车而不输入字符会导致线程阻塞</p><p>hasNext、hasNextLine也有存储功能，从“开始输入”到“判断结束”的过程中的所有输入都将储存，直到之后遇到需要键盘输入的next、nextLine，这些存储的字符串和空格会自动填写给后面的next、nextLine。而空格再next和nextLine上有不同的表现</p><p>查看API还有很多同类型的不同方法，按照这个思路可以一通百通<br><img src="https://img-blog.csdnimg.cn/2021100113530823.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_20,color_FFFFFF,t_70,g_se,x_16"><br><img src="https://img-blog.csdnimg.cn/20211001135328579.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5Y-k57uG5Lqa,size_20,color_FFFFFF,t_70,g_se,x_16"></p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
